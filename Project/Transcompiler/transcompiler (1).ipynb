{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Author: Palash Kamble\n## E9 309 Advanced Deep Learning Project_1","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"# PyTorch Libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"_uuid":"700f9b3c-c709-41f3-8d91-d5c4d3dbb555","_cell_guid":"50320a47-87dd-4d39-aa37-20b07f243589","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-23T07:18:10.113142Z","iopub.execute_input":"2021-09-23T07:18:10.113725Z","iopub.status.idle":"2021-09-23T07:18:10.118104Z","shell.execute_reply.started":"2021-09-23T07:18:10.113687Z","shell.execute_reply":"2021-09-23T07:18:10.117157Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:12.110736Z","iopub.execute_input":"2021-09-23T07:18:12.111291Z","iopub.status.idle":"2021-09-23T07:18:12.114882Z","shell.execute_reply.started":"2021-09-23T07:18:12.111254Z","shell.execute_reply":"2021-09-23T07:18:12.114198Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:12.621586Z","iopub.execute_input":"2021-09-23T07:18:12.622251Z","iopub.status.idle":"2021-09-23T07:18:12.625541Z","shell.execute_reply.started":"2021-09-23T07:18:12.622216Z","shell.execute_reply":"2021-09-23T07:18:12.624741Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Loading Dataset","metadata":{}},{"cell_type":"code","source":"dataset_dir = '../input/d/palash97/translate-code/Dataset'\ntrain_dir = dataset_dir + '/Train'\nval_dir = dataset_dir + '/Val'\ntest_dir = dataset_dir + '/Test'\n\ntrain_py_dir = train_dir + '/python'\nval_py_dir = val_dir + '/python'\ntest_py_dir = test_dir + '/python'\n\ntrain_cpp_dir = train_dir + '/cpp'\nval_cpp_dir = val_dir + '/cpp'","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:12.774615Z","iopub.execute_input":"2021-09-23T07:18:12.775244Z","iopub.status.idle":"2021-09-23T07:18:12.780165Z","shell.execute_reply.started":"2021-09-23T07:18:12.775211Z","shell.execute_reply":"2021-09-23T07:18:12.779361Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Listing files from training python directory\npy_files = os.listdir(train_py_dir)\nprint(py_files[:5]) # printing first 5 file names ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:12.882412Z","iopub.execute_input":"2021-09-23T07:18:12.883133Z","iopub.status.idle":"2021-09-23T07:18:12.899531Z","shell.execute_reply.started":"2021-09-23T07:18:12.883098Z","shell.execute_reply":"2021-09-23T07:18:12.898778Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"['p_28.txt', 'p_35.txt', 'p_46.txt', 'p_53.txt', 'p_16.txt']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Listing files from training cpp directory\ncpp_files = os.listdir(train_cpp_dir)\nprint(cpp_files[:5]) # printing first 5 file names ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:12.985322Z","iopub.execute_input":"2021-09-23T07:18:12.987556Z","iopub.status.idle":"2021-09-23T07:18:13.004255Z","shell.execute_reply.started":"2021-09-23T07:18:12.987512Z","shell.execute_reply":"2021-09-23T07:18:13.003543Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"['c_21.txt', 'c_49.txt', 'c_39.txt', 'c_58.txt', 'c_38.txt']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'Number of files in python directory: {len(py_files)}')\nprint(f'Number of files in cpp directory: {len(cpp_files)}')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.048661Z","iopub.execute_input":"2021-09-23T07:18:13.049246Z","iopub.status.idle":"2021-09-23T07:18:13.055758Z","shell.execute_reply.started":"2021-09-23T07:18:13.049198Z","shell.execute_reply":"2021-09-23T07:18:13.054261Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Number of files in python directory: 60\nNumber of files in cpp directory: 60\n","output_type":"stream"}]},{"cell_type":"code","source":"# Printing one source and target code\npy_txt_file = os.path.join(train_py_dir, 'p_10.txt')\ncpp_txt_file = os.path.join(train_cpp_dir, 'c_10.txt')\n\nwith open (py_txt_file, 'r') as f:\n    py_txt = f.read()\n    \nwith open (cpp_txt_file, 'r') as f:\n    cpp_txt = f.read()\n\nprint('** Source Code **\\n')\nprint(py_txt)\nprint('\\n** Target Code **\\n')\nprint(cpp_txt)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.157782Z","iopub.execute_input":"2021-09-23T07:18:13.158040Z","iopub.status.idle":"2021-09-23T07:18:13.170905Z","shell.execute_reply.started":"2021-09-23T07:18:13.158014Z","shell.execute_reply":"2021-09-23T07:18:13.170018Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"** Source Code **\n\ndef func ( x : int , y : int ) -> int :\n    if x > y :\n        return x\n    else :\n        return y\n\n** Target Code **\n\nint func ( int x , int y ) { \n    if ( x > y ) { \n        return x ;\n    } else { \n        return y ;\n    } \n}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Pre-Processing and Tokenization","metadata":{}},{"cell_type":"code","source":"def tokenize(txt):\n    txt_split = txt.split(' ')\n    tokens = []\n    for tok in txt_split:\n        if '\\n' in tok:\n            for idx in range( len ( tok ) ) :\n                tokens.append(tok[idx])\n        else:\n            tokens.append(tok)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.355444Z","iopub.execute_input":"2021-09-23T07:18:13.355671Z","iopub.status.idle":"2021-09-23T07:18:13.364470Z","shell.execute_reply.started":"2021-09-23T07:18:13.355643Z","shell.execute_reply":"2021-09-23T07:18:13.363638Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Create Vocabulary","metadata":{}},{"cell_type":"code","source":"class Vocabulary(object):\n    def __init__(self):\n        self.freqs = {}\n        self.itos = {0: \"<UNK>\", 1: \"<PAD>\", 2: \"<SOS>\", 3: \"<EOS>\"}\n        self.stoi = {\"<UNK>\": 0, \"<PAD>\": 1, \"<SOS>\": 2, \"<EOS>\": 3}\n    \n    def build_vocabulary(self, py_dir, cpp_dir, threshold=1):\n        idx = 4\n        \n        for i in range(26):\n            ch = chr(97+i)\n            ch = str(ch)\n            self.freqs[ch] = 1\n            self.stoi[ch] = idx\n            self.itos[idx] = ch\n            idx += 1\n        \n        extra_functions = ['sub', 'func1', 'func2']\n        for extra_func in extra_functions:\n            self.freqs[extra_func] = 1\n            self.stoi[extra_func] = idx\n            self.itos[idx] = extra_func\n            idx += 1\n    \n        num_files = len(os.listdir(py_dir)) # number of files in py_dir is same as in cpp_dir\n        for i in range(1, num_files + 1):\n            py_file = os.path.join(py_dir, f'p_{i}.txt')\n            cpp_file = os.path.join(cpp_dir, f'c_{i}.txt')\n            \n            with open (py_file, 'r') as f:\n                py_txt = f.read()\n            with open (cpp_file, 'r') as f:\n                cpp_txt = f.read()\n            \n            py_tokens = tokenize(py_txt)\n            cpp_tokens = tokenize(cpp_txt)\n            \n            for tok in py_tokens:\n                if tok not in self.freqs:\n                    self.freqs[tok] = 1\n                else:\n                    self.freqs[tok] += 1\n                if self.freqs[tok] == threshold:\n                    self.stoi[tok] = idx\n                    self.itos[idx] = tok\n                    idx += 1\n            for tok in cpp_tokens:\n                if tok not in self.freqs:\n                    self.freqs[tok] = 1\n                else:\n                    self.freqs[tok] += 1\n                if self.freqs[tok] == threshold:\n                    self.stoi[tok] = idx\n                    self.itos[idx] = tok\n                    idx += 1\n    \n    def encode(self, text):\n        tokens = tokenize(text)\n        tokens_to_indices = [self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] for token in tokens]\n        tokens_to_indices = [self.stoi['<SOS>']] + tokens_to_indices + [self.stoi['<EOS>']]\n        return tokens_to_indices","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.516900Z","iopub.execute_input":"2021-09-23T07:18:13.517478Z","iopub.status.idle":"2021-09-23T07:18:13.537250Z","shell.execute_reply.started":"2021-09-23T07:18:13.517436Z","shell.execute_reply":"2021-09-23T07:18:13.536519Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"vocab = Vocabulary()\nvocab.build_vocabulary(train_py_dir, train_cpp_dir)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.539761Z","iopub.execute_input":"2021-09-23T07:18:13.540014Z","iopub.status.idle":"2021-09-23T07:18:13.805166Z","shell.execute_reply.started":"2021-09-23T07:18:13.539983Z","shell.execute_reply":"2021-09-23T07:18:13.804424Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(vocab.stoi)\nprint(f'Number of tokens in vocabulary: {vocab_size}')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.806638Z","iopub.execute_input":"2021-09-23T07:18:13.806975Z","iopub.status.idle":"2021-09-23T07:18:13.811857Z","shell.execute_reply.started":"2021-09-23T07:18:13.806939Z","shell.execute_reply":"2021-09-23T07:18:13.811171Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Number of tokens in vocabulary: 155\n","output_type":"stream"}]},{"cell_type":"code","source":"print(vocab.stoi) # token and its corresponding index","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.813127Z","iopub.execute_input":"2021-09-23T07:18:13.813528Z","iopub.status.idle":"2021-09-23T07:18:13.825140Z","shell.execute_reply.started":"2021-09-23T07:18:13.813494Z","shell.execute_reply":"2021-09-23T07:18:13.824239Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"{'<UNK>': 0, '<PAD>': 1, '<SOS>': 2, '<EOS>': 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'j': 13, 'k': 14, 'l': 15, 'm': 16, 'n': 17, 'o': 18, 'p': 19, 'q': 20, 'r': 21, 's': 22, 't': 23, 'u': 24, 'v': 25, 'w': 26, 'x': 27, 'y': 28, 'z': 29, 'sub': 30, 'func1': 31, 'func2': 32, 'def': 33, 'add': 34, '(': 35, ':': 36, 'int': 37, ',': 38, ')': 39, '->': 40, '\\n': 41, '': 42, '=': 43, '+': 44, 'return': 45, '{': 46, ';': 47, '}': 48, 'float': 49, 'subtract': 50, '-': 51, 'multiply': 52, 'int)': 53, '*': 54, 'divide': 55, '/': 56, 'func': 57, '**': 58, 'pow': 59, 'if': 60, '>': 61, 'else': 62, '<': 63, 'and': 64, 'elif': 65, 'str': 66, '0': 67, '\"': 68, 'N': 69, 'P': 70, '\"Zero\"': 71, 'string': 72, '\"Negative\"': 73, '\"Positive\"': 74, '%': 75, '5': 76, '==': 77, '11': 78, '1': 79, '2': 80, '4': 81, '100': 82, '!=': 83, 'or': 84, '400': 85, \"'a'\": 86, \"'e'\": 87, \"'i'\": 88, \"'o'\": 89, \"'u'\": 90, \"'A'\": 91, \"'E'\": 92, \"'I'\": 93, \"'O'\": 94, \"'U'\": 95, 'char': 96, '3': 97, '8': 98, '6': 99, '7': 100, '9': 101, '10': 102, '12': 103, '-1': 104, '31': 105, '28': 106, '30': 107, 'sum': 108, '180': 109, 'cp': 110, 'sp': 111, 'profit': 112, 'loss': 113, 'for': 114, 'in': 115, 'range': 116, 'print': 117, 'void': 118, '++': 119, 'cout': 120, '<<': 121, 'endl': 122, '+=': 123, 'while': 124, '//': 125, 'prod': 126, '*=': 127, 'rev': 128, '<=': 129, 'isprime': 130, '2,': 131, '3,': 132, 'sz': 133, 'len': 134, 's[i]': 135, \"'1'\": 136, '.size()': 137, 'ans': 138, '>=': 139, \"'z'\": 140, 'reversed': 141, '[': 142, ']': 143, '\"\"': 144, '--': 145, 'arr': 146, 'list': 147, '[i]': 148, 'vector<int>': 149, 'INT_MIN': 150, 'INT_MAX': 151, 'max1': 152, 'max2': 153, 'mid': 154}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(vocab.itos) # index and its corresponding token","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.826924Z","iopub.execute_input":"2021-09-23T07:18:13.827184Z","iopub.status.idle":"2021-09-23T07:18:13.834398Z","shell.execute_reply.started":"2021-09-23T07:18:13.827150Z","shell.execute_reply":"2021-09-23T07:18:13.833581Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"{0: '<UNK>', 1: '<PAD>', 2: '<SOS>', 3: '<EOS>', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z', 30: 'sub', 31: 'func1', 32: 'func2', 33: 'def', 34: 'add', 35: '(', 36: ':', 37: 'int', 38: ',', 39: ')', 40: '->', 41: '\\n', 42: '', 43: '=', 44: '+', 45: 'return', 46: '{', 47: ';', 48: '}', 49: 'float', 50: 'subtract', 51: '-', 52: 'multiply', 53: 'int)', 54: '*', 55: 'divide', 56: '/', 57: 'func', 58: '**', 59: 'pow', 60: 'if', 61: '>', 62: 'else', 63: '<', 64: 'and', 65: 'elif', 66: 'str', 67: '0', 68: '\"', 69: 'N', 70: 'P', 71: '\"Zero\"', 72: 'string', 73: '\"Negative\"', 74: '\"Positive\"', 75: '%', 76: '5', 77: '==', 78: '11', 79: '1', 80: '2', 81: '4', 82: '100', 83: '!=', 84: 'or', 85: '400', 86: \"'a'\", 87: \"'e'\", 88: \"'i'\", 89: \"'o'\", 90: \"'u'\", 91: \"'A'\", 92: \"'E'\", 93: \"'I'\", 94: \"'O'\", 95: \"'U'\", 96: 'char', 97: '3', 98: '8', 99: '6', 100: '7', 101: '9', 102: '10', 103: '12', 104: '-1', 105: '31', 106: '28', 107: '30', 108: 'sum', 109: '180', 110: 'cp', 111: 'sp', 112: 'profit', 113: 'loss', 114: 'for', 115: 'in', 116: 'range', 117: 'print', 118: 'void', 119: '++', 120: 'cout', 121: '<<', 122: 'endl', 123: '+=', 124: 'while', 125: '//', 126: 'prod', 127: '*=', 128: 'rev', 129: '<=', 130: 'isprime', 131: '2,', 132: '3,', 133: 'sz', 134: 'len', 135: 's[i]', 136: \"'1'\", 137: '.size()', 138: 'ans', 139: '>=', 140: \"'z'\", 141: 'reversed', 142: '[', 143: ']', 144: '\"\"', 145: '--', 146: 'arr', 147: 'list', 148: '[i]', 149: 'vector<int>', 150: 'INT_MIN', 151: 'INT_MAX', 152: 'max1', 153: 'max2', 154: 'mid'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create Custom Dataset","metadata":{}},{"cell_type":"code","source":"class TransCompilerDataset(Dataset):\n    def __init__(self, py_dir, cpp_dir, vocab):\n        self.py_dir = py_dir\n        self.cpp_dir = cpp_dir\n        self.vocab = vocab\n    \n    def __len__(self):\n        return len(os.listdir(self.py_dir))\n    \n    def __getitem__(self, index):\n        py_file = os.path.join(self.py_dir, f'p_{index+1}.txt')\n        cpp_file = os.path.join(self.cpp_dir, f'c_{index+1}.txt')\n        \n        with open (py_file, 'r') as f:\n            py_txt = f.read()\n        \n        with open (cpp_file, 'r') as f:\n            cpp_txt = f.read()\n        \n        py_encoded = vocab.encode(py_txt)\n        cpp_encoded = vocab.encode(cpp_txt)\n        \n        return torch.tensor(py_encoded), torch.tensor(cpp_encoded)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.969386Z","iopub.execute_input":"2021-09-23T07:18:13.969599Z","iopub.status.idle":"2021-09-23T07:18:13.979298Z","shell.execute_reply.started":"2021-09-23T07:18:13.969574Z","shell.execute_reply":"2021-09-23T07:18:13.978545Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class Collate():\n    def __init__(self, pad_idx):\n        self.pad_idx = pad_idx\n    \n    def __call__(self, batch):\n        (py, cpp) = zip(*batch)\n        \n        py_pad = pad_sequence(py, batch_first=True, padding_value=self.pad_idx)\n        cpp_pad = pad_sequence(cpp, batch_first=True, padding_value=self.pad_idx)\n        return py_pad, cpp_pad","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.101556Z","iopub.execute_input":"2021-09-23T07:18:14.101774Z","iopub.status.idle":"2021-09-23T07:18:14.107419Z","shell.execute_reply.started":"2021-09-23T07:18:14.101749Z","shell.execute_reply":"2021-09-23T07:18:14.106747Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def get_loaders(train_py_dir, train_cpp_dir, val_py_dir, val_cpp_dir, vocab):\n    train_dataset = TransCompilerDataset(train_py_dir, train_cpp_dir, vocab)\n    val_dataset = TransCompilerDataset(val_py_dir, val_cpp_dir, vocab)\n    pad_idx = vocab.stoi['<PAD>']\n    train_loader = DataLoader(train_dataset, batch_size = 10, shuffle=True, collate_fn=Collate(pad_idx))\n    val_loader = DataLoader(val_dataset, batch_size = 10, shuffle=True, collate_fn=Collate(pad_idx))\n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.121610Z","iopub.execute_input":"2021-09-23T07:18:14.122081Z","iopub.status.idle":"2021-09-23T07:18:14.126881Z","shell.execute_reply.started":"2021-09-23T07:18:14.122052Z","shell.execute_reply":"2021-09-23T07:18:14.126199Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train_loader, val_loader = get_loaders(train_py_dir, train_cpp_dir, val_py_dir, val_cpp_dir, vocab)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.228063Z","iopub.execute_input":"2021-09-23T07:18:14.228530Z","iopub.status.idle":"2021-09-23T07:18:14.237207Z","shell.execute_reply.started":"2021-09-23T07:18:14.228502Z","shell.execute_reply":"2021-09-23T07:18:14.236475Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(len(train_loader))\nprint(len(val_loader))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.286562Z","iopub.execute_input":"2021-09-23T07:18:14.286747Z","iopub.status.idle":"2021-09-23T07:18:14.292197Z","shell.execute_reply.started":"2021-09-23T07:18:14.286726Z","shell.execute_reply":"2021-09-23T07:18:14.291457Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"6\n2\n","output_type":"stream"}]},{"cell_type":"code","source":"for idx, (py, cpp) in enumerate(train_loader):\n    print(f'Shape of py: {py.shape}')      # batch_size x src_seq_len\n    print(f'Shape of cpp: {cpp.shape}')    # batch_size x trg_seq_len\n    break","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.396884Z","iopub.execute_input":"2021-09-23T07:18:14.397490Z","iopub.status.idle":"2021-09-23T07:18:14.441569Z","shell.execute_reply.started":"2021-09-23T07:18:14.397458Z","shell.execute_reply":"2021-09-23T07:18:14.440738Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Shape of py: torch.Size([10, 127])\nShape of cpp: torch.Size([10, 161])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ready to build transformer architecture!!!","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.450994Z","iopub.execute_input":"2021-09-23T07:18:14.451179Z","iopub.status.idle":"2021-09-23T07:18:14.454570Z","shell.execute_reply.started":"2021-09-23T07:18:14.451158Z","shell.execute_reply":"2021-09-23T07:18:14.453665Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Building Transformer Architecture","metadata":{}},{"cell_type":"markdown","source":"#### Building Attention Mechanism","metadata":{}},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def __init__(self, embed_size, heads):\n        super(SelfAttention, self).__init__()\n        self.embed_size = embed_size\n        self.heads = heads\n        self.head_dim = embed_size // heads\n\n        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        \n        self.fc_out = nn.Linear(self.head_dim * self.heads, embed_size)   # concatenating heads\n        \n    def forward(self, queries, keys, values, mask):\n        # queries, keys, values => shape (N, seq_len, embed_size)\n        # mask => shape (N, 1, 1, src_seq_len)\n        N = queries.shape[0] # N = Batch_size\n        query_len, key_len, value_len = queries.shape[1], keys.shape[1], values.shape[1]   # same as seq length\n        \n        # splitting embedding into heads\n        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n        values = values.reshape(N, value_len, self.heads, self.head_dim)\n        \n        \n        # Step 1: Create query, key, value matrices (for each head)\n        queries = self.queries(queries) # (N, query_len, heads, head_dim)\n        keys = self.queries(keys)       # (N, key_len, heads, head_dim)\n        values = self.queries(values)   # (N, value_len, heads, head_dim) \n        \n        # Step 2: Calculate the scores for each tokens against all tokens (dot query and key)\n        query_key_score = torch.einsum(\"nqhd, nkhd -> nhqk\", [queries, keys])   # (N, heads, query_len, key_len)\n        \n        # Step 2.1 : If mask is set (needed in decoder), then mask upper right triangle matrix with negative infiniy\n        if mask is not None:\n            query_key_score = query_key_score.masked_fill(mask == 0, float('-1e20'))\n        \n        # Step 3: Calculate softmax score\n        softmax_score = torch.softmax(query_key_score / (self.embed_size ** 0.5), dim=3) # (N, heads, query_len, key_len)\n        \n        # Step 4: Calculate weighted values\n        attention = torch.einsum(\"nhql, nvhd -> nqhd\", [softmax_score, values])   # (N, query_len, heads, head_dim)\n        attention = attention.reshape(N, query_len, self.head_dim * self.heads) # (N, query_len ,embed_size)\n        \n        # Step 5: Concatenating heads\n        out = self.fc_out(attention)\n        return out     # (N, query_len, embed_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.744168Z","iopub.execute_input":"2021-09-23T07:18:14.744574Z","iopub.status.idle":"2021-09-23T07:18:14.757905Z","shell.execute_reply.started":"2021-09-23T07:18:14.744542Z","shell.execute_reply":"2021-09-23T07:18:14.757148Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Testing self attention\nattention = SelfAttention(512, 8)\nq = torch.randn(5, 100, 512)\nk = torch.randn(5, 100, 512)\nv = torch.randn(5, 100, 512)\nm = torch.randn(5, 1, 100, 100)\nout = attention(q,k,v,m)\nprint(out.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.788610Z","iopub.execute_input":"2021-09-23T07:18:14.788818Z","iopub.status.idle":"2021-09-23T07:18:14.864829Z","shell.execute_reply.started":"2021-09-23T07:18:14.788779Z","shell.execute_reply":"2021-09-23T07:18:14.864059Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"torch.Size([5, 100, 512])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Building Transformer Block","metadata":{}},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, embed_size, heads, forward_expansion, dropout=0.5):\n        super(TransformerBlock, self).__init__()\n        self.attention = SelfAttention(embed_size, heads)\n        self.layer_norm1 = nn.LayerNorm(embed_size)\n        self.layer_norm2 = nn.LayerNorm(embed_size)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(embed_size, forward_expansion * embed_size),\n            nn.ReLU(),\n            nn.Linear(forward_expansion * embed_size, embed_size)\n        )\n        \n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, query, key, value, mask):\n        attention = self.attention(query, key, value, mask)\n        \n        # Step1: Skip connection\n        x = attention + query\n        \n        # Step2: Layer norm\n        x = self.layer_norm1(x)\n        \n        # Step3: Dropout\n        x = self.dropout(x)\n        \n        # Step4: Feed forward\n        forward = self.feed_forward(x)\n        \n        # Step5: Same as above from step 1 to step 3\n        out = self.dropout(self.layer_norm2(forward + x))\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.955409Z","iopub.execute_input":"2021-09-23T07:18:14.955941Z","iopub.status.idle":"2021-09-23T07:18:14.966004Z","shell.execute_reply.started":"2021-09-23T07:18:14.955910Z","shell.execute_reply":"2021-09-23T07:18:14.965237Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"#### Building Encoder Architecture (stacking Transformer Blocks)\n","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, vocab_size, embed_size, num_layers, heads, device, forward_expansion, max_len, drop=0.5):\n        super(Encoder, self).__init__()\n        self.embed_size = embed_size\n        self.device = device\n        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n        self.pos_embedding = nn.Embedding(max_len, embed_size)\n        self.dropout = nn.Dropout(drop)\n        \n        self.layers = nn.ModuleList(\n            [\n                TransformerBlock(embed_size, heads, forward_expansion, drop)\n                for _ in range(num_layers)\n            ]\n        )\n        \n    def forward(self, x, mask):\n        # Shape of x : (batch_size x src_seq_len)\n        # shape of mask: (batch_size, 1, 1, src_seq_len)\n        batch_size, seq_len = x.shape\n        positions = torch.arange(0, seq_len).expand(batch_size, seq_len).to(self.device)\n        out = self.word_embedding(x) + self.pos_embedding(positions)\n        out = self.dropout(out)     # (N, src_seq_len, embed_size)\n        \n        \n        for layer in self.layers:\n            # query, key, value inputs are same for each transformer block from\n            # their previous transformer block, except in the beginning that is positional encodings\n            out = layer(out, out, out, mask)\n        return out      # (N, src_seq_len, embed_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.177531Z","iopub.execute_input":"2021-09-23T07:18:15.178036Z","iopub.status.idle":"2021-09-23T07:18:15.188260Z","shell.execute_reply.started":"2021-09-23T07:18:15.178001Z","shell.execute_reply":"2021-09-23T07:18:15.187349Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"#### Building Decoder Architecture","metadata":{}},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, embed_size ,heads, forward_expansion, device, drop=0.5):\n        super(DecoderBlock, self).__init__()\n        self.norm = nn.LayerNorm(embed_size)\n        self.attention = SelfAttention(embed_size ,heads)\n        self.transformer_block = TransformerBlock(embed_size, heads, forward_expansion, drop)\n        self.dropout = nn.Dropout(drop)\n    \n    def forward(self, x, value, key, src_mask, trg_mask):\n        attention = self.attention(x,x,x,trg_mask)\n        query = self.dropout(self.norm(attention + x))\n        out = self.transformer_block(query, key, value, src_mask)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.285973Z","iopub.execute_input":"2021-09-23T07:18:15.286542Z","iopub.status.idle":"2021-09-23T07:18:15.293692Z","shell.execute_reply.started":"2021-09-23T07:18:15.286510Z","shell.execute_reply":"2021-09-23T07:18:15.292762Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, vocab_size, embed_size, num_layers, heads, device, forward_expansion, max_len, drop=0.5,):\n        super(Decoder, self).__init__()\n        self.device = device\n        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n        self.pos_embedding = nn.Embedding(max_len, embed_size)\n        \n        self.layers = nn.ModuleList(\n            [\n                DecoderBlock(embed_size, heads, forward_expansion, device, drop)\n                for _ in range(num_layers)\n            ]\n        )\n        \n        self.fc_out = nn.Linear(embed_size, vocab_size)\n        self.dropout = nn.Dropout(drop)\n    \n    def forward(self, x, enc_out, src_mask, trg_mask):\n        # enc_out => shape (N, src_seq_len, embed_size)\n        # src_mask => shape (N, 1, 1, seq_len)\n        # trg_mask => shape (N, 1, seq_len, seq_len)\n        batch_size, seq_len = x.shape\n        positions = torch.arange(0, seq_len).expand(batch_size, seq_len).to(self.device)\n        x = self.dropout(self.word_embedding(x) + self.pos_embedding(positions))\n        value = enc_out\n        key = enc_out\n        for layer in self.layers:\n            x = layer(x, value, key, src_mask, trg_mask)\n        \n        out = self.fc_out(x)\n        return out   # (N, trg_len, vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.380241Z","iopub.execute_input":"2021-09-23T07:18:15.380793Z","iopub.status.idle":"2021-09-23T07:18:15.391224Z","shell.execute_reply.started":"2021-09-23T07:18:15.380762Z","shell.execute_reply":"2021-09-23T07:18:15.390549Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"#### Putting it all together","metadata":{}},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, vocab_size, pad_idx, embed_size=512, num_layers=6, forward_expansion=4, heads=8, dropout=0, device=\"cpu\", max_len=350):\n        super(Transformer, self).__init__()\n        \n        self.encoder = Encoder(vocab_size, embed_size, num_layers, heads, device, forward_expansion, max_len ,dropout)\n        self.decoder = Decoder(vocab_size ,embed_size, num_layers, heads, device, forward_expansion, max_len, dropout)\n        self.pad_idx = pad_idx\n        self.device = device\n    \n    def make_src_mask(self, src):\n        # shape of src : (N, seq_len)\n        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)\n        return src_mask.to(self.device)\n\n    def make_trg_mask(self, trg):\n        # shape of trg: (N, seq_len)\n        batch_size, seq_len = trg.shape\n        # fill lower triangular matrix\n        trg_mask = torch.tril(torch.ones((seq_len, seq_len))).expand(batch_size, 1, seq_len, seq_len)\n        return trg_mask.to(device)\n\n    def forward(self, src, trg):\n        # Shape of src: (batch_size x src_seq_len)\n        # Shape of trg: (batch_size x trg_seq_len)\n        src_mask = self.make_src_mask(src)\n        trg_mask = self.make_trg_mask(trg)\n        enc_out = self.encoder(src, src_mask)\n        out = self.decoder(trg, enc_out, src_mask, trg_mask)\n        return out  # (batch_size x trg_seq_len x vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.534902Z","iopub.execute_input":"2021-09-23T07:18:15.535470Z","iopub.status.idle":"2021-09-23T07:18:15.546878Z","shell.execute_reply.started":"2021-09-23T07:18:15.535439Z","shell.execute_reply":"2021-09-23T07:18:15.546072Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"#### Testing Transformer Architecture","metadata":{}},{"cell_type":"code","source":"# Setting device to cuda if available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.709630Z","iopub.execute_input":"2021-09-23T07:18:15.709898Z","iopub.status.idle":"2021-09-23T07:18:15.767579Z","shell.execute_reply.started":"2021-09-23T07:18:15.709854Z","shell.execute_reply":"2021-09-23T07:18:15.766712Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 5\nsrc_seq_len = 100\ntrg_seq_len = 150\npad_idx = 0\nvocab_size = 10\n\nx = torch.randint(0, vocab_size, (batch_size, src_seq_len)).to(device)\ntrg = torch.randint(0, vocab_size, (batch_size, trg_seq_len)).to(device)\nmodel = Transformer(vocab_size, pad_idx, device=device).to(device)\nout = model(x, trg[:, :-1])\nprint(out.shape)   # (batch_size, (trg_seq_len-1), vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.801489Z","iopub.execute_input":"2021-09-23T07:18:15.802065Z","iopub.status.idle":"2021-09-23T07:18:20.951444Z","shell.execute_reply.started":"2021-09-23T07:18:15.802034Z","shell.execute_reply":"2021-09-23T07:18:20.950561Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"torch.Size([5, 149, 10])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"vocab_size = len(vocab.stoi)\nembed_size = 256\nnum_layers = 6\nheads = 8\nforward_expansion = 4\ndropout = 0.2\nmax_len = 250\npad_idx = vocab.stoi['<PAD>']\nlr = 3e-5\nepochs = 100","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:20.953163Z","iopub.execute_input":"2021-09-23T07:18:20.953622Z","iopub.status.idle":"2021-09-23T07:18:20.958713Z","shell.execute_reply.started":"2021-09-23T07:18:20.953584Z","shell.execute_reply":"2021-09-23T07:18:20.957824Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"# Function to plot loss\ndef plot_loss(loss,epochs,val_loss=None):\n    plt.title('Plot of training loss')\n    plt.plot(loss, c='r', label='training_loss')\n    if val_loss is not None:\n        plt.plot(val_loss, c='g', label='validation_loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig(f'loss.png')\n    plt.show()\n    \n# Function to save checkpoint\ndef save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n\n\n# Function to load checkpoint\ndef load_checkpoint(checkpoint, model, optimizer):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    \n    \n# Function to convert tokens to code\ndef get_code(vocab, tokens):\n    tok_list = []\n    for tok in tokens:\n        if tok == vocab.stoi[\"<SOS>\"] or tok == vocab.stoi[\"<EOS>\"]:\n            continue\n        tok_list.append(vocab.itos[tok])\n    return ' '.join(tok_list)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:20.960282Z","iopub.execute_input":"2021-09-23T07:18:20.960852Z","iopub.status.idle":"2021-09-23T07:18:20.975852Z","shell.execute_reply.started":"2021-09-23T07:18:20.960684Z","shell.execute_reply":"2021-09-23T07:18:20.975194Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## Instantiating model","metadata":{}},{"cell_type":"code","source":"model_cpp = Transformer(vocab_size = vocab_size, \n                    pad_idx = pad_idx,\n                    embed_size = embed_size,\n                    num_layers = num_layers,\n                    forward_expansion = forward_expansion,\n                    heads = heads,\n                    max_len = max_len,\n                    dropout = dropout,\n                    device=device).to(device)\nmodel_py = Transformer(vocab_size = vocab_size, \n                    pad_idx = pad_idx,\n                    embed_size = embed_size,\n                    num_layers = num_layers,\n                    forward_expansion = forward_expansion,\n                    heads = heads,\n                    max_len = max_len,\n                    dropout = dropout,\n                    device=device).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:20.977904Z","iopub.execute_input":"2021-09-23T07:18:20.978187Z","iopub.status.idle":"2021-09-23T07:18:21.150932Z","shell.execute_reply.started":"2021-09-23T07:18:20.978153Z","shell.execute_reply":"2021-09-23T07:18:21.150119Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## Defining loss function and optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n# optimizer_cpp = optim.SGD(model_cpp.parameters(), lr=lr)\n# optimizer_py = optim.SGD(model_py.parameters(), lr=lr)\n\noptimizer_cpp = optim.Adam(model_cpp.parameters(), lr=lr, betas=(0.9, 0.99))\noptimizer_py = optim.Adam(model_py.parameters(), lr=lr, betas=(0.9, 0.99))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:21.152572Z","iopub.execute_input":"2021-09-23T07:18:21.152981Z","iopub.status.idle":"2021-09-23T07:18:21.165038Z","shell.execute_reply.started":"2021-09-23T07:18:21.152945Z","shell.execute_reply":"2021-09-23T07:18:21.164181Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"def train():\n\n    train_loss = []\n    val_loss = []\n    best_val_loss = np.inf\n    \n    for epoch in range(1, epochs+1):\n        model.train()\n        losses = []\n        for batch_idx, (py_src, cpp_trg) in enumerate(train_loader):\n            # Put on cuda if available\n            py_src = py_src.to(device)   # (batch_size, src_seq_len)\n            cpp_trg = cpp_trg.to(device)\n            \n            # Forward pass\n            output_cpp = model_cpp(py_src, cpp_trg[:, :-1])  # shape (batch_size, (tgr_seq_len-1), vocab_size)\n            \n            out_cpp = output_cpp.reshape(-1, vocab_size)  # [batch_size * (trg_seq_len-1), vocab_size]\n            target = cpp_trg[:, 1:]  # (batch_size, trg_seq_len - 1)\n            target = target.reshape(-1)    # [batch_size x (trg_seq_len - 1)]\n            \n            loss_cpp = criterion(out_cpp, target)\n            \n            output_py = model_py(cpp_trg, py_src[:, :-1])\n            out_py = output_py.reshape(-1, vocab_size)\n            target = py_src[:, 1:]\n            target = target.reshape(-1)\n            \n            loss_py = criterion(out_py, target)\n            \n            \n            # Cycle consistency\n            \n            ## generated_cpp to reconstruct_python code\n            gen_cpp = torch.full((output_cpp.shape[0],output_cpp.shape[1]+1), vocab.stoi[\"<SOS>\"]).to(device)\n            gen_cpp[:, 1:] = output_cpp.argmax(2)\n            gen_cpp[:, -1] = vocab.stoi[\"<EOS>\"]\n            \n            rec_py = model_py(gen_cpp, py_src[:, :-1])\n            rec_py = rec_py.reshape(-1, vocab_size)\n            target = py_src[:, 1:]\n            target = target.reshape(-1)\n            \n            loss_rec_py = criterion(rec_py, target)\n            \n            ## generated_py to reconstruct_cpp code\n            gen_py = torch.full((output_py.shape[0],output_py.shape[1]+1), vocab.stoi[\"<SOS>\"]).to(device)\n            gen_py[:, 1:] = output_py.argmax(2)\n            gen_py[:, -1] = vocab.stoi[\"<EOS>\"]\n            \n            rec_cpp = model_py(gen_py, cpp_trg[:, :-1])\n            rec_cpp = rec_cpp.reshape(-1, vocab_size)\n            target = cpp_trg[:, 1:]\n            target = target.reshape(-1)\n            \n            loss_rec_cpp = criterion(rec_cpp, target)\n            \n            loss =  0.25 * ( loss_cpp + loss_py + loss_rec_py + loss_rec_cpp )\n            \n            losses.append(loss.item())\n            \n            # Clear the gradients\n            optimizer_cpp.zero_grad()\n            optimizer_py.zero_grad()\n            \n            # Backward pass\n            loss.backward()\n            optimizer_cpp.step()\n            optimizer_py.step()\n        \n        mean_train_loss = sum(losses) / len(losses)\n        train_loss.append(mean_train_loss)\n      \n        model.eval()\n        losses = []\n        for batch_idx, (py, cpp) in enumerate(val_loader):\n            py = py.to(device)\n            cpp = cpp.to(device)\n\n            output = model_cpp(py, cpp[:, :-1])\n\n            output = output.reshape(-1, vocab_size)  # [batch_size * (trg_seq_len-1), vocab_size]\n            target = cpp[:, 1:]  # (batch_size, trg_seq_len - 1)\n            target = target.reshape(-1)    # [batch_size x (trg_seq_len - 1)]\n\n            # Calculate loss\n            loss = criterion(output, target)\n            losses.append(loss.item())\n        mean_val_loss = sum(losses) / len(losses)\n        val_loss.append(mean_val_loss)\n        \n        print(f'Epoch: {epoch}/{epochs}\\tTraining Loss: {mean_train_loss:.6f}\\tValidation Loss: {mean_val_loss:.6f}')\n        \n        if mean_val_loss < best_val_loss:\n            print('Validation loss decreased. Saving model params...')\n            best_val_loss = mean_val_loss\n            checkpoint = {\n                \"state_dict\": model_cpp.state_dict(),\n                \"optimizer\": optimizer_cpp.state_dict(),\n            }\n            save_checkpoint(checkpoint)\n        \n    return train_loss, val_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:21.166298Z","iopub.execute_input":"2021-09-23T07:18:21.166550Z","iopub.status.idle":"2021-09-23T07:18:21.187789Z","shell.execute_reply.started":"2021-09-23T07:18:21.166516Z","shell.execute_reply":"2021-09-23T07:18:21.187132Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"train_loss, val_loss = train()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:21.189065Z","iopub.execute_input":"2021-09-23T07:18:21.189315Z","iopub.status.idle":"2021-09-23T07:21:14.727670Z","shell.execute_reply.started":"2021-09-23T07:18:21.189280Z","shell.execute_reply":"2021-09-23T07:21:14.726928Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Epoch: 1/100\tTraining Loss: 4.701959\tValidation Loss: 4.045337\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 2/100\tTraining Loss: 3.994806\tValidation Loss: 3.765424\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 3/100\tTraining Loss: 3.760471\tValidation Loss: 3.691013\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 4/100\tTraining Loss: 3.645073\tValidation Loss: 3.512170\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 5/100\tTraining Loss: 3.565485\tValidation Loss: 3.534410\nEpoch: 6/100\tTraining Loss: 3.488753\tValidation Loss: 3.414297\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 7/100\tTraining Loss: 3.443183\tValidation Loss: 3.374536\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 8/100\tTraining Loss: 3.418345\tValidation Loss: 3.345180\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 9/100\tTraining Loss: 3.397480\tValidation Loss: 3.309568\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 10/100\tTraining Loss: 3.360681\tValidation Loss: 3.273800\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 11/100\tTraining Loss: 3.340515\tValidation Loss: 3.392527\nEpoch: 12/100\tTraining Loss: 3.323033\tValidation Loss: 3.268075\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 13/100\tTraining Loss: 3.315330\tValidation Loss: 3.431244\nEpoch: 14/100\tTraining Loss: 3.292689\tValidation Loss: 3.380516\nEpoch: 15/100\tTraining Loss: 3.275298\tValidation Loss: 3.233695\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 16/100\tTraining Loss: 3.270012\tValidation Loss: 3.221387\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 17/100\tTraining Loss: 3.265890\tValidation Loss: 3.234456\nEpoch: 18/100\tTraining Loss: 3.253778\tValidation Loss: 3.257943\nEpoch: 19/100\tTraining Loss: 3.251763\tValidation Loss: 3.181996\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 20/100\tTraining Loss: 3.235184\tValidation Loss: 3.187464\nEpoch: 21/100\tTraining Loss: 3.221536\tValidation Loss: 3.215098\nEpoch: 22/100\tTraining Loss: 3.219894\tValidation Loss: 3.162821\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 23/100\tTraining Loss: 3.218771\tValidation Loss: 3.145967\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 24/100\tTraining Loss: 3.205667\tValidation Loss: 3.157132\nEpoch: 25/100\tTraining Loss: 3.193656\tValidation Loss: 3.154829\nEpoch: 26/100\tTraining Loss: 3.201309\tValidation Loss: 3.112056\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 27/100\tTraining Loss: 3.190309\tValidation Loss: 3.115374\nEpoch: 28/100\tTraining Loss: 3.177439\tValidation Loss: 3.211689\nEpoch: 29/100\tTraining Loss: 3.172401\tValidation Loss: 3.188618\nEpoch: 30/100\tTraining Loss: 3.170171\tValidation Loss: 3.117720\nEpoch: 31/100\tTraining Loss: 3.172375\tValidation Loss: 3.131249\nEpoch: 32/100\tTraining Loss: 3.167537\tValidation Loss: 3.118294\nEpoch: 33/100\tTraining Loss: 3.156523\tValidation Loss: 3.110971\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 34/100\tTraining Loss: 3.156806\tValidation Loss: 3.107614\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 35/100\tTraining Loss: 3.143116\tValidation Loss: 3.105234\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 36/100\tTraining Loss: 3.140757\tValidation Loss: 3.138939\nEpoch: 37/100\tTraining Loss: 3.140108\tValidation Loss: 3.082383\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 38/100\tTraining Loss: 3.132576\tValidation Loss: 3.059966\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 39/100\tTraining Loss: 3.134506\tValidation Loss: 3.052906\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 40/100\tTraining Loss: 3.123811\tValidation Loss: 3.056670\nEpoch: 41/100\tTraining Loss: 3.135442\tValidation Loss: 3.043932\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 42/100\tTraining Loss: 3.132437\tValidation Loss: 3.047607\nEpoch: 43/100\tTraining Loss: 3.122098\tValidation Loss: 3.144923\nEpoch: 44/100\tTraining Loss: 3.128325\tValidation Loss: 3.053140\nEpoch: 45/100\tTraining Loss: 3.114443\tValidation Loss: 3.118932\nEpoch: 46/100\tTraining Loss: 3.119099\tValidation Loss: 3.041655\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 47/100\tTraining Loss: 3.109410\tValidation Loss: 3.057921\nEpoch: 48/100\tTraining Loss: 3.116052\tValidation Loss: 3.043465\nEpoch: 49/100\tTraining Loss: 3.109383\tValidation Loss: 3.057691\nEpoch: 50/100\tTraining Loss: 3.110011\tValidation Loss: 3.054545\nEpoch: 51/100\tTraining Loss: 3.103045\tValidation Loss: 3.007002\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 52/100\tTraining Loss: 3.097677\tValidation Loss: 3.003575\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 53/100\tTraining Loss: 3.092454\tValidation Loss: 3.044191\nEpoch: 54/100\tTraining Loss: 3.105078\tValidation Loss: 3.026888\nEpoch: 55/100\tTraining Loss: 3.094534\tValidation Loss: 3.025787\nEpoch: 56/100\tTraining Loss: 3.089665\tValidation Loss: 3.036455\nEpoch: 57/100\tTraining Loss: 3.082224\tValidation Loss: 2.986790\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 58/100\tTraining Loss: 3.076370\tValidation Loss: 2.969306\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 59/100\tTraining Loss: 3.092607\tValidation Loss: 3.025876\nEpoch: 60/100\tTraining Loss: 3.086513\tValidation Loss: 3.014433\nEpoch: 61/100\tTraining Loss: 3.081985\tValidation Loss: 3.065991\nEpoch: 62/100\tTraining Loss: 3.080152\tValidation Loss: 2.998190\nEpoch: 63/100\tTraining Loss: 3.075248\tValidation Loss: 2.973517\nEpoch: 64/100\tTraining Loss: 3.090120\tValidation Loss: 3.005113\nEpoch: 65/100\tTraining Loss: 3.066145\tValidation Loss: 2.976286\nEpoch: 66/100\tTraining Loss: 3.071628\tValidation Loss: 2.957704\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 67/100\tTraining Loss: 3.073369\tValidation Loss: 2.970931\nEpoch: 68/100\tTraining Loss: 3.065419\tValidation Loss: 2.975550\nEpoch: 69/100\tTraining Loss: 3.059620\tValidation Loss: 2.982252\nEpoch: 70/100\tTraining Loss: 3.062096\tValidation Loss: 2.921897\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 71/100\tTraining Loss: 3.057503\tValidation Loss: 2.985031\nEpoch: 72/100\tTraining Loss: 3.066173\tValidation Loss: 2.923583\nEpoch: 73/100\tTraining Loss: 3.057840\tValidation Loss: 2.971003\nEpoch: 74/100\tTraining Loss: 3.043732\tValidation Loss: 2.926281\nEpoch: 75/100\tTraining Loss: 3.048478\tValidation Loss: 2.928442\nEpoch: 76/100\tTraining Loss: 3.048902\tValidation Loss: 2.942516\nEpoch: 77/100\tTraining Loss: 3.048909\tValidation Loss: 2.972027\nEpoch: 78/100\tTraining Loss: 3.047345\tValidation Loss: 2.938440\nEpoch: 79/100\tTraining Loss: 3.045992\tValidation Loss: 2.911409\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 80/100\tTraining Loss: 3.044233\tValidation Loss: 2.938245\nEpoch: 81/100\tTraining Loss: 3.047583\tValidation Loss: 2.946246\nEpoch: 82/100\tTraining Loss: 3.039063\tValidation Loss: 2.926231\nEpoch: 83/100\tTraining Loss: 3.042101\tValidation Loss: 2.908541\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 84/100\tTraining Loss: 3.032072\tValidation Loss: 2.915973\nEpoch: 85/100\tTraining Loss: 3.035380\tValidation Loss: 2.923483\nEpoch: 86/100\tTraining Loss: 3.042073\tValidation Loss: 2.913404\nEpoch: 87/100\tTraining Loss: 3.037205\tValidation Loss: 2.984391\nEpoch: 88/100\tTraining Loss: 3.038608\tValidation Loss: 2.998117\nEpoch: 89/100\tTraining Loss: 3.034586\tValidation Loss: 2.910385\nEpoch: 90/100\tTraining Loss: 3.034225\tValidation Loss: 2.958339\nEpoch: 91/100\tTraining Loss: 3.031732\tValidation Loss: 2.952806\nEpoch: 92/100\tTraining Loss: 3.034005\tValidation Loss: 2.940041\nEpoch: 93/100\tTraining Loss: 3.033499\tValidation Loss: 2.962878\nEpoch: 94/100\tTraining Loss: 3.033030\tValidation Loss: 2.901247\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 95/100\tTraining Loss: 3.018189\tValidation Loss: 2.935611\nEpoch: 96/100\tTraining Loss: 3.026623\tValidation Loss: 2.957856\nEpoch: 97/100\tTraining Loss: 3.026724\tValidation Loss: 2.927479\nEpoch: 98/100\tTraining Loss: 3.020152\tValidation Loss: 2.955171\nEpoch: 99/100\tTraining Loss: 3.023009\tValidation Loss: 2.901608\nEpoch: 100/100\tTraining Loss: 3.035466\tValidation Loss: 2.896305\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_loss(train_loss, epochs, val_loss)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:21:35.621863Z","iopub.execute_input":"2021-09-23T07:21:35.622413Z","iopub.status.idle":"2021-09-23T07:21:35.912929Z","shell.execute_reply.started":"2021-09-23T07:21:35.622376Z","shell.execute_reply":"2021-09-23T07:21:35.912236Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"### Load best model","metadata":{}},{"cell_type":"code","source":"load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model_cpp, optimizer_cpp)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:21:46.814227Z","iopub.execute_input":"2021-09-23T07:21:46.815104Z","iopub.status.idle":"2021-09-23T07:21:46.960164Z","shell.execute_reply.started":"2021-09-23T07:21:46.815059Z","shell.execute_reply":"2021-09-23T07:21:46.959436Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"=> Loading checkpoint\n","output_type":"stream"}]},{"cell_type":"code","source":"def test(max_len=300):\n    model.eval()\n    test_py_dir = '../input/d/palash97/translate-code/Dataset/Test/python'    \n    txt_files = os.listdir(test_py_dir)\n    soft = nn.Softmax(dim=2)\n    \n    for idx, txt_file in enumerate(txt_files):\n        test_py_file = os.path.join(test_py_dir, txt_file)\n        with open (test_py_file, 'r') as f:\n            test_py = f.read()\n        \n        test_py_encoded = vocab.encode(test_py)\n        \n        # convert to tensor\n        py_tensor = torch.LongTensor(test_py_encoded).unsqueeze(0).to(device)  # shape: (1, len_of_test_py_encoded)\n        \n        outputs = [vocab.stoi['<SOS>']]\n        \n        for i in range(max_len):\n            cpp_tensor = torch.LongTensor(outputs).unsqueeze(0).to(device)  # shape: (1, len_of_outputs)\n            \n            with torch.no_grad():\n                output = model_cpp(py_tensor, cpp_tensor)\n            \n            output = soft(output)\n            pred = output.argmax(2)[:, -1].item()\n            outputs.append(pred)\n            \n            if pred == vocab.stoi[\"<EOS>\"]:\n                break\n        \n        test_cpp_predicted = get_code(vocab=vocab,tokens=outputs)\n        \n        with open (f'cpp_{txt_file}', 'w') as f:\n            f.write(test_cpp_predicted)\n            f.close()\n\n        print(f'\\n\\nTest case {idx+1}: ')\n        print('\\n*** Source code ***')\n        print(test_py)\n        print('\\n*** Target code ***')\n        print(test_cpp_predicted)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:23:09.939094Z","iopub.execute_input":"2021-09-23T07:23:09.939369Z","iopub.status.idle":"2021-09-23T07:23:09.949399Z","shell.execute_reply.started":"2021-09-23T07:23:09.939333Z","shell.execute_reply":"2021-09-23T07:23:09.948436Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"test()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:23:13.314652Z","iopub.execute_input":"2021-09-23T07:23:13.315341Z","iopub.status.idle":"2021-09-23T07:23:13.340608Z","shell.execute_reply.started":"2021-09-23T07:23:13.315304Z","shell.execute_reply":"2021-09-23T07:23:13.339961Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"\n\nTest case 1: \n\n*** Source code ***\ndef sub ( a : int , b : int ) -> int :\n    c = a - b\n    return z\n\n*** Target code ***\nint sub ( int a , int b ) { \n int c = a - b ; \nreturn c \n}\n\n\nTest case 2: \n\n*** Source code ***\ndef func1 ( a : float , b : float ) -> float :\n    c = a + b\n    return c\n\n*** Target code ***\nfloat func1 ( float a , float b ) { \nint c = a + b ; \nreturn c ; \n}\n\n\nTest case 3: \n\n*** Source code ***\ndef func ( p : int , q : int ) -> int :\n    r = p / q\n    return r\n\n*** Target code ***\nint func ( int p , int q ) { \nint r = p / q ; \nreturn r ; \n}\n\n\nTest case 4: \n\n*** Source code ***\ndef func1 ( p : int , q : int ) -> int :\n    r = p / q\n    return r\n\n*** Target code ***\nint func1 ( int p , int q ) { \nint r = p / q ; \nreturn r ; \n}\n\n\nTest case 5: \n\n*** Source code ***\ndef func2 ( x : int , y : int , z : int ) -> int :\n    ans = x + y - z\n    return ans\n\n*** Target code ***\nint func2 ( int x , int y , int z ) { \nint ans = x + y ; \nreturn ans ; \n}\n\n\nTest case 6: \n\n*** Source code ***\ndef func1 ( a : int , b : int , c : int ) -> int :\n    if a > b and a > c :\n        return a\n    elif b > a and b > c :\n        return b\n    else :\n        return c\n\n*** Target code ***\nint func1 ( int a , int b , int c ) { \nif (                                                       \n}\n\n\nTest case 7: \n\n*** Source code ***\ndef func2 ( a : int ) -> int :\n    if a % 2 == 0 :\n        return 1\n    else :\n        return 0\n\n*** Target code ***\nint func2 ( int a ) { \nif (                                   \n}\n\n\nTest case 8: \n\n*** Source code ***\ndef func ( a : int ) -> int :\n    if a % 2 != 0 :\n        return 1\n    else :\n        return 0\n\n*** Target code ***\nint func ( int a ) { \nif (                                                     else  \n}\n\n\nTest case 9: \n\n*** Source code ***\ndef func1 ( x : int ) -> int :\n    if x % 2 != 0 :\n        return 1\n    else :\n        return 0\n\n*** Target code ***\nint func1 ( int x ) { \nif (                                                              \n}\n\n\nTest case 10: \n\n*** Source code ***\ndef func ( n : int ) -> int :\n    ans = 0\n    for i in range ( n ) :\n        ans += i ** 2\n    return ans\n\n*** Target code ***\nint func ( int n ) { \nint ans = 0 ; \nfor ( i  \n     ans += i ** 2 \n     } \n    return ans ;\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}