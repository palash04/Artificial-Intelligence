{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Author: Palash Kamble\n## E9 309 Advanced Deep Learning Project_1","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"# PyTorch Libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"_uuid":"700f9b3c-c709-41f3-8d91-d5c4d3dbb555","_cell_guid":"50320a47-87dd-4d39-aa37-20b07f243589","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-23T16:25:36.797032Z","iopub.execute_input":"2021-09-23T16:25:36.797318Z","iopub.status.idle":"2021-09-23T16:25:41.202551Z","shell.execute_reply.started":"2021-09-23T16:25:36.797221Z","shell.execute_reply":"2021-09-23T16:25:41.201775Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:41.205215Z","iopub.execute_input":"2021-09-23T16:25:41.205504Z","iopub.status.idle":"2021-09-23T16:25:41.209170Z","shell.execute_reply.started":"2021-09-23T16:25:41.205469Z","shell.execute_reply":"2021-09-23T16:25:41.208294Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:46.618532Z","iopub.execute_input":"2021-09-23T16:25:46.618799Z","iopub.status.idle":"2021-09-23T16:25:46.624372Z","shell.execute_reply.started":"2021-09-23T16:25:46.618767Z","shell.execute_reply":"2021-09-23T16:25:46.623566Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Loading Dataset","metadata":{}},{"cell_type":"code","source":"dataset_dir = '../input/d/palash97/translate-code/Dataset'\ntrain_dir = dataset_dir + '/Train'\nval_dir = dataset_dir + '/Val'\ntest_dir = dataset_dir + '/Test'\n\ntrain_py_dir = train_dir + '/python'\nval_py_dir = val_dir + '/python'\ntest_py_dir = test_dir + '/python'\n\ntrain_cpp_dir = train_dir + '/cpp'\nval_cpp_dir = val_dir + '/cpp'","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:49.586129Z","iopub.execute_input":"2021-09-23T16:25:49.586854Z","iopub.status.idle":"2021-09-23T16:25:49.591428Z","shell.execute_reply.started":"2021-09-23T16:25:49.586815Z","shell.execute_reply":"2021-09-23T16:25:49.590747Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Listing files from training python directory\npy_files = os.listdir(train_py_dir)\nprint(py_files[:5]) # printing first 5 file names ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:50.849590Z","iopub.execute_input":"2021-09-23T16:25:50.850125Z","iopub.status.idle":"2021-09-23T16:25:50.878442Z","shell.execute_reply.started":"2021-09-23T16:25:50.850088Z","shell.execute_reply":"2021-09-23T16:25:50.877769Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"['p_28.txt', 'p_35.txt', 'p_46.txt', 'p_53.txt', 'p_16.txt']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Listing files from training cpp directory\ncpp_files = os.listdir(train_cpp_dir)\nprint(cpp_files[:5]) # printing first 5 file names ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:52.277941Z","iopub.execute_input":"2021-09-23T16:25:52.278655Z","iopub.status.idle":"2021-09-23T16:25:52.293246Z","shell.execute_reply.started":"2021-09-23T16:25:52.278620Z","shell.execute_reply":"2021-09-23T16:25:52.292560Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['c_21.txt', 'c_49.txt', 'c_39.txt', 'c_58.txt', 'c_38.txt']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'Number of files in python directory: {len(py_files)}')\nprint(f'Number of files in cpp directory: {len(cpp_files)}')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:52.952548Z","iopub.execute_input":"2021-09-23T16:25:52.953118Z","iopub.status.idle":"2021-09-23T16:25:52.958209Z","shell.execute_reply.started":"2021-09-23T16:25:52.953079Z","shell.execute_reply":"2021-09-23T16:25:52.957167Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Number of files in python directory: 60\nNumber of files in cpp directory: 60\n","output_type":"stream"}]},{"cell_type":"code","source":"# Printing one source and target code\npy_txt_file = os.path.join(train_py_dir, 'p_10.txt')\ncpp_txt_file = os.path.join(train_cpp_dir, 'c_10.txt')\n\nwith open (py_txt_file, 'r') as f:\n    py_txt = f.read()\n    \nwith open (cpp_txt_file, 'r') as f:\n    cpp_txt = f.read()\n\nprint('** Source Code **\\n')\nprint(py_txt)\nprint('\\n** Target Code **\\n')\nprint(cpp_txt)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:53.702735Z","iopub.execute_input":"2021-09-23T16:25:53.703000Z","iopub.status.idle":"2021-09-23T16:25:53.720745Z","shell.execute_reply.started":"2021-09-23T16:25:53.702969Z","shell.execute_reply":"2021-09-23T16:25:53.720077Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"** Source Code **\n\ndef func ( x : int , y : int ) -> int :\n    if x > y :\n        return x\n    else :\n        return y\n\n** Target Code **\n\nint func ( int x , int y ) { \n    if ( x > y ) { \n        return x ;\n    } else { \n        return y ;\n    } \n}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Pre-Processing and Tokenization","metadata":{}},{"cell_type":"code","source":"def tokenize(txt):\n    txt_split = txt.split(' ')\n    tokens = []\n    for tok in txt_split:\n        if '\\n' in tok:\n            for idx in range( len ( tok ) ) :\n                tokens.append(tok[idx])\n        else:\n            tokens.append(tok)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:56.818096Z","iopub.execute_input":"2021-09-23T16:25:56.818757Z","iopub.status.idle":"2021-09-23T16:25:56.823897Z","shell.execute_reply.started":"2021-09-23T16:25:56.818715Z","shell.execute_reply":"2021-09-23T16:25:56.823084Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Create Vocabulary","metadata":{}},{"cell_type":"code","source":"class Vocabulary(object):\n    def __init__(self):\n        self.freqs = {}\n        self.itos = {0: \"<UNK>\", 1: \"<PAD>\", 2: \"<SOS>\", 3: \"<EOS>\"}\n        self.stoi = {\"<UNK>\": 0, \"<PAD>\": 1, \"<SOS>\": 2, \"<EOS>\": 3}\n    \n    def build_vocabulary(self, py_dir, cpp_dir, threshold=1):\n        idx = 4\n        \n        for i in range(26):\n            ch = chr(97+i)\n            ch = str(ch)\n            self.freqs[ch] = 1\n            self.stoi[ch] = idx\n            self.itos[idx] = ch\n            idx += 1\n        \n        extra_functions = ['sub', 'func1', 'func2']\n        for extra_func in extra_functions:\n            self.freqs[extra_func] = 1\n            self.stoi[extra_func] = idx\n            self.itos[idx] = extra_func\n            idx += 1\n    \n        num_files = len(os.listdir(py_dir)) # number of files in py_dir is same as in cpp_dir\n        for i in range(1, num_files + 1):\n            py_file = os.path.join(py_dir, f'p_{i}.txt')\n            cpp_file = os.path.join(cpp_dir, f'c_{i}.txt')\n            \n            with open (py_file, 'r') as f:\n                py_txt = f.read()\n            with open (cpp_file, 'r') as f:\n                cpp_txt = f.read()\n            \n            py_tokens = tokenize(py_txt)\n            cpp_tokens = tokenize(cpp_txt)\n            \n            for tok in py_tokens:\n                if tok not in self.freqs:\n                    self.freqs[tok] = 1\n                else:\n                    self.freqs[tok] += 1\n                if self.freqs[tok] == threshold:\n                    self.stoi[tok] = idx\n                    self.itos[idx] = tok\n                    idx += 1\n            for tok in cpp_tokens:\n                if tok not in self.freqs:\n                    self.freqs[tok] = 1\n                else:\n                    self.freqs[tok] += 1\n                if self.freqs[tok] == threshold:\n                    self.stoi[tok] = idx\n                    self.itos[idx] = tok\n                    idx += 1\n    \n    def encode(self, text):\n        tokens = tokenize(text)\n        tokens_to_indices = [self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] for token in tokens]\n        tokens_to_indices = [self.stoi['<SOS>']] + tokens_to_indices + [self.stoi['<EOS>']]\n        return tokens_to_indices","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:58.167044Z","iopub.execute_input":"2021-09-23T16:25:58.167579Z","iopub.status.idle":"2021-09-23T16:25:58.182472Z","shell.execute_reply.started":"2021-09-23T16:25:58.167541Z","shell.execute_reply":"2021-09-23T16:25:58.181508Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"vocab = Vocabulary()\nvocab.build_vocabulary(train_py_dir, train_cpp_dir)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:58.928366Z","iopub.execute_input":"2021-09-23T16:25:58.929060Z","iopub.status.idle":"2021-09-23T16:25:59.496455Z","shell.execute_reply.started":"2021-09-23T16:25:58.929022Z","shell.execute_reply":"2021-09-23T16:25:59.495589Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(vocab.stoi)\nprint(f'Number of tokens in vocabulary: {vocab_size}')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:59.678681Z","iopub.execute_input":"2021-09-23T16:25:59.679382Z","iopub.status.idle":"2021-09-23T16:25:59.684338Z","shell.execute_reply.started":"2021-09-23T16:25:59.679337Z","shell.execute_reply":"2021-09-23T16:25:59.683622Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Number of tokens in vocabulary: 155\n","output_type":"stream"}]},{"cell_type":"code","source":"print(vocab.stoi) # token and its corresponding index","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:25:59.699092Z","iopub.execute_input":"2021-09-23T16:25:59.699518Z","iopub.status.idle":"2021-09-23T16:25:59.703675Z","shell.execute_reply.started":"2021-09-23T16:25:59.699491Z","shell.execute_reply":"2021-09-23T16:25:59.702907Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'<UNK>': 0, '<PAD>': 1, '<SOS>': 2, '<EOS>': 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'j': 13, 'k': 14, 'l': 15, 'm': 16, 'n': 17, 'o': 18, 'p': 19, 'q': 20, 'r': 21, 's': 22, 't': 23, 'u': 24, 'v': 25, 'w': 26, 'x': 27, 'y': 28, 'z': 29, 'sub': 30, 'func1': 31, 'func2': 32, 'def': 33, 'add': 34, '(': 35, ':': 36, 'int': 37, ',': 38, ')': 39, '->': 40, '\\n': 41, '': 42, '=': 43, '+': 44, 'return': 45, '{': 46, ';': 47, '}': 48, 'float': 49, 'subtract': 50, '-': 51, 'multiply': 52, 'int)': 53, '*': 54, 'divide': 55, '/': 56, 'func': 57, '**': 58, 'pow': 59, 'if': 60, '>': 61, 'else': 62, '<': 63, 'and': 64, 'elif': 65, 'str': 66, '0': 67, '\"': 68, 'N': 69, 'P': 70, '\"Zero\"': 71, 'string': 72, '\"Negative\"': 73, '\"Positive\"': 74, '%': 75, '5': 76, '==': 77, '11': 78, '1': 79, '2': 80, '4': 81, '100': 82, '!=': 83, 'or': 84, '400': 85, \"'a'\": 86, \"'e'\": 87, \"'i'\": 88, \"'o'\": 89, \"'u'\": 90, \"'A'\": 91, \"'E'\": 92, \"'I'\": 93, \"'O'\": 94, \"'U'\": 95, 'char': 96, '3': 97, '8': 98, '6': 99, '7': 100, '9': 101, '10': 102, '12': 103, '-1': 104, '31': 105, '28': 106, '30': 107, 'sum': 108, '180': 109, 'cp': 110, 'sp': 111, 'profit': 112, 'loss': 113, 'for': 114, 'in': 115, 'range': 116, 'print': 117, 'void': 118, '++': 119, 'cout': 120, '<<': 121, 'endl': 122, '+=': 123, 'while': 124, '//': 125, 'prod': 126, '*=': 127, 'rev': 128, '<=': 129, 'isprime': 130, '2,': 131, '3,': 132, 'sz': 133, 'len': 134, 's[i]': 135, \"'1'\": 136, '.size()': 137, 'ans': 138, '>=': 139, \"'z'\": 140, 'reversed': 141, '[': 142, ']': 143, '\"\"': 144, '--': 145, 'arr': 146, 'list': 147, '[i]': 148, 'vector<int>': 149, 'INT_MIN': 150, 'INT_MAX': 151, 'max1': 152, 'max2': 153, 'mid': 154}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(vocab.itos) # index and its corresponding token","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:00.612713Z","iopub.execute_input":"2021-09-23T16:26:00.613442Z","iopub.status.idle":"2021-09-23T16:26:00.618122Z","shell.execute_reply.started":"2021-09-23T16:26:00.613404Z","shell.execute_reply":"2021-09-23T16:26:00.617224Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"{0: '<UNK>', 1: '<PAD>', 2: '<SOS>', 3: '<EOS>', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z', 30: 'sub', 31: 'func1', 32: 'func2', 33: 'def', 34: 'add', 35: '(', 36: ':', 37: 'int', 38: ',', 39: ')', 40: '->', 41: '\\n', 42: '', 43: '=', 44: '+', 45: 'return', 46: '{', 47: ';', 48: '}', 49: 'float', 50: 'subtract', 51: '-', 52: 'multiply', 53: 'int)', 54: '*', 55: 'divide', 56: '/', 57: 'func', 58: '**', 59: 'pow', 60: 'if', 61: '>', 62: 'else', 63: '<', 64: 'and', 65: 'elif', 66: 'str', 67: '0', 68: '\"', 69: 'N', 70: 'P', 71: '\"Zero\"', 72: 'string', 73: '\"Negative\"', 74: '\"Positive\"', 75: '%', 76: '5', 77: '==', 78: '11', 79: '1', 80: '2', 81: '4', 82: '100', 83: '!=', 84: 'or', 85: '400', 86: \"'a'\", 87: \"'e'\", 88: \"'i'\", 89: \"'o'\", 90: \"'u'\", 91: \"'A'\", 92: \"'E'\", 93: \"'I'\", 94: \"'O'\", 95: \"'U'\", 96: 'char', 97: '3', 98: '8', 99: '6', 100: '7', 101: '9', 102: '10', 103: '12', 104: '-1', 105: '31', 106: '28', 107: '30', 108: 'sum', 109: '180', 110: 'cp', 111: 'sp', 112: 'profit', 113: 'loss', 114: 'for', 115: 'in', 116: 'range', 117: 'print', 118: 'void', 119: '++', 120: 'cout', 121: '<<', 122: 'endl', 123: '+=', 124: 'while', 125: '//', 126: 'prod', 127: '*=', 128: 'rev', 129: '<=', 130: 'isprime', 131: '2,', 132: '3,', 133: 'sz', 134: 'len', 135: 's[i]', 136: \"'1'\", 137: '.size()', 138: 'ans', 139: '>=', 140: \"'z'\", 141: 'reversed', 142: '[', 143: ']', 144: '\"\"', 145: '--', 146: 'arr', 147: 'list', 148: '[i]', 149: 'vector<int>', 150: 'INT_MIN', 151: 'INT_MAX', 152: 'max1', 153: 'max2', 154: 'mid'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create Custom Dataset","metadata":{}},{"cell_type":"code","source":"class TransCompilerDataset(Dataset):\n    def __init__(self, py_dir, cpp_dir, vocab):\n        self.py_dir = py_dir\n        self.cpp_dir = cpp_dir\n        self.vocab = vocab\n    \n    def __len__(self):\n        return len(os.listdir(self.py_dir))\n    \n    def __getitem__(self, index):\n        py_file = os.path.join(self.py_dir, f'p_{index+1}.txt')\n        cpp_file = os.path.join(self.cpp_dir, f'c_{index+1}.txt')\n        \n        with open (py_file, 'r') as f:\n            py_txt = f.read()\n        \n        with open (cpp_file, 'r') as f:\n            cpp_txt = f.read()\n        \n        py_encoded = vocab.encode(py_txt)\n        cpp_encoded = vocab.encode(cpp_txt)\n        \n        return torch.tensor(py_encoded), torch.tensor(cpp_encoded)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:01.444758Z","iopub.execute_input":"2021-09-23T16:26:01.445225Z","iopub.status.idle":"2021-09-23T16:26:01.452913Z","shell.execute_reply.started":"2021-09-23T16:26:01.445190Z","shell.execute_reply":"2021-09-23T16:26:01.451860Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Collate():\n    def __init__(self, pad_idx):\n        self.pad_idx = pad_idx\n    \n    def __call__(self, batch):\n        (py, cpp) = zip(*batch)\n        \n        py_pad = pad_sequence(py, batch_first=True, padding_value=self.pad_idx)\n        cpp_pad = pad_sequence(cpp, batch_first=True, padding_value=self.pad_idx)\n        return py_pad, cpp_pad","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:02.420900Z","iopub.execute_input":"2021-09-23T16:26:02.421409Z","iopub.status.idle":"2021-09-23T16:26:02.431707Z","shell.execute_reply.started":"2021-09-23T16:26:02.421369Z","shell.execute_reply":"2021-09-23T16:26:02.430713Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def get_loaders(train_py_dir, train_cpp_dir, val_py_dir, val_cpp_dir, vocab):\n    train_dataset = TransCompilerDataset(train_py_dir, train_cpp_dir, vocab)\n    val_dataset = TransCompilerDataset(val_py_dir, val_cpp_dir, vocab)\n    pad_idx = vocab.stoi['<PAD>']\n    train_loader = DataLoader(train_dataset, batch_size = 10, shuffle=True, collate_fn=Collate(pad_idx))\n    val_loader = DataLoader(val_dataset, batch_size = 10, shuffle=True, collate_fn=Collate(pad_idx))\n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:04.666542Z","iopub.execute_input":"2021-09-23T16:26:04.666803Z","iopub.status.idle":"2021-09-23T16:26:04.672718Z","shell.execute_reply.started":"2021-09-23T16:26:04.666774Z","shell.execute_reply":"2021-09-23T16:26:04.671899Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_loader, val_loader = get_loaders(train_py_dir, train_cpp_dir, val_py_dir, val_cpp_dir, vocab)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:05.243356Z","iopub.execute_input":"2021-09-23T16:26:05.244205Z","iopub.status.idle":"2021-09-23T16:26:05.263803Z","shell.execute_reply.started":"2021-09-23T16:26:05.244166Z","shell.execute_reply":"2021-09-23T16:26:05.263020Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(len(train_loader))\nprint(len(val_loader))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:05.994033Z","iopub.execute_input":"2021-09-23T16:26:05.994323Z","iopub.status.idle":"2021-09-23T16:26:05.999684Z","shell.execute_reply.started":"2021-09-23T16:26:05.994288Z","shell.execute_reply":"2021-09-23T16:26:05.998903Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"6\n2\n","output_type":"stream"}]},{"cell_type":"code","source":"for idx, (py, cpp) in enumerate(train_loader):\n    print(f'Shape of py: {py.shape}')      # batch_size x src_seq_len\n    print(f'Shape of cpp: {cpp.shape}')    # batch_size x trg_seq_len\n    break","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:06.658731Z","iopub.execute_input":"2021-09-23T16:26:06.659336Z","iopub.status.idle":"2021-09-23T16:26:06.718151Z","shell.execute_reply.started":"2021-09-23T16:26:06.659226Z","shell.execute_reply":"2021-09-23T16:26:06.717480Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Shape of py: torch.Size([10, 76])\nShape of cpp: torch.Size([10, 102])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ready to build transformer architecture!!!","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:07.449563Z","iopub.execute_input":"2021-09-23T16:26:07.450095Z","iopub.status.idle":"2021-09-23T16:26:07.453407Z","shell.execute_reply.started":"2021-09-23T16:26:07.450057Z","shell.execute_reply":"2021-09-23T16:26:07.452747Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Building Transformer Architecture","metadata":{}},{"cell_type":"markdown","source":"#### Building Attention Mechanism","metadata":{}},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def __init__(self, embed_size, heads):\n        super(SelfAttention, self).__init__()\n        self.embed_size = embed_size\n        self.heads = heads\n        self.head_dim = embed_size // heads\n\n        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        \n        self.fc_out = nn.Linear(self.head_dim * self.heads, embed_size)   # concatenating heads\n        \n    def forward(self, queries, keys, values, mask):\n        # queries, keys, values => shape (N, seq_len, embed_size)\n        # mask => shape (N, 1, 1, src_seq_len)\n        N = queries.shape[0] # N = Batch_size\n        query_len, key_len, value_len = queries.shape[1], keys.shape[1], values.shape[1]   # same as seq length\n        \n        # splitting embedding into heads\n        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n        values = values.reshape(N, value_len, self.heads, self.head_dim)\n        \n        \n        # Step 1: Create query, key, value matrices (for each head)\n        queries = self.queries(queries) # (N, query_len, heads, head_dim)\n        keys = self.queries(keys)       # (N, key_len, heads, head_dim)\n        values = self.queries(values)   # (N, value_len, heads, head_dim) \n        \n        # Step 2: Calculate the scores for each tokens against all tokens (dot query and key)\n        query_key_score = torch.einsum(\"nqhd, nkhd -> nhqk\", [queries, keys])   # (N, heads, query_len, key_len)\n        \n        # Step 2.1 : If mask is set (needed in decoder), then mask upper right triangle matrix with negative infiniy\n        if mask is not None:\n            query_key_score = query_key_score.masked_fill(mask == 0, float('-1e20'))\n        \n        # Step 3: Calculate softmax score\n        softmax_score = torch.softmax(query_key_score / (self.embed_size ** 0.5), dim=3) # (N, heads, query_len, key_len)\n        \n        # Step 4: Calculate weighted values\n        attention = torch.einsum(\"nhql, nvhd -> nqhd\", [softmax_score, values])   # (N, query_len, heads, head_dim)\n        attention = attention.reshape(N, query_len, self.head_dim * self.heads) # (N, query_len ,embed_size)\n        \n        # Step 5: Concatenating heads\n        out = self.fc_out(attention)\n        return out     # (N, query_len, embed_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:09.848900Z","iopub.execute_input":"2021-09-23T16:26:09.849157Z","iopub.status.idle":"2021-09-23T16:26:09.861049Z","shell.execute_reply.started":"2021-09-23T16:26:09.849126Z","shell.execute_reply":"2021-09-23T16:26:09.860387Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Testing self attention\nattention = SelfAttention(512, 8)\nq = torch.randn(5, 100, 512)\nk = torch.randn(5, 100, 512)\nv = torch.randn(5, 100, 512)\nm = torch.randn(5, 1, 100, 100)\nout = attention(q,k,v,m)\nprint(out.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:10.463921Z","iopub.execute_input":"2021-09-23T16:26:10.464462Z","iopub.status.idle":"2021-09-23T16:26:10.545767Z","shell.execute_reply.started":"2021-09-23T16:26:10.464422Z","shell.execute_reply":"2021-09-23T16:26:10.545064Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"torch.Size([5, 100, 512])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Building Transformer Block","metadata":{}},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, embed_size, heads, forward_expansion, dropout=0.5):\n        super(TransformerBlock, self).__init__()\n        self.attention = SelfAttention(embed_size, heads)\n        self.layer_norm1 = nn.LayerNorm(embed_size)\n        self.layer_norm2 = nn.LayerNorm(embed_size)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(embed_size, forward_expansion * embed_size),\n            nn.ReLU(),\n            nn.Linear(forward_expansion * embed_size, embed_size)\n        )\n        \n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, query, key, value, mask):\n        attention = self.attention(query, key, value, mask)\n        \n        # Step1: Skip connection\n        x = attention + query\n        \n        # Step2: Layer norm\n        x = self.layer_norm1(x)\n        \n        # Step3: Dropout\n        x = self.dropout(x)\n        \n        # Step4: Feed forward\n        forward = self.feed_forward(x)\n        \n        # Step5: Same as above from step 1 to step 3\n        out = self.dropout(self.layer_norm2(forward + x))\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:12.538067Z","iopub.execute_input":"2021-09-23T16:26:12.538629Z","iopub.status.idle":"2021-09-23T16:26:12.547523Z","shell.execute_reply.started":"2021-09-23T16:26:12.538589Z","shell.execute_reply":"2021-09-23T16:26:12.546599Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"#### Building Encoder Architecture (stacking Transformer Blocks)\n","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, vocab_size, embed_size, num_layers, heads, device, forward_expansion, max_len, drop=0.5):\n        super(Encoder, self).__init__()\n        self.embed_size = embed_size\n        self.device = device\n        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n        self.pos_embedding = nn.Embedding(max_len, embed_size)\n        self.dropout = nn.Dropout(drop)\n        \n        self.layers = nn.ModuleList(\n            [\n                TransformerBlock(embed_size, heads, forward_expansion, drop)\n                for _ in range(num_layers)\n            ]\n        )\n        \n    def forward(self, x, mask):\n        # Shape of x : (batch_size x src_seq_len)\n        # shape of mask: (batch_size, 1, 1, src_seq_len)\n        batch_size, seq_len = x.shape\n        positions = torch.arange(0, seq_len).expand(batch_size, seq_len).to(self.device)\n        out = self.word_embedding(x) + self.pos_embedding(positions)\n        out = self.dropout(out)     # (N, src_seq_len, embed_size)\n        \n        \n        for layer in self.layers:\n            # query, key, value inputs are same for each transformer block from\n            # their previous transformer block, except in the beginning that is positional encodings\n            out = layer(out, out, out, mask)\n        return out      # (N, src_seq_len, embed_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:19.811153Z","iopub.execute_input":"2021-09-23T16:26:19.811746Z","iopub.status.idle":"2021-09-23T16:26:19.823108Z","shell.execute_reply.started":"2021-09-23T16:26:19.811705Z","shell.execute_reply":"2021-09-23T16:26:19.822395Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"#### Building Decoder Architecture","metadata":{}},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, embed_size ,heads, forward_expansion, device, drop=0.5):\n        super(DecoderBlock, self).__init__()\n        self.norm = nn.LayerNorm(embed_size)\n        self.attention = SelfAttention(embed_size ,heads)\n        self.transformer_block = TransformerBlock(embed_size, heads, forward_expansion, drop)\n        self.dropout = nn.Dropout(drop)\n    \n    def forward(self, x, value, key, src_mask, trg_mask):\n        attention = self.attention(x,x,x,trg_mask)\n        query = self.dropout(self.norm(attention + x))\n        out = self.transformer_block(query, key, value, src_mask)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:23.127027Z","iopub.execute_input":"2021-09-23T16:26:23.127304Z","iopub.status.idle":"2021-09-23T16:26:23.134909Z","shell.execute_reply.started":"2021-09-23T16:26:23.127254Z","shell.execute_reply":"2021-09-23T16:26:23.133008Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, vocab_size, embed_size, num_layers, heads, device, forward_expansion, max_len, drop=0.5,):\n        super(Decoder, self).__init__()\n        self.device = device\n        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n        self.pos_embedding = nn.Embedding(max_len, embed_size)\n        \n        self.layers = nn.ModuleList(\n            [\n                DecoderBlock(embed_size, heads, forward_expansion, device, drop)\n                for _ in range(num_layers)\n            ]\n        )\n        \n        self.fc_out = nn.Linear(embed_size, vocab_size)\n        self.dropout = nn.Dropout(drop)\n    \n    def forward(self, x, enc_out, src_mask, trg_mask):\n        # enc_out => shape (N, src_seq_len, embed_size)\n        # src_mask => shape (N, 1, 1, seq_len)\n        # trg_mask => shape (N, 1, seq_len, seq_len)\n        batch_size, seq_len = x.shape\n        positions = torch.arange(0, seq_len).expand(batch_size, seq_len).to(self.device)\n        x = self.dropout(self.word_embedding(x) + self.pos_embedding(positions))\n        value = enc_out\n        key = enc_out\n        for layer in self.layers:\n            x = layer(x, value, key, src_mask, trg_mask)\n        \n        out = self.fc_out(x)\n        return out   # (N, trg_len, vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:24.946105Z","iopub.execute_input":"2021-09-23T16:26:24.946778Z","iopub.status.idle":"2021-09-23T16:26:24.958093Z","shell.execute_reply.started":"2021-09-23T16:26:24.946739Z","shell.execute_reply":"2021-09-23T16:26:24.957414Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"#### Putting it all together","metadata":{}},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, vocab_size, pad_idx, embed_size=512, num_layers=6, forward_expansion=4, heads=8, dropout=0, device=\"cpu\", max_len=350):\n        super(Transformer, self).__init__()\n        \n        self.encoder = Encoder(vocab_size, embed_size, num_layers, heads, device, forward_expansion, max_len ,dropout)\n        self.decoder = Decoder(vocab_size ,embed_size, num_layers, heads, device, forward_expansion, max_len, dropout)\n        self.pad_idx = pad_idx\n        self.device = device\n    \n    def make_src_mask(self, src):\n        # shape of src : (N, seq_len)\n        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)\n        return src_mask.to(self.device)\n\n    def make_trg_mask(self, trg):\n        # shape of trg: (N, seq_len)\n        batch_size, seq_len = trg.shape\n        # fill lower triangular matrix\n        trg_mask = torch.tril(torch.ones((seq_len, seq_len))).expand(batch_size, 1, seq_len, seq_len)\n        return trg_mask.to(device)\n\n    def forward(self, src, trg):\n        # Shape of src: (batch_size x src_seq_len)\n        # Shape of trg: (batch_size x trg_seq_len)\n        src_mask = self.make_src_mask(src)\n        trg_mask = self.make_trg_mask(trg)\n        enc_out = self.encoder(src, src_mask)\n        out = self.decoder(trg, enc_out, src_mask, trg_mask)\n        return out  # (batch_size x trg_seq_len x vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:27.789770Z","iopub.execute_input":"2021-09-23T16:26:27.790034Z","iopub.status.idle":"2021-09-23T16:26:27.799288Z","shell.execute_reply.started":"2021-09-23T16:26:27.790006Z","shell.execute_reply":"2021-09-23T16:26:27.798613Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"#### Testing Transformer Architecture","metadata":{}},{"cell_type":"code","source":"# Setting device to cuda if available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:40.020947Z","iopub.execute_input":"2021-09-23T16:26:40.021776Z","iopub.status.idle":"2021-09-23T16:26:40.027292Z","shell.execute_reply.started":"2021-09-23T16:26:40.021714Z","shell.execute_reply":"2021-09-23T16:26:40.026656Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 5\nsrc_seq_len = 100\ntrg_seq_len = 150\npad_idx = 0\nvocab_size = 10\n\nx = torch.randint(0, vocab_size, (batch_size, src_seq_len)).to(device)\ntrg = torch.randint(0, vocab_size, (batch_size, trg_seq_len)).to(device)\nmodel = Transformer(vocab_size, pad_idx, device=device).to(device)\nout = model(x, trg[:, :-1])\nprint(out.shape)   # (batch_size, (trg_seq_len-1), vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:26:44.237587Z","iopub.execute_input":"2021-09-23T16:26:44.238247Z","iopub.status.idle":"2021-09-23T16:26:49.952440Z","shell.execute_reply.started":"2021-09-23T16:26:44.238203Z","shell.execute_reply":"2021-09-23T16:26:49.951672Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"torch.Size([5, 149, 10])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"vocab_size = len(vocab.stoi)\nembed_size = 256\nnum_layers = 6\nheads = 8\nforward_expansion = 4\ndropout = 0.2\nmax_len = 250\npad_idx = vocab.stoi['<PAD>']\nlr = 3e-5\nepochs = 100","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:27:00.961168Z","iopub.execute_input":"2021-09-23T16:27:00.961780Z","iopub.status.idle":"2021-09-23T16:27:00.966520Z","shell.execute_reply.started":"2021-09-23T16:27:00.961740Z","shell.execute_reply":"2021-09-23T16:27:00.965711Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"# Function to plot loss\ndef plot_loss(loss,epochs,val_loss=None):\n    plt.title('Plot of training loss')\n    plt.plot(loss, c='r', label='training_loss')\n    if val_loss is not None:\n        plt.plot(val_loss, c='g', label='validation_loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig(f'loss.png')\n    plt.show()\n    \n# Function to save checkpoint\ndef save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n\n\n# Function to load checkpoint\ndef load_checkpoint(checkpoint, model, optimizer):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    \n    \n# Function to convert tokens to code\ndef get_code(vocab, tokens):\n    tok_list = []\n    for tok in tokens:\n        if tok == vocab.stoi[\"<SOS>\"] or tok == vocab.stoi[\"<EOS>\"]:\n            continue\n        tok_list.append(vocab.itos[tok])\n    return ' '.join(tok_list)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:27:07.828649Z","iopub.execute_input":"2021-09-23T16:27:07.828923Z","iopub.status.idle":"2021-09-23T16:27:07.837471Z","shell.execute_reply.started":"2021-09-23T16:27:07.828892Z","shell.execute_reply":"2021-09-23T16:27:07.836771Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Instantiating model","metadata":{}},{"cell_type":"code","source":"model_cpp = Transformer(vocab_size = vocab_size, \n                    pad_idx = pad_idx,\n                    embed_size = embed_size,\n                    num_layers = num_layers,\n                    forward_expansion = forward_expansion,\n                    heads = heads,\n                    max_len = max_len,\n                    dropout = dropout,\n                    device=device).to(device)\nmodel_py = Transformer(vocab_size = vocab_size, \n                    pad_idx = pad_idx,\n                    embed_size = embed_size,\n                    num_layers = num_layers,\n                    forward_expansion = forward_expansion,\n                    heads = heads,\n                    max_len = max_len,\n                    dropout = dropout,\n                    device=device).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:27:09.774993Z","iopub.execute_input":"2021-09-23T16:27:09.775722Z","iopub.status.idle":"2021-09-23T16:27:09.949355Z","shell.execute_reply.started":"2021-09-23T16:27:09.775680Z","shell.execute_reply":"2021-09-23T16:27:09.948605Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## Defining loss function and optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n# optimizer_cpp = optim.SGD(model_cpp.parameters(), lr=lr)\n# optimizer_py = optim.SGD(model_py.parameters(), lr=lr)\n\noptimizer_cpp = optim.Adam(model_cpp.parameters(), lr=lr, betas=(0.9, 0.99))\noptimizer_py = optim.Adam(model_py.parameters(), lr=lr, betas=(0.9, 0.99))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:27:11.714859Z","iopub.execute_input":"2021-09-23T16:27:11.715120Z","iopub.status.idle":"2021-09-23T16:27:11.726200Z","shell.execute_reply.started":"2021-09-23T16:27:11.715089Z","shell.execute_reply":"2021-09-23T16:27:11.725506Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"def train():\n\n    train_loss = []\n    val_loss = []\n    best_val_loss = np.inf\n    \n    for epoch in range(1, epochs+1):\n        model.train()\n        losses = []\n        for batch_idx, (py_src, cpp_trg) in enumerate(train_loader):\n            # Put on cuda if available\n            py_src = py_src.to(device)   # (batch_size, src_seq_len)\n            cpp_trg = cpp_trg.to(device)\n            \n            # Forward pass\n            output_cpp = model_cpp(py_src, cpp_trg[:, :-1])  # shape (batch_size, (tgr_seq_len-1), vocab_size)\n            \n            out_cpp = output_cpp.reshape(-1, vocab_size)  # [batch_size * (trg_seq_len-1), vocab_size]\n            target = cpp_trg[:, 1:]  # (batch_size, trg_seq_len - 1)\n            target = target.reshape(-1)    # [batch_size x (trg_seq_len - 1)]\n            \n            loss_cpp = criterion(out_cpp, target)\n            \n            output_py = model_py(cpp_trg, py_src[:, :-1])\n            out_py = output_py.reshape(-1, vocab_size)\n            target = py_src[:, 1:]\n            target = target.reshape(-1)\n            \n            loss_py = criterion(out_py, target)\n            \n            \n            # Cycle consistency\n            \n            ## generated_cpp to reconstruct_python code\n            gen_cpp = torch.full((output_cpp.shape[0],output_cpp.shape[1]+1), vocab.stoi[\"<SOS>\"]).to(device)\n            gen_cpp[:, 1:] = output_cpp.argmax(2)\n            gen_cpp[:, -1] = vocab.stoi[\"<EOS>\"]\n            \n            rec_py = model_py(gen_cpp, py_src[:, :-1])\n            rec_py = rec_py.reshape(-1, vocab_size)\n            target = py_src[:, 1:]\n            target = target.reshape(-1)\n            \n            loss_rec_py = criterion(rec_py, target)\n            \n            ## generated_py to reconstruct_cpp code\n            gen_py = torch.full((output_py.shape[0],output_py.shape[1]+1), vocab.stoi[\"<SOS>\"]).to(device)\n            gen_py[:, 1:] = output_py.argmax(2)\n            gen_py[:, -1] = vocab.stoi[\"<EOS>\"]\n            \n            rec_cpp = model_py(gen_py, cpp_trg[:, :-1])\n            rec_cpp = rec_cpp.reshape(-1, vocab_size)\n            target = cpp_trg[:, 1:]\n            target = target.reshape(-1)\n            \n            loss_rec_cpp = criterion(rec_cpp, target)\n            \n            loss =  0.25 * ( loss_cpp + loss_py + loss_rec_py + loss_rec_cpp )\n            \n            losses.append(loss.item())\n            \n            # Clear the gradients\n            optimizer_cpp.zero_grad()\n            optimizer_py.zero_grad()\n            \n            # Backward pass\n            loss.backward()\n            optimizer_cpp.step()\n            optimizer_py.step()\n        \n        mean_train_loss = sum(losses) / len(losses)\n        train_loss.append(mean_train_loss)\n      \n        model.eval()\n        losses = []\n        for batch_idx, (py, cpp) in enumerate(val_loader):\n            py = py.to(device)\n            cpp = cpp.to(device)\n\n            output = model_cpp(py, cpp[:, :-1])\n\n            output = output.reshape(-1, vocab_size)  # [batch_size * (trg_seq_len-1), vocab_size]\n            target = cpp[:, 1:]  # (batch_size, trg_seq_len - 1)\n            target = target.reshape(-1)    # [batch_size x (trg_seq_len - 1)]\n\n            # Calculate loss\n            loss = criterion(output, target)\n            losses.append(loss.item())\n        mean_val_loss = sum(losses) / len(losses)\n        val_loss.append(mean_val_loss)\n        \n        print(f'Epoch: {epoch}/{epochs}\\tTraining Loss: {mean_train_loss:.6f}\\tValidation Loss: {mean_val_loss:.6f}')\n        \n        if mean_val_loss < best_val_loss:\n            print('Validation loss decreased. Saving model params...')\n            best_val_loss = mean_val_loss\n            checkpoint = {\n                \"state_dict\": model_cpp.state_dict(),\n                \"optimizer\": optimizer_cpp.state_dict(),\n            }\n            save_checkpoint(checkpoint)\n        \n    return train_loss, val_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:27:14.467982Z","iopub.execute_input":"2021-09-23T16:27:14.468389Z","iopub.status.idle":"2021-09-23T16:27:14.487971Z","shell.execute_reply.started":"2021-09-23T16:27:14.468350Z","shell.execute_reply":"2021-09-23T16:27:14.487316Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_loss, val_loss = train()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:27:15.503303Z","iopub.execute_input":"2021-09-23T16:27:15.503860Z","iopub.status.idle":"2021-09-23T16:30:11.853542Z","shell.execute_reply.started":"2021-09-23T16:27:15.503821Z","shell.execute_reply":"2021-09-23T16:30:11.852630Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch: 1/100\tTraining Loss: 4.761284\tValidation Loss: 4.021055\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 2/100\tTraining Loss: 3.878847\tValidation Loss: 3.721201\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 3/100\tTraining Loss: 3.683478\tValidation Loss: 3.566378\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 4/100\tTraining Loss: 3.560849\tValidation Loss: 3.472154\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 5/100\tTraining Loss: 3.491527\tValidation Loss: 3.418906\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 6/100\tTraining Loss: 3.432953\tValidation Loss: 3.355131\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 7/100\tTraining Loss: 3.393372\tValidation Loss: 3.339287\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 8/100\tTraining Loss: 3.372571\tValidation Loss: 3.298211\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 9/100\tTraining Loss: 3.343279\tValidation Loss: 3.322858\nEpoch: 10/100\tTraining Loss: 3.319857\tValidation Loss: 3.330836\nEpoch: 11/100\tTraining Loss: 3.304256\tValidation Loss: 3.342749\nEpoch: 12/100\tTraining Loss: 3.298112\tValidation Loss: 3.296453\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 13/100\tTraining Loss: 3.282403\tValidation Loss: 3.277570\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 14/100\tTraining Loss: 3.258785\tValidation Loss: 3.320623\nEpoch: 15/100\tTraining Loss: 3.251098\tValidation Loss: 3.282475\nEpoch: 16/100\tTraining Loss: 3.236489\tValidation Loss: 3.192027\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 17/100\tTraining Loss: 3.252007\tValidation Loss: 3.251607\nEpoch: 18/100\tTraining Loss: 3.230020\tValidation Loss: 3.293235\nEpoch: 19/100\tTraining Loss: 3.219026\tValidation Loss: 3.228936\nEpoch: 20/100\tTraining Loss: 3.204488\tValidation Loss: 3.282225\nEpoch: 21/100\tTraining Loss: 3.211414\tValidation Loss: 3.258188\nEpoch: 22/100\tTraining Loss: 3.210921\tValidation Loss: 3.159601\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 23/100\tTraining Loss: 3.185446\tValidation Loss: 3.257045\nEpoch: 24/100\tTraining Loss: 3.205700\tValidation Loss: 3.241772\nEpoch: 25/100\tTraining Loss: 3.185528\tValidation Loss: 3.190752\nEpoch: 26/100\tTraining Loss: 3.191442\tValidation Loss: 3.143956\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 27/100\tTraining Loss: 3.179678\tValidation Loss: 3.115517\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 28/100\tTraining Loss: 3.168449\tValidation Loss: 3.105757\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 29/100\tTraining Loss: 3.174080\tValidation Loss: 3.114753\nEpoch: 30/100\tTraining Loss: 3.154600\tValidation Loss: 3.134736\nEpoch: 31/100\tTraining Loss: 3.149367\tValidation Loss: 3.118050\nEpoch: 32/100\tTraining Loss: 3.145577\tValidation Loss: 3.138060\nEpoch: 33/100\tTraining Loss: 3.144176\tValidation Loss: 3.145404\nEpoch: 34/100\tTraining Loss: 3.138516\tValidation Loss: 3.098432\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 35/100\tTraining Loss: 3.145505\tValidation Loss: 3.111659\nEpoch: 36/100\tTraining Loss: 3.134604\tValidation Loss: 3.074374\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 37/100\tTraining Loss: 3.132470\tValidation Loss: 3.081790\nEpoch: 38/100\tTraining Loss: 3.135736\tValidation Loss: 3.116037\nEpoch: 39/100\tTraining Loss: 3.124477\tValidation Loss: 3.063143\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 40/100\tTraining Loss: 3.126063\tValidation Loss: 3.057911\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 41/100\tTraining Loss: 3.136096\tValidation Loss: 3.083902\nEpoch: 42/100\tTraining Loss: 3.123006\tValidation Loss: 3.057187\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 43/100\tTraining Loss: 3.111584\tValidation Loss: 3.071817\nEpoch: 44/100\tTraining Loss: 3.125320\tValidation Loss: 3.032056\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 45/100\tTraining Loss: 3.111648\tValidation Loss: 3.055688\nEpoch: 46/100\tTraining Loss: 3.116579\tValidation Loss: 3.078979\nEpoch: 47/100\tTraining Loss: 3.104030\tValidation Loss: 3.041867\nEpoch: 48/100\tTraining Loss: 3.097862\tValidation Loss: 3.032011\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 49/100\tTraining Loss: 3.101193\tValidation Loss: 3.052088\nEpoch: 50/100\tTraining Loss: 3.102124\tValidation Loss: 3.036527\nEpoch: 51/100\tTraining Loss: 3.098783\tValidation Loss: 3.017340\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 52/100\tTraining Loss: 3.088853\tValidation Loss: 3.015804\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 53/100\tTraining Loss: 3.090223\tValidation Loss: 3.033941\nEpoch: 54/100\tTraining Loss: 3.091837\tValidation Loss: 3.017762\nEpoch: 55/100\tTraining Loss: 3.087588\tValidation Loss: 3.001959\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 56/100\tTraining Loss: 3.083255\tValidation Loss: 3.020346\nEpoch: 57/100\tTraining Loss: 3.077485\tValidation Loss: 3.010003\nEpoch: 58/100\tTraining Loss: 3.079056\tValidation Loss: 2.980543\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 59/100\tTraining Loss: 3.079812\tValidation Loss: 2.981984\nEpoch: 60/100\tTraining Loss: 3.070639\tValidation Loss: 2.964741\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 61/100\tTraining Loss: 3.075358\tValidation Loss: 2.954189\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 62/100\tTraining Loss: 3.067053\tValidation Loss: 3.019475\nEpoch: 63/100\tTraining Loss: 3.066374\tValidation Loss: 2.971185\nEpoch: 64/100\tTraining Loss: 3.062625\tValidation Loss: 2.969023\nEpoch: 65/100\tTraining Loss: 3.065454\tValidation Loss: 2.945918\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 66/100\tTraining Loss: 3.060411\tValidation Loss: 2.943665\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 67/100\tTraining Loss: 3.058339\tValidation Loss: 3.039416\nEpoch: 68/100\tTraining Loss: 3.060164\tValidation Loss: 2.994414\nEpoch: 69/100\tTraining Loss: 3.057301\tValidation Loss: 2.941976\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 70/100\tTraining Loss: 3.051502\tValidation Loss: 2.950749\nEpoch: 71/100\tTraining Loss: 3.049526\tValidation Loss: 2.997180\nEpoch: 72/100\tTraining Loss: 3.055815\tValidation Loss: 2.965451\nEpoch: 73/100\tTraining Loss: 3.048060\tValidation Loss: 2.945785\nEpoch: 74/100\tTraining Loss: 3.049061\tValidation Loss: 2.952634\nEpoch: 75/100\tTraining Loss: 3.053646\tValidation Loss: 2.968440\nEpoch: 76/100\tTraining Loss: 3.055413\tValidation Loss: 2.940406\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 77/100\tTraining Loss: 3.038592\tValidation Loss: 2.902503\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 78/100\tTraining Loss: 3.032606\tValidation Loss: 2.967978\nEpoch: 79/100\tTraining Loss: 3.042653\tValidation Loss: 2.955791\nEpoch: 80/100\tTraining Loss: 3.042415\tValidation Loss: 2.896374\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 81/100\tTraining Loss: 3.039376\tValidation Loss: 2.986872\nEpoch: 82/100\tTraining Loss: 3.034141\tValidation Loss: 2.931964\nEpoch: 83/100\tTraining Loss: 3.035170\tValidation Loss: 2.903644\nEpoch: 84/100\tTraining Loss: 3.027217\tValidation Loss: 2.898315\nEpoch: 85/100\tTraining Loss: 3.030250\tValidation Loss: 2.939835\nEpoch: 86/100\tTraining Loss: 3.034268\tValidation Loss: 2.944557\nEpoch: 87/100\tTraining Loss: 3.032455\tValidation Loss: 2.900008\nEpoch: 88/100\tTraining Loss: 3.030684\tValidation Loss: 2.914159\nEpoch: 89/100\tTraining Loss: 3.025992\tValidation Loss: 2.972538\nEpoch: 90/100\tTraining Loss: 3.037485\tValidation Loss: 2.910596\nEpoch: 91/100\tTraining Loss: 3.019926\tValidation Loss: 2.898086\nEpoch: 92/100\tTraining Loss: 3.021676\tValidation Loss: 2.969917\nEpoch: 93/100\tTraining Loss: 3.029062\tValidation Loss: 2.908118\nEpoch: 94/100\tTraining Loss: 3.024226\tValidation Loss: 2.926417\nEpoch: 95/100\tTraining Loss: 3.018241\tValidation Loss: 2.960714\nEpoch: 96/100\tTraining Loss: 3.017342\tValidation Loss: 2.982985\nEpoch: 97/100\tTraining Loss: 3.014613\tValidation Loss: 2.916805\nEpoch: 98/100\tTraining Loss: 3.021661\tValidation Loss: 2.881396\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\nEpoch: 99/100\tTraining Loss: 3.019411\tValidation Loss: 2.905506\nEpoch: 100/100\tTraining Loss: 3.021007\tValidation Loss: 2.850995\nValidation loss decreased. Saving model params...\n=> Saving checkpoint\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_loss(train_loss, epochs, val_loss)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:30:11.858001Z","iopub.execute_input":"2021-09-23T16:30:11.858255Z","iopub.status.idle":"2021-09-23T16:30:12.190781Z","shell.execute_reply.started":"2021-09-23T16:30:11.858227Z","shell.execute_reply":"2021-09-23T16:30:12.188993Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"### Load best model","metadata":{}},{"cell_type":"code","source":"load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model_cpp, optimizer_cpp)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:30:19.054800Z","iopub.execute_input":"2021-09-23T16:30:19.055068Z","iopub.status.idle":"2021-09-23T16:30:19.204179Z","shell.execute_reply.started":"2021-09-23T16:30:19.055037Z","shell.execute_reply":"2021-09-23T16:30:19.203349Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"=> Loading checkpoint\n","output_type":"stream"}]},{"cell_type":"code","source":"def test(max_len=300):\n    model_cpp.eval()\n    test_py_dir = '../input/d/palash97/translate-code/Dataset/Test/python'    \n    txt_files = os.listdir(test_py_dir)\n    soft = nn.Softmax(dim=2)\n    \n    for idx, txt_file in enumerate(txt_files):\n        test_py_file = os.path.join(test_py_dir, txt_file)\n        with open (test_py_file, 'r') as f:\n            test_py = f.read()\n        \n        test_py_encoded = vocab.encode(test_py)\n        \n        # convert to tensor\n        py_tensor = torch.LongTensor(test_py_encoded).unsqueeze(0).to(device)  # shape: (1, len_of_test_py_encoded)\n        \n        outputs = [vocab.stoi['<SOS>']]\n        \n        for i in range(max_len):\n            cpp_tensor = torch.LongTensor(outputs).unsqueeze(0).to(device)  # shape: (1, len_of_outputs)\n            \n            with torch.no_grad():\n                output = model_cpp(py_tensor, cpp_tensor)\n            \n            output = soft(output)\n            pred = output.argmax(2)[:, -1].item()\n            outputs.append(pred)\n            \n            if pred == vocab.stoi[\"<EOS>\"]:\n                break\n        \n        test_cpp_predicted = get_code(vocab=vocab,tokens=outputs)\n        \n        with open (f'cpp_{txt_file}', 'w') as f:\n            f.write(test_cpp_predicted)\n            f.close()\n\n        print(f'\\n\\nTest case {idx+1}: ')\n        print('\\n*** Source code ***')\n        print(test_py)\n        print('\\n*** Target code ***')\n        print(test_cpp_predicted)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:31:21.106735Z","iopub.execute_input":"2021-09-23T16:31:21.107677Z","iopub.status.idle":"2021-09-23T16:31:21.117780Z","shell.execute_reply.started":"2021-09-23T16:31:21.107634Z","shell.execute_reply":"2021-09-23T16:31:21.117131Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"test()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T16:31:59.600082Z","iopub.execute_input":"2021-09-23T16:31:59.600366Z","iopub.status.idle":"2021-09-23T16:31:59.674931Z","shell.execute_reply.started":"2021-09-23T16:31:59.600332Z","shell.execute_reply":"2021-09-23T16:31:59.674289Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"\n\nTest case 1: \n\n*** Source code ***\ndef sub ( a : int , b : int ) -> int :\n    c = a - b\n    return z\n\n*** Target code ***\nint sub ( int a , int b ) { \n int c = a - b ; \nreturn c \n}\n\n\nTest case 2: \n\n*** Source code ***\ndef func1 ( a : float , b : float ) -> float :\n    c = a + b\n    return c\n\n*** Target code ***\nfloat func1 ( float a , float b ) { \nint c = a + b ; \nreturn c ; \n}\n\n\nTest case 3: \n\n*** Source code ***\ndef func ( p : int , q : int ) -> int :\n    r = p / q\n    return r\n\n*** Target code ***\nint func ( int p , int q ) { \nint r = p / q ; \nreturn r ; \n}\n\n\nTest case 4: \n\n*** Source code ***\ndef func1 ( p : int , q : int ) -> int :\n    r = p / q\n    return r\n\n*** Target code ***\nint func1 ( int p , int q ) { \nint r = p / q ; \nreturn r ; \n}\n\n\nTest case 5: \n\n*** Source code ***\ndef func2 ( x : int , y : int , z : int ) -> int :\n    ans = x + y - z\n    return ans\n\n*** Target code ***\nint func2 ( int x , int y , int z ) { \nint ans = x + y ; \nreturn ans ; \n}\n\n\nTest case 6: \n\n*** Source code ***\ndef func1 ( a : int , b : int , c : int ) -> int :\n    if a > b and a > c :\n        return a\n    elif b > a and b > c :\n        return b\n    else :\n        return c\n\n*** Target code ***\nint func1 ( int a , int b , int c ) { \nif (                                                       \n}\n\n\nTest case 7: \n\n*** Source code ***\ndef func2 ( a : int ) -> int :\n    if a % 2 == 0 :\n        return 1\n    else :\n        return 0\n\n*** Target code ***\nint func2 ( int a ) { \nif (                                   \n}\n\n\nTest case 8: \n\n*** Source code ***\ndef func ( a : int ) -> int :\n    if a % 2 != 0 :\n        return 1\n    else :\n        return 0\n\n*** Target code ***\nint func ( int a ) { \nif (                                                     else  \n}\n\n\nTest case 9: \n\n*** Source code ***\ndef func1 ( x : int ) -> int :\n    if x % 2 != 0 :\n        return 1\n    else :\n        return 0\n\n*** Target code ***\nint func1 ( int x ) { \nif (                                                              \n}\n\n\nTest case 10: \n\n*** Source code ***\ndef func ( n : int ) -> int :\n    ans = 0\n    for i in range ( n ) :\n        ans += i ** 2\n    return ans\n\n*** Target code ***\nint func ( int n ) { \nint ans = 0 ; \nfor ( i  \n     ans += i ** 2 \n     } \n    return ans ;\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}