{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Author: Palash Kamble\n## E9 309 Advanced Deep Learning Project_1","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"# PyTorch Libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"_uuid":"700f9b3c-c709-41f3-8d91-d5c4d3dbb555","_cell_guid":"50320a47-87dd-4d39-aa37-20b07f243589","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-23T07:18:10.113142Z","iopub.execute_input":"2021-09-23T07:18:10.113725Z","iopub.status.idle":"2021-09-23T07:18:10.118104Z","shell.execute_reply.started":"2021-09-23T07:18:10.113687Z","shell.execute_reply":"2021-09-23T07:18:10.117157Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:12.110736Z","iopub.execute_input":"2021-09-23T07:18:12.111291Z","iopub.status.idle":"2021-09-23T07:18:12.114882Z","shell.execute_reply.started":"2021-09-23T07:18:12.111254Z","shell.execute_reply":"2021-09-23T07:18:12.114198Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:12.621586Z","iopub.execute_input":"2021-09-23T07:18:12.622251Z","iopub.status.idle":"2021-09-23T07:18:12.625541Z","shell.execute_reply.started":"2021-09-23T07:18:12.622216Z","shell.execute_reply":"2021-09-23T07:18:12.624741Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Loading Dataset","metadata":{}},{"cell_type":"code","source":"dataset_dir = '../input/d/palash97/translate-code/Dataset'\ntrain_dir = dataset_dir + '/Train'\nval_dir = dataset_dir + '/Val'\ntest_dir = dataset_dir + '/Test'\n\ntrain_py_dir = train_dir + '/python'\nval_py_dir = val_dir + '/python'\ntest_py_dir = test_dir + '/python'\n\ntrain_cpp_dir = train_dir + '/cpp'\nval_cpp_dir = val_dir + '/cpp'","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:12.774615Z","iopub.execute_input":"2021-09-23T07:18:12.775244Z","iopub.status.idle":"2021-09-23T07:18:12.780165Z","shell.execute_reply.started":"2021-09-23T07:18:12.775211Z","shell.execute_reply":"2021-09-23T07:18:12.779361Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Listing files from training python directory\npy_files = os.listdir(train_py_dir)\nprint(py_files[:5]) # printing first 5 file names ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:12.882412Z","iopub.execute_input":"2021-09-23T07:18:12.883133Z","iopub.status.idle":"2021-09-23T07:18:12.899531Z","shell.execute_reply.started":"2021-09-23T07:18:12.883098Z","shell.execute_reply":"2021-09-23T07:18:12.898778Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Listing files from training cpp directory\ncpp_files = os.listdir(train_cpp_dir)\nprint(cpp_files[:5]) # printing first 5 file names ","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:12.985322Z","iopub.execute_input":"2021-09-23T07:18:12.987556Z","iopub.status.idle":"2021-09-23T07:18:13.004255Z","shell.execute_reply.started":"2021-09-23T07:18:12.987512Z","shell.execute_reply":"2021-09-23T07:18:13.003543Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(f'Number of files in python directory: {len(py_files)}')\nprint(f'Number of files in cpp directory: {len(cpp_files)}')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.048661Z","iopub.execute_input":"2021-09-23T07:18:13.049246Z","iopub.status.idle":"2021-09-23T07:18:13.055758Z","shell.execute_reply.started":"2021-09-23T07:18:13.049198Z","shell.execute_reply":"2021-09-23T07:18:13.054261Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Printing one source and target code\npy_txt_file = os.path.join(train_py_dir, 'p_10.txt')\ncpp_txt_file = os.path.join(train_cpp_dir, 'c_10.txt')\n\nwith open (py_txt_file, 'r') as f:\n    py_txt = f.read()\n    \nwith open (cpp_txt_file, 'r') as f:\n    cpp_txt = f.read()\n\nprint('** Source Code **\\n')\nprint(py_txt)\nprint('\\n** Target Code **\\n')\nprint(cpp_txt)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.157782Z","iopub.execute_input":"2021-09-23T07:18:13.158040Z","iopub.status.idle":"2021-09-23T07:18:13.170905Z","shell.execute_reply.started":"2021-09-23T07:18:13.158014Z","shell.execute_reply":"2021-09-23T07:18:13.170018Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Pre-Processing and Tokenization","metadata":{}},{"cell_type":"code","source":"def tokenize(txt):\n    txt_split = txt.split(' ')\n    tokens = []\n    for tok in txt_split:\n        if '\\n' in tok:\n            for idx in range( len ( tok ) ) :\n                tokens.append(tok[idx])\n        else:\n            tokens.append(tok)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.355444Z","iopub.execute_input":"2021-09-23T07:18:13.355671Z","iopub.status.idle":"2021-09-23T07:18:13.364470Z","shell.execute_reply.started":"2021-09-23T07:18:13.355643Z","shell.execute_reply":"2021-09-23T07:18:13.363638Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Create Vocabulary","metadata":{}},{"cell_type":"code","source":"class Vocabulary(object):\n    def __init__(self):\n        self.freqs = {}\n        self.itos = {0: \"<UNK>\", 1: \"<PAD>\", 2: \"<SOS>\", 3: \"<EOS>\"}\n        self.stoi = {\"<UNK>\": 0, \"<PAD>\": 1, \"<SOS>\": 2, \"<EOS>\": 3}\n    \n    def build_vocabulary(self, py_dir, cpp_dir, threshold=1):\n        idx = 4\n        \n        for i in range(26):\n            ch = chr(97+i)\n            ch = str(ch)\n            self.freqs[ch] = 1\n            self.stoi[ch] = idx\n            self.itos[idx] = ch\n            idx += 1\n        \n        extra_functions = ['sub', 'func1', 'func2']\n        for extra_func in extra_functions:\n            self.freqs[extra_func] = 1\n            self.stoi[extra_func] = idx\n            self.itos[idx] = extra_func\n            idx += 1\n    \n        num_files = len(os.listdir(py_dir)) # number of files in py_dir is same as in cpp_dir\n        for i in range(1, num_files + 1):\n            py_file = os.path.join(py_dir, f'p_{i}.txt')\n            cpp_file = os.path.join(cpp_dir, f'c_{i}.txt')\n            \n            with open (py_file, 'r') as f:\n                py_txt = f.read()\n            with open (cpp_file, 'r') as f:\n                cpp_txt = f.read()\n            \n            py_tokens = tokenize(py_txt)\n            cpp_tokens = tokenize(cpp_txt)\n            \n            for tok in py_tokens:\n                if tok not in self.freqs:\n                    self.freqs[tok] = 1\n                else:\n                    self.freqs[tok] += 1\n                if self.freqs[tok] == threshold:\n                    self.stoi[tok] = idx\n                    self.itos[idx] = tok\n                    idx += 1\n            for tok in cpp_tokens:\n                if tok not in self.freqs:\n                    self.freqs[tok] = 1\n                else:\n                    self.freqs[tok] += 1\n                if self.freqs[tok] == threshold:\n                    self.stoi[tok] = idx\n                    self.itos[idx] = tok\n                    idx += 1\n    \n    def encode(self, text):\n        tokens = tokenize(text)\n        tokens_to_indices = [self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] for token in tokens]\n        tokens_to_indices = [self.stoi['<SOS>']] + tokens_to_indices + [self.stoi['<EOS>']]\n        return tokens_to_indices","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.516900Z","iopub.execute_input":"2021-09-23T07:18:13.517478Z","iopub.status.idle":"2021-09-23T07:18:13.537250Z","shell.execute_reply.started":"2021-09-23T07:18:13.517436Z","shell.execute_reply":"2021-09-23T07:18:13.536519Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"vocab = Vocabulary()\nvocab.build_vocabulary(train_py_dir, train_cpp_dir)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.539761Z","iopub.execute_input":"2021-09-23T07:18:13.540014Z","iopub.status.idle":"2021-09-23T07:18:13.805166Z","shell.execute_reply.started":"2021-09-23T07:18:13.539983Z","shell.execute_reply":"2021-09-23T07:18:13.804424Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(vocab.stoi)\nprint(f'Number of tokens in vocabulary: {vocab_size}')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.806638Z","iopub.execute_input":"2021-09-23T07:18:13.806975Z","iopub.status.idle":"2021-09-23T07:18:13.811857Z","shell.execute_reply.started":"2021-09-23T07:18:13.806939Z","shell.execute_reply":"2021-09-23T07:18:13.811171Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"print(vocab.stoi) # token and its corresponding index","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.813127Z","iopub.execute_input":"2021-09-23T07:18:13.813528Z","iopub.status.idle":"2021-09-23T07:18:13.825140Z","shell.execute_reply.started":"2021-09-23T07:18:13.813494Z","shell.execute_reply":"2021-09-23T07:18:13.824239Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(vocab.itos) # index and its corresponding token","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.826924Z","iopub.execute_input":"2021-09-23T07:18:13.827184Z","iopub.status.idle":"2021-09-23T07:18:13.834398Z","shell.execute_reply.started":"2021-09-23T07:18:13.827150Z","shell.execute_reply":"2021-09-23T07:18:13.833581Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Create Custom Dataset","metadata":{}},{"cell_type":"code","source":"class TransCompilerDataset(Dataset):\n    def __init__(self, py_dir, cpp_dir, vocab):\n        self.py_dir = py_dir\n        self.cpp_dir = cpp_dir\n        self.vocab = vocab\n    \n    def __len__(self):\n        return len(os.listdir(self.py_dir))\n    \n    def __getitem__(self, index):\n        py_file = os.path.join(self.py_dir, f'p_{index+1}.txt')\n        cpp_file = os.path.join(self.cpp_dir, f'c_{index+1}.txt')\n        \n        with open (py_file, 'r') as f:\n            py_txt = f.read()\n        \n        with open (cpp_file, 'r') as f:\n            cpp_txt = f.read()\n        \n        py_encoded = vocab.encode(py_txt)\n        cpp_encoded = vocab.encode(cpp_txt)\n        \n        return torch.tensor(py_encoded), torch.tensor(cpp_encoded)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:13.969386Z","iopub.execute_input":"2021-09-23T07:18:13.969599Z","iopub.status.idle":"2021-09-23T07:18:13.979298Z","shell.execute_reply.started":"2021-09-23T07:18:13.969574Z","shell.execute_reply":"2021-09-23T07:18:13.978545Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class Collate():\n    def __init__(self, pad_idx):\n        self.pad_idx = pad_idx\n    \n    def __call__(self, batch):\n        (py, cpp) = zip(*batch)\n        \n        py_pad = pad_sequence(py, batch_first=True, padding_value=self.pad_idx)\n        cpp_pad = pad_sequence(cpp, batch_first=True, padding_value=self.pad_idx)\n        return py_pad, cpp_pad","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.101556Z","iopub.execute_input":"2021-09-23T07:18:14.101774Z","iopub.status.idle":"2021-09-23T07:18:14.107419Z","shell.execute_reply.started":"2021-09-23T07:18:14.101749Z","shell.execute_reply":"2021-09-23T07:18:14.106747Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def get_loaders(train_py_dir, train_cpp_dir, val_py_dir, val_cpp_dir, vocab):\n    train_dataset = TransCompilerDataset(train_py_dir, train_cpp_dir, vocab)\n    val_dataset = TransCompilerDataset(val_py_dir, val_cpp_dir, vocab)\n    pad_idx = vocab.stoi['<PAD>']\n    train_loader = DataLoader(train_dataset, batch_size = 10, shuffle=True, collate_fn=Collate(pad_idx))\n    val_loader = DataLoader(val_dataset, batch_size = 10, shuffle=True, collate_fn=Collate(pad_idx))\n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.121610Z","iopub.execute_input":"2021-09-23T07:18:14.122081Z","iopub.status.idle":"2021-09-23T07:18:14.126881Z","shell.execute_reply.started":"2021-09-23T07:18:14.122052Z","shell.execute_reply":"2021-09-23T07:18:14.126199Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train_loader, val_loader = get_loaders(train_py_dir, train_cpp_dir, val_py_dir, val_cpp_dir, vocab)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.228063Z","iopub.execute_input":"2021-09-23T07:18:14.228530Z","iopub.status.idle":"2021-09-23T07:18:14.237207Z","shell.execute_reply.started":"2021-09-23T07:18:14.228502Z","shell.execute_reply":"2021-09-23T07:18:14.236475Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(len(train_loader))\nprint(len(val_loader))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.286562Z","iopub.execute_input":"2021-09-23T07:18:14.286747Z","iopub.status.idle":"2021-09-23T07:18:14.292197Z","shell.execute_reply.started":"2021-09-23T07:18:14.286726Z","shell.execute_reply":"2021-09-23T07:18:14.291457Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"for idx, (py, cpp) in enumerate(train_loader):\n    print(f'Shape of py: {py.shape}')      # batch_size x src_seq_len\n    print(f'Shape of cpp: {cpp.shape}')    # batch_size x trg_seq_len\n    break","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.396884Z","iopub.execute_input":"2021-09-23T07:18:14.397490Z","iopub.status.idle":"2021-09-23T07:18:14.441569Z","shell.execute_reply.started":"2021-09-23T07:18:14.397458Z","shell.execute_reply":"2021-09-23T07:18:14.440738Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Ready to build transformer architecture!!!","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.450994Z","iopub.execute_input":"2021-09-23T07:18:14.451179Z","iopub.status.idle":"2021-09-23T07:18:14.454570Z","shell.execute_reply.started":"2021-09-23T07:18:14.451158Z","shell.execute_reply":"2021-09-23T07:18:14.453665Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Building Transformer Architecture","metadata":{}},{"cell_type":"markdown","source":"#### Building Attention Mechanism","metadata":{}},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def __init__(self, embed_size, heads):\n        super(SelfAttention, self).__init__()\n        self.embed_size = embed_size\n        self.heads = heads\n        self.head_dim = embed_size // heads\n\n        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n        \n        self.fc_out = nn.Linear(self.head_dim * self.heads, embed_size)   # concatenating heads\n        \n    def forward(self, queries, keys, values, mask):\n        # queries, keys, values => shape (N, seq_len, embed_size)\n        # mask => shape (N, 1, 1, src_seq_len)\n        N = queries.shape[0] # N = Batch_size\n        query_len, key_len, value_len = queries.shape[1], keys.shape[1], values.shape[1]   # same as seq length\n        \n        # splitting embedding into heads\n        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n        values = values.reshape(N, value_len, self.heads, self.head_dim)\n        \n        \n        # Step 1: Create query, key, value matrices (for each head)\n        queries = self.queries(queries) # (N, query_len, heads, head_dim)\n        keys = self.queries(keys)       # (N, key_len, heads, head_dim)\n        values = self.queries(values)   # (N, value_len, heads, head_dim) \n        \n        # Step 2: Calculate the scores for each tokens against all tokens (dot query and key)\n        query_key_score = torch.einsum(\"nqhd, nkhd -> nhqk\", [queries, keys])   # (N, heads, query_len, key_len)\n        \n        # Step 2.1 : If mask is set (needed in decoder), then mask upper right triangle matrix with negative infiniy\n        if mask is not None:\n            query_key_score = query_key_score.masked_fill(mask == 0, float('-1e20'))\n        \n        # Step 3: Calculate softmax score\n        softmax_score = torch.softmax(query_key_score / (self.embed_size ** 0.5), dim=3) # (N, heads, query_len, key_len)\n        \n        # Step 4: Calculate weighted values\n        attention = torch.einsum(\"nhql, nvhd -> nqhd\", [softmax_score, values])   # (N, query_len, heads, head_dim)\n        attention = attention.reshape(N, query_len, self.head_dim * self.heads) # (N, query_len ,embed_size)\n        \n        # Step 5: Concatenating heads\n        out = self.fc_out(attention)\n        return out     # (N, query_len, embed_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.744168Z","iopub.execute_input":"2021-09-23T07:18:14.744574Z","iopub.status.idle":"2021-09-23T07:18:14.757905Z","shell.execute_reply.started":"2021-09-23T07:18:14.744542Z","shell.execute_reply":"2021-09-23T07:18:14.757148Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Testing self attention\nattention = SelfAttention(512, 8)\nq = torch.randn(5, 100, 512)\nk = torch.randn(5, 100, 512)\nv = torch.randn(5, 100, 512)\nm = torch.randn(5, 1, 100, 100)\nout = attention(q,k,v,m)\nprint(out.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.788610Z","iopub.execute_input":"2021-09-23T07:18:14.788818Z","iopub.status.idle":"2021-09-23T07:18:14.864829Z","shell.execute_reply.started":"2021-09-23T07:18:14.788779Z","shell.execute_reply":"2021-09-23T07:18:14.864059Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"#### Building Transformer Block","metadata":{}},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, embed_size, heads, forward_expansion, dropout=0.5):\n        super(TransformerBlock, self).__init__()\n        self.attention = SelfAttention(embed_size, heads)\n        self.layer_norm1 = nn.LayerNorm(embed_size)\n        self.layer_norm2 = nn.LayerNorm(embed_size)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(embed_size, forward_expansion * embed_size),\n            nn.ReLU(),\n            nn.Linear(forward_expansion * embed_size, embed_size)\n        )\n        \n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, query, key, value, mask):\n        attention = self.attention(query, key, value, mask)\n        \n        # Step1: Skip connection\n        x = attention + query\n        \n        # Step2: Layer norm\n        x = self.layer_norm1(x)\n        \n        # Step3: Dropout\n        x = self.dropout(x)\n        \n        # Step4: Feed forward\n        forward = self.feed_forward(x)\n        \n        # Step5: Same as above from step 1 to step 3\n        out = self.dropout(self.layer_norm2(forward + x))\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:14.955409Z","iopub.execute_input":"2021-09-23T07:18:14.955941Z","iopub.status.idle":"2021-09-23T07:18:14.966004Z","shell.execute_reply.started":"2021-09-23T07:18:14.955910Z","shell.execute_reply":"2021-09-23T07:18:14.965237Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"#### Building Encoder Architecture (stacking Transformer Blocks)\n","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, vocab_size, embed_size, num_layers, heads, device, forward_expansion, max_len, drop=0.5):\n        super(Encoder, self).__init__()\n        self.embed_size = embed_size\n        self.device = device\n        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n        self.pos_embedding = nn.Embedding(max_len, embed_size)\n        self.dropout = nn.Dropout(drop)\n        \n        self.layers = nn.ModuleList(\n            [\n                TransformerBlock(embed_size, heads, forward_expansion, drop)\n                for _ in range(num_layers)\n            ]\n        )\n        \n    def forward(self, x, mask):\n        # Shape of x : (batch_size x src_seq_len)\n        # shape of mask: (batch_size, 1, 1, src_seq_len)\n        batch_size, seq_len = x.shape\n        positions = torch.arange(0, seq_len).expand(batch_size, seq_len).to(self.device)\n        out = self.word_embedding(x) + self.pos_embedding(positions)\n        out = self.dropout(out)     # (N, src_seq_len, embed_size)\n        \n        \n        for layer in self.layers:\n            # query, key, value inputs are same for each transformer block from\n            # their previous transformer block, except in the beginning that is positional encodings\n            out = layer(out, out, out, mask)\n        return out      # (N, src_seq_len, embed_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.177531Z","iopub.execute_input":"2021-09-23T07:18:15.178036Z","iopub.status.idle":"2021-09-23T07:18:15.188260Z","shell.execute_reply.started":"2021-09-23T07:18:15.178001Z","shell.execute_reply":"2021-09-23T07:18:15.187349Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"#### Building Decoder Architecture","metadata":{}},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, embed_size ,heads, forward_expansion, device, drop=0.5):\n        super(DecoderBlock, self).__init__()\n        self.norm = nn.LayerNorm(embed_size)\n        self.attention = SelfAttention(embed_size ,heads)\n        self.transformer_block = TransformerBlock(embed_size, heads, forward_expansion, drop)\n        self.dropout = nn.Dropout(drop)\n    \n    def forward(self, x, value, key, src_mask, trg_mask):\n        attention = self.attention(x,x,x,trg_mask)\n        query = self.dropout(self.norm(attention + x))\n        out = self.transformer_block(query, key, value, src_mask)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.285973Z","iopub.execute_input":"2021-09-23T07:18:15.286542Z","iopub.status.idle":"2021-09-23T07:18:15.293692Z","shell.execute_reply.started":"2021-09-23T07:18:15.286510Z","shell.execute_reply":"2021-09-23T07:18:15.292762Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, vocab_size, embed_size, num_layers, heads, device, forward_expansion, max_len, drop=0.5,):\n        super(Decoder, self).__init__()\n        self.device = device\n        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n        self.pos_embedding = nn.Embedding(max_len, embed_size)\n        \n        self.layers = nn.ModuleList(\n            [\n                DecoderBlock(embed_size, heads, forward_expansion, device, drop)\n                for _ in range(num_layers)\n            ]\n        )\n        \n        self.fc_out = nn.Linear(embed_size, vocab_size)\n        self.dropout = nn.Dropout(drop)\n    \n    def forward(self, x, enc_out, src_mask, trg_mask):\n        # enc_out => shape (N, src_seq_len, embed_size)\n        # src_mask => shape (N, 1, 1, seq_len)\n        # trg_mask => shape (N, 1, seq_len, seq_len)\n        batch_size, seq_len = x.shape\n        positions = torch.arange(0, seq_len).expand(batch_size, seq_len).to(self.device)\n        x = self.dropout(self.word_embedding(x) + self.pos_embedding(positions))\n        value = enc_out\n        key = enc_out\n        for layer in self.layers:\n            x = layer(x, value, key, src_mask, trg_mask)\n        \n        out = self.fc_out(x)\n        return out   # (N, trg_len, vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.380241Z","iopub.execute_input":"2021-09-23T07:18:15.380793Z","iopub.status.idle":"2021-09-23T07:18:15.391224Z","shell.execute_reply.started":"2021-09-23T07:18:15.380762Z","shell.execute_reply":"2021-09-23T07:18:15.390549Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"#### Putting it all together","metadata":{}},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, vocab_size, pad_idx, embed_size=512, num_layers=6, forward_expansion=4, heads=8, dropout=0, device=\"cpu\", max_len=350):\n        super(Transformer, self).__init__()\n        \n        self.encoder = Encoder(vocab_size, embed_size, num_layers, heads, device, forward_expansion, max_len ,dropout)\n        self.decoder = Decoder(vocab_size ,embed_size, num_layers, heads, device, forward_expansion, max_len, dropout)\n        self.pad_idx = pad_idx\n        self.device = device\n    \n    def make_src_mask(self, src):\n        # shape of src : (N, seq_len)\n        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)\n        return src_mask.to(self.device)\n\n    def make_trg_mask(self, trg):\n        # shape of trg: (N, seq_len)\n        batch_size, seq_len = trg.shape\n        # fill lower triangular matrix\n        trg_mask = torch.tril(torch.ones((seq_len, seq_len))).expand(batch_size, 1, seq_len, seq_len)\n        return trg_mask.to(device)\n\n    def forward(self, src, trg):\n        # Shape of src: (batch_size x src_seq_len)\n        # Shape of trg: (batch_size x trg_seq_len)\n        src_mask = self.make_src_mask(src)\n        trg_mask = self.make_trg_mask(trg)\n        enc_out = self.encoder(src, src_mask)\n        out = self.decoder(trg, enc_out, src_mask, trg_mask)\n        return out  # (batch_size x trg_seq_len x vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.534902Z","iopub.execute_input":"2021-09-23T07:18:15.535470Z","iopub.status.idle":"2021-09-23T07:18:15.546878Z","shell.execute_reply.started":"2021-09-23T07:18:15.535439Z","shell.execute_reply":"2021-09-23T07:18:15.546072Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"#### Testing Transformer Architecture","metadata":{}},{"cell_type":"code","source":"# Setting device to cuda if available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.709630Z","iopub.execute_input":"2021-09-23T07:18:15.709898Z","iopub.status.idle":"2021-09-23T07:18:15.767579Z","shell.execute_reply.started":"2021-09-23T07:18:15.709854Z","shell.execute_reply":"2021-09-23T07:18:15.766712Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"batch_size = 5\nsrc_seq_len = 100\ntrg_seq_len = 150\npad_idx = 0\nvocab_size = 10\n\nx = torch.randint(0, vocab_size, (batch_size, src_seq_len)).to(device)\ntrg = torch.randint(0, vocab_size, (batch_size, trg_seq_len)).to(device)\nmodel = Transformer(vocab_size, pad_idx, device=device).to(device)\nout = model(x, trg[:, :-1])\nprint(out.shape)   # (batch_size, (trg_seq_len-1), vocab_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:15.801489Z","iopub.execute_input":"2021-09-23T07:18:15.802065Z","iopub.status.idle":"2021-09-23T07:18:20.951444Z","shell.execute_reply.started":"2021-09-23T07:18:15.802034Z","shell.execute_reply":"2021-09-23T07:18:20.950561Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"vocab_size = len(vocab.stoi)\nembed_size = 256\nnum_layers = 6\nheads = 8\nforward_expansion = 4\ndropout = 0.2\nmax_len = 250\npad_idx = vocab.stoi['<PAD>']\nlr = 3e-5\nepochs = 100","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:20.953163Z","iopub.execute_input":"2021-09-23T07:18:20.953622Z","iopub.status.idle":"2021-09-23T07:18:20.958713Z","shell.execute_reply.started":"2021-09-23T07:18:20.953584Z","shell.execute_reply":"2021-09-23T07:18:20.957824Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"# Function to plot loss\ndef plot_loss(loss,epochs,val_loss=None):\n    plt.title('Plot of training loss')\n    plt.plot(loss, c='r', label='training_loss')\n    if val_loss is not None:\n        plt.plot(val_loss, c='g', label='validation_loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig(f'loss.png')\n    plt.show()\n    \n# Function to save checkpoint\ndef save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n\n\n# Function to load checkpoint\ndef load_checkpoint(checkpoint, model, optimizer):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    \n    \n# Function to convert tokens to code\ndef get_code(vocab, tokens):\n    tok_list = []\n    for tok in tokens:\n        if tok == vocab.stoi[\"<SOS>\"] or tok == vocab.stoi[\"<EOS>\"]:\n            continue\n        tok_list.append(vocab.itos[tok])\n    return ' '.join(tok_list)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:20.960282Z","iopub.execute_input":"2021-09-23T07:18:20.960852Z","iopub.status.idle":"2021-09-23T07:18:20.975852Z","shell.execute_reply.started":"2021-09-23T07:18:20.960684Z","shell.execute_reply":"2021-09-23T07:18:20.975194Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## Instantiating model","metadata":{}},{"cell_type":"code","source":"model_cpp = Transformer(vocab_size = vocab_size, \n                    pad_idx = pad_idx,\n                    embed_size = embed_size,\n                    num_layers = num_layers,\n                    forward_expansion = forward_expansion,\n                    heads = heads,\n                    max_len = max_len,\n                    dropout = dropout,\n                    device=device).to(device)\nmodel_py = Transformer(vocab_size = vocab_size, \n                    pad_idx = pad_idx,\n                    embed_size = embed_size,\n                    num_layers = num_layers,\n                    forward_expansion = forward_expansion,\n                    heads = heads,\n                    max_len = max_len,\n                    dropout = dropout,\n                    device=device).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:20.977904Z","iopub.execute_input":"2021-09-23T07:18:20.978187Z","iopub.status.idle":"2021-09-23T07:18:21.150932Z","shell.execute_reply.started":"2021-09-23T07:18:20.978153Z","shell.execute_reply":"2021-09-23T07:18:21.150119Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## Defining loss function and optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n# optimizer_cpp = optim.SGD(model_cpp.parameters(), lr=lr)\n# optimizer_py = optim.SGD(model_py.parameters(), lr=lr)\n\noptimizer_cpp = optim.Adam(model_cpp.parameters(), lr=lr, betas=(0.9, 0.99))\noptimizer_py = optim.Adam(model_py.parameters(), lr=lr, betas=(0.9, 0.99))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:21.152572Z","iopub.execute_input":"2021-09-23T07:18:21.152981Z","iopub.status.idle":"2021-09-23T07:18:21.165038Z","shell.execute_reply.started":"2021-09-23T07:18:21.152945Z","shell.execute_reply":"2021-09-23T07:18:21.164181Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"def train():\n\n    train_loss = []\n    val_loss = []\n    best_val_loss = np.inf\n    \n    for epoch in range(1, epochs+1):\n        model.train()\n        losses = []\n        for batch_idx, (py_src, cpp_trg) in enumerate(train_loader):\n            # Put on cuda if available\n            py_src = py_src.to(device)   # (batch_size, src_seq_len)\n            cpp_trg = cpp_trg.to(device)\n            \n            # Forward pass\n            output_cpp = model_cpp(py_src, cpp_trg[:, :-1])  # shape (batch_size, (tgr_seq_len-1), vocab_size)\n            \n            out_cpp = output_cpp.reshape(-1, vocab_size)  # [batch_size * (trg_seq_len-1), vocab_size]\n            target = cpp_trg[:, 1:]  # (batch_size, trg_seq_len - 1)\n            target = target.reshape(-1)    # [batch_size x (trg_seq_len - 1)]\n            \n            loss_cpp = criterion(out_cpp, target)\n            \n            output_py = model_py(cpp_trg, py_src[:, :-1])\n            out_py = output_py.reshape(-1, vocab_size)\n            target = py_src[:, 1:]\n            target = target.reshape(-1)\n            \n            loss_py = criterion(out_py, target)\n            \n            \n            # Cycle consistency\n            \n            ## generated_cpp to reconstruct_python code\n            gen_cpp = torch.full((output_cpp.shape[0],output_cpp.shape[1]+1), vocab.stoi[\"<SOS>\"]).to(device)\n            gen_cpp[:, 1:] = output_cpp.argmax(2)\n            gen_cpp[:, -1] = vocab.stoi[\"<EOS>\"]\n            \n            rec_py = model_py(gen_cpp, py_src[:, :-1])\n            rec_py = rec_py.reshape(-1, vocab_size)\n            target = py_src[:, 1:]\n            target = target.reshape(-1)\n            \n            loss_rec_py = criterion(rec_py, target)\n            \n            ## generated_py to reconstruct_cpp code\n            gen_py = torch.full((output_py.shape[0],output_py.shape[1]+1), vocab.stoi[\"<SOS>\"]).to(device)\n            gen_py[:, 1:] = output_py.argmax(2)\n            gen_py[:, -1] = vocab.stoi[\"<EOS>\"]\n            \n            rec_cpp = model_py(gen_py, cpp_trg[:, :-1])\n            rec_cpp = rec_cpp.reshape(-1, vocab_size)\n            target = cpp_trg[:, 1:]\n            target = target.reshape(-1)\n            \n            loss_rec_cpp = criterion(rec_cpp, target)\n            \n            loss =  0.25 * ( loss_cpp + loss_py + loss_rec_py + loss_rec_cpp )\n            \n            losses.append(loss.item())\n            \n            # Clear the gradients\n            optimizer_cpp.zero_grad()\n            optimizer_py.zero_grad()\n            \n            # Backward pass\n            loss.backward()\n            optimizer_cpp.step()\n            optimizer_py.step()\n        \n        mean_train_loss = sum(losses) / len(losses)\n        train_loss.append(mean_train_loss)\n      \n        model.eval()\n        losses = []\n        for batch_idx, (py, cpp) in enumerate(val_loader):\n            py = py.to(device)\n            cpp = cpp.to(device)\n\n            output = model_cpp(py, cpp[:, :-1])\n\n            output = output.reshape(-1, vocab_size)  # [batch_size * (trg_seq_len-1), vocab_size]\n            target = cpp[:, 1:]  # (batch_size, trg_seq_len - 1)\n            target = target.reshape(-1)    # [batch_size x (trg_seq_len - 1)]\n\n            # Calculate loss\n            loss = criterion(output, target)\n            losses.append(loss.item())\n        mean_val_loss = sum(losses) / len(losses)\n        val_loss.append(mean_val_loss)\n        \n        print(f'Epoch: {epoch}/{epochs}\\tTraining Loss: {mean_train_loss:.6f}\\tValidation Loss: {mean_val_loss:.6f}')\n        \n        if mean_val_loss < best_val_loss:\n            print('Validation loss decreased. Saving model params...')\n            best_val_loss = mean_val_loss\n            checkpoint = {\n                \"state_dict\": model_cpp.state_dict(),\n                \"optimizer\": optimizer_cpp.state_dict(),\n            }\n            save_checkpoint(checkpoint)\n        \n    return train_loss, val_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:21.166298Z","iopub.execute_input":"2021-09-23T07:18:21.166550Z","iopub.status.idle":"2021-09-23T07:18:21.187789Z","shell.execute_reply.started":"2021-09-23T07:18:21.166516Z","shell.execute_reply":"2021-09-23T07:18:21.187132Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"train_loss, val_loss = train()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:18:21.189065Z","iopub.execute_input":"2021-09-23T07:18:21.189315Z","iopub.status.idle":"2021-09-23T07:21:14.727670Z","shell.execute_reply.started":"2021-09-23T07:18:21.189280Z","shell.execute_reply":"2021-09-23T07:21:14.726928Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"plot_loss(train_loss, epochs, val_loss)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:21:35.621863Z","iopub.execute_input":"2021-09-23T07:21:35.622413Z","iopub.status.idle":"2021-09-23T07:21:35.912929Z","shell.execute_reply.started":"2021-09-23T07:21:35.622376Z","shell.execute_reply":"2021-09-23T07:21:35.912236Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"### Load best model","metadata":{}},{"cell_type":"code","source":"load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model_cpp, optimizer_cpp)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:21:46.814227Z","iopub.execute_input":"2021-09-23T07:21:46.815104Z","iopub.status.idle":"2021-09-23T07:21:46.960164Z","shell.execute_reply.started":"2021-09-23T07:21:46.815059Z","shell.execute_reply":"2021-09-23T07:21:46.959436Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def test(max_len=300):\n    model.eval()\n    test_py_dir = '../input/d/palash97/translate-code/Dataset/Test/python'    \n    txt_files = os.listdir(test_py_dir)\n    soft = nn.Softmax(dim=2)\n    \n    for idx, txt_file in enumerate(txt_files):\n        test_py_file = os.path.join(test_py_dir, txt_file)\n        with open (test_py_file, 'r') as f:\n            test_py = f.read()\n        \n        test_py_encoded = vocab.encode(test_py)\n        \n        # convert to tensor\n        py_tensor = torch.LongTensor(test_py_encoded).unsqueeze(0).to(device)  # shape: (1, len_of_test_py_encoded)\n        \n        outputs = [vocab.stoi['<SOS>']]\n        \n        for i in range(max_len):\n            cpp_tensor = torch.LongTensor(outputs).unsqueeze(0).to(device)  # shape: (1, len_of_outputs)\n            \n            with torch.no_grad():\n                output = model_cpp(py_tensor, cpp_tensor)\n            \n            output = soft(output)\n            pred = output.argmax(2)[:, -1].item()\n            outputs.append(pred)\n            \n            if pred == vocab.stoi[\"<EOS>\"]:\n                break\n        \n        test_cpp_predicted = get_code(vocab=vocab,tokens=outputs)\n        \n        with open (f'cpp_{txt_file}', 'w') as f:\n            f.write(test_cpp_predicted)\n            f.close()\n\n        print(f'\\n\\nTest case {idx+1}: ')\n        print('\\n*** Source code ***')\n        print(test_py)\n        print('\\n*** Target code ***')\n        print(test_cpp_predicted)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:23:09.939094Z","iopub.execute_input":"2021-09-23T07:23:09.939369Z","iopub.status.idle":"2021-09-23T07:23:09.949399Z","shell.execute_reply.started":"2021-09-23T07:23:09.939333Z","shell.execute_reply":"2021-09-23T07:23:09.948436Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"test()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T07:23:13.314652Z","iopub.execute_input":"2021-09-23T07:23:13.315341Z","iopub.status.idle":"2021-09-23T07:23:13.340608Z","shell.execute_reply.started":"2021-09-23T07:23:13.315304Z","shell.execute_reply":"2021-09-23T07:23:13.339961Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}