{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_with_Attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCTPsmJEGUyx"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSbr_dtvZNvY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import spacy\n",
        "import spacy.cli\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp2_zAtzTq3Y",
        "outputId": "aa60c375-e562-49bb-92d6-ef16a8dcad6d"
      },
      "source": [
        "spacy.cli.download('en_core_web_md')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SACbO5SxUIwV"
      },
      "source": [
        "spacy_eng = spacy.load('en_core_web_md')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saH6sbIzGW7V"
      },
      "source": [
        "## Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WksChklP9BGC"
      },
      "source": [
        "root_dir = '/content/drive/MyDrive/Datasets/Machine_Translation/Hindi_English_Truncated_Corpus.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4YsAwU6-XG3",
        "outputId": "aff7360f-6489-4362-963e-d5d0b5dda4a7"
      },
      "source": [
        "df = pd.read_csv(root_dir, encoding='utf-8')\n",
        "df = df.dropna()\n",
        "df = df[df['source']=='ted']\n",
        "print(len(df))\n",
        "print(df.head(10).iloc[:, 1:])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39881\n",
            "                                     english_sentence                                     hindi_sentence\n",
            "0   politicians do not have permission to do what ...  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...\n",
            "1          I'd like to tell you about one such child,  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...\n",
            "3   what we really mean is that they're bad at not...     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते\n",
            "7    And who are we to say, even, that they are wrong   और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं\n",
            "13                   So there is some sort of justice                                   तो वहाँ न्याय है\n",
            "23                                This changed slowly                               धीरे धीरे ये सब बदला\n",
            "26                               were being produced.                           उत्पन्न नहीं कि जाती थी.\n",
            "30        And you can see, this LED is going to glow.       और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।\n",
            "32  to turn on the lights or to bring him a glass ...    लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,\n",
            "35                       Can you imagine saying that?                       क्या आप ये कल्पना कर सकते है\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJCBT_bVHsuF",
        "outputId": "8842277b-9b59-4b32-8f87-01470c784526"
      },
      "source": [
        "print(df.iloc[0,1])\n",
        "print(df.iloc[0,2])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "politicians do not have permission to do what needs to be done.\n",
            "राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0VGImUhIap5",
        "outputId": "4f2ec8bd-da89-4b15-aebc-b8f8f6df7503"
      },
      "source": [
        "print(df.iloc[37554,1])\n",
        "print(df.iloc[37554,2])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "And they can afford to watch how we work -\n",
            "और वह वहां कर सकते हैं हमारे काम के तरीके को समझने में -\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtFKC0PnGRwK"
      },
      "source": [
        "## Create vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u72oKWHqAMa_"
      },
      "source": [
        "class Vocabulary():\n",
        "  def __init__(self, threshold=2):\n",
        "    self.threshold = threshold\n",
        "    self.freqs = {}\n",
        "    self.itos = {0: \"<unk>\", 1: \"<pad>\", 2: \"<sos>\", 3: \"<eos>\"}\n",
        "    self.stoi = {\"<unk>\": 0, \"<pad>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
        "  \n",
        "  def build_vocabulary(self, df, en):\n",
        "    idx = 4\n",
        "    if en:\n",
        "      for i in range(len(df)):\n",
        "        eng_text = df.iloc[i, 1]\n",
        "        tokens = [tok.text.lower() for tok in spacy_eng.tokenizer(eng_text)]\n",
        "        for token in tokens:\n",
        "          if token not in self.freqs:\n",
        "            self.freqs[token] = 1\n",
        "          else:\n",
        "            self.freqs[token] += 1\n",
        "          if self.freqs[token] == self.threshold:\n",
        "            self.stoi[token] = idx\n",
        "            self.itos[idx] = token\n",
        "            idx += 1\n",
        "    else:\n",
        "      for i in range(len(df)):\n",
        "        hindi_text = df.iloc[i, 2]\n",
        "        hindi_text = re.sub('r[?,:.]।', '', hindi_text)\n",
        "        for token in hindi_text.split(' '):\n",
        "          if token not in self.freqs:\n",
        "            self.freqs[token] = 1\n",
        "          else:\n",
        "            self.freqs[token] += 1\n",
        "          if self.freqs[token] == self.threshold:\n",
        "            self.stoi[token] = idx\n",
        "            self.itos[idx] = token\n",
        "            idx += 1\n",
        "\n",
        "  def numericalize(self, text, en):\n",
        "    if en:\n",
        "      tokens = [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
        "    else:\n",
        "      tokens = [token for token in text.lower().split(' ')]\n",
        "    \n",
        "    token_to_indices = [self.stoi[token] if token in self.stoi else self.stoi['<unk>'] for token in tokens]\n",
        "    token_to_indices = [self.stoi['<sos>']] + token_to_indices + [self.stoi['<eos>']]\n",
        "    return token_to_indices"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gzOuqywRUyA"
      },
      "source": [
        "en_vocab = Vocabulary()\n",
        "hi_vocab = Vocabulary()\n",
        "\n",
        "en_vocab.build_vocabulary(df, en=True)\n",
        "hi_vocab.build_vocabulary(df, en=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "___5FN-YNDqu",
        "outputId": "dc07e904-cecd-4d7f-a09a-fa31f3946fc3"
      },
      "source": [
        "input_vocab_size = len(en_vocab.stoi)\n",
        "output_vocab_size = len(hi_vocab.stoi)\n",
        "print(f'English vocab size: {input_vocab_size}')\n",
        "print(f'Hindi vocab size: {output_vocab_size}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English vocab size: 9133\n",
            "Hindi vocab size: 11833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK4Ku-KuR9Qp"
      },
      "source": [
        "## Create Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJNnh7RrRzV-"
      },
      "source": [
        "class MTDataset(Dataset):\n",
        "  def __init__(self, df, en_vocab, hi_voab):\n",
        "    self.df = df\n",
        "    self.en_vocab = en_vocab\n",
        "    self.hi_vocab = hi_vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(df)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    en_text = df.iloc[index, 1]\n",
        "    hi_text = df.iloc[index, 2]\n",
        "\n",
        "    en_numericalized = en_vocab.numericalize(en_text, en=True)\n",
        "    hi_numericalized = hi_vocab.numericalize(hi_text, en=False)\n",
        "\n",
        "    return torch.tensor(en_numericalized), torch.tensor(hi_numericalized)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh6SrxuVVr6l"
      },
      "source": [
        "class Collate():\n",
        "  def __init__(self, pad_idx):\n",
        "    self.pad_idx = pad_idx\n",
        "  \n",
        "  def __call__(self, batch):\n",
        "    (en, hi) = zip(*batch)\n",
        "    \n",
        "    en_pad = pad_sequence(en, batch_first=False, padding_value=self.pad_idx)\n",
        "    hi_pad = pad_sequence(hi, batch_first=False, padding_value=self.pad_idx)\n",
        "\n",
        "    return en_pad, hi_pad"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgVvH_AWUEHa"
      },
      "source": [
        "def get_loader(df, en_vocab, hi_vocab, batch_size=32, num_workers=2, shuffle=True, pin_memory=True):\n",
        "  dataset = MTDataset(df, en_vocab, hi_vocab)\n",
        "  train_size = int(0.8 * len(dataset))\n",
        "  test_size = len(dataset) - train_size\n",
        "  train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "  pad_idx = en_vocab.stoi[\"<pad>\"]\n",
        "  train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle, pin_memory=pin_memory, collate_fn=Collate(pad_idx))\n",
        "  test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, collate_fn=Collate(pad_idx))\n",
        "  return train_loader, test_loader"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnDMv8XcURdZ"
      },
      "source": [
        "train_loader, test_loader = get_loader(df, en_vocab, hi_vocab)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FN9aemXUcCQ",
        "outputId": "1192a5a7-5779-49d4-e283-f70a13e3b08e"
      },
      "source": [
        "print(len(train_loader))\n",
        "print(len(test_loader))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "997\n",
            "250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZr2Rz3-NMji"
      },
      "source": [
        "for idx, (en, hi) in enumerate(train_loader):\n",
        "  # shape of en: (eng_source_len, batch_size)\n",
        "  # shape of hi: (hindi_source_len, batch_size)\n",
        "  break\n",
        "for idx, (en, hi) in enumerate(test_loader):\n",
        "  # shape of en: (eng_source_len, batch_size)\n",
        "  # shape of hi: (hindi_source_len, batch_size)\n",
        "  break"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzNW8OR_QKj0"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CBuNyv-QKEP"
      },
      "source": [
        "def trace(x, name, arg='shape'):\n",
        "  if arg == 'shape':\n",
        "    print(f'Shape of {name}: {x.shape}')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf8305NrNqOG"
      },
      "source": [
        "## Building Encoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExPHUAMkNihE"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, embed_size, hidden_size, num_layers, drop_prob):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.embed_size = embed_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_size, embed_size)\n",
        "    self.rnn = nn.LSTM(embed_size, hidden_size, num_layers, bidirectional=True)\n",
        "    \n",
        "    self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # shape of x: (seq_length, batch_size)\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # shape of embedding: (seq_length, batch_size, embed_size)\n",
        "\n",
        "    encoder_states, (hidden , cell) = self.rnn(embedding)\n",
        "  \n",
        "    # shape of encoder_states: (seq_length, batch_size, hidden_size*2)\n",
        "    # shape of hidden: (2*num_layers, batch_size, hidden_size)\n",
        "    # shape of cell: (2*num_layers, batch_size, hidden_size)\n",
        "\n",
        "    hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
        "    cell = self.fc_hidden(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
        "    # shape of hidden, cell: (num_layers, batch_size, hidden_size)\n",
        "\n",
        "    return encoder_states, hidden, cell"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBewKnjPPac8",
        "outputId": "2779cb20-12f0-4634-8aa3-d19158d2ffc6"
      },
      "source": [
        "# Testing encoder\n",
        "X = torch.zeros((35, 32)).long()\n",
        "encoder = Encoder(input_vocab_size, 300, 256, 1, drop_prob=0.5)\n",
        "encoder_states, hidden, cell = encoder(X)\n",
        "print(encoder_states.shape)\n",
        "print(hidden.shape)\n",
        "print(cell.shape)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([35, 32, 512])\n",
            "torch.Size([1, 32, 256])\n",
            "torch.Size([1, 32, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw4sZKc0RJVy"
      },
      "source": [
        "## Building Decoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MyJSndvP0rV"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, embed_size, hidden_size, output_size, num_layers, drop_prob):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.embed_size = embed_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_size, embed_size)\n",
        "    self.rnn = nn.LSTM(hidden_size * 2 + embed_size, hidden_size, num_layers)\n",
        "\n",
        "    self.energy = nn.Linear(hidden_size * 3, 1)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "    self.softmax = nn.Softmax(dim=0)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x, encoder_states, hidden, cell):\n",
        "    # shape of x: (batch_size)\n",
        "    x = x.unsqueeze(0) # (1, batch_size)\n",
        "\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # shape of embedding: (1, batch_size, embed_size)\n",
        "\n",
        "    seq_len = encoder_states.shape[0]\n",
        "    \n",
        "    h_reshaped = hidden.repeat(seq_len, 1, 1)\n",
        "    # shape of h_reshaped: (seq_len, batch_size, hidden_size*2)\n",
        "    \n",
        "    energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
        "    # shape of energy: (seq_len, batch_size, 1)\n",
        "\n",
        "    attention = self.softmax(energy)\n",
        "    # shape of attention: (seq_len, batch_size, 1)\n",
        "\n",
        "    attention = attention.permute(1,2,0)\n",
        "    # shape of attention: (batch_size, 1, seq_len)\n",
        "\n",
        "    encoder_states = encoder_states.permute(1,0,2)\n",
        "    # shape of encoder_states: (batch_size, seq_len, hidden_size*2)\n",
        "\n",
        "    context_vector = torch.bmm(attention, encoder_states)\n",
        "    # shape of context_vector: (batch_size, 1, hidden_size * 2)\n",
        "\n",
        "    # we want (1, batch_size, hidden_size * 2)\n",
        "    context_vector = context_vector.permute(1,0,2)\n",
        "\n",
        "    rnn_input = torch.cat([context_vector, embedding], dim=2)\n",
        "\n",
        "    outputs, (hidden, cell) = self.rnn(rnn_input, (hidden,cell))\n",
        "    # shape of outputs: (1, batch_size, hidden_size)\n",
        "\n",
        "    predictions = self.fc(outputs)\n",
        "    # shape of predictions: (1, batch_size, target_vocabulary_size)\n",
        "\n",
        "    predictions = predictions.squeeze(0)\n",
        "    # shape of predictions: (batch_size, target_vocabulary_size), since loss calculation needs this dimension\n",
        "\n",
        "    return predictions, hidden, cell"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhDQlu5GXwcM"
      },
      "source": [
        "## Seq2Seq "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5iOt6XuXs3U"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, output_vocab_size):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "  \n",
        "  def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "    # shape of source: (num_steps_in_source, batch_size)\n",
        "    # shape of target: (num_steps_in_target, batch_size)\n",
        "    batch_size = source.shape[1]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = self.output_vocab_size\n",
        "\n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "    encoder_states, hidden, cell = self.encoder(source)\n",
        "\n",
        "    # First input is <sos> token\n",
        "    x = target[0]\n",
        "\n",
        "    for t in range(1, target_len):\n",
        "      output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
        "\n",
        "      # store predictions for current timestep\n",
        "      outputs[t] = output\n",
        "\n",
        "      # get the best word the decoder predicted \n",
        "      best_guess = output.argmax(1)\n",
        "\n",
        "      x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "    \n",
        "    return outputs"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnTG6WpgZVxK"
      },
      "source": [
        "# Device config\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJy1jyozZrOr"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-A-NLylZf0i"
      },
      "source": [
        "# Training hyperparameters\n",
        "num_epochs = 100\n",
        "learning_rate = 1e-3\n",
        "batch_size = 32"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB-eKplAZqc4"
      },
      "source": [
        "# Model hyperparameters\n",
        "input_size_encoder = len(en_vocab.stoi)\n",
        "input_size_decoder = len(hi_vocab.stoi)\n",
        "output_size = len(hi_vocab.stoi)\n",
        "encoder_embed_size = 300\n",
        "decoder_embed_size = 300\n",
        "hidden_size = 1024 # according to paper\n",
        "num_layers = 1\n",
        "enc_dropout = 0.2\n",
        "dec_dropout = 0.2"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHkJvb_6aJLU"
      },
      "source": [
        "encoder = Encoder(input_size_encoder, encoder_embed_size, hidden_size, num_layers, enc_dropout).to(device)\n",
        "decoder = Decoder(input_size_decoder, decoder_embed_size, hidden_size, output_size, num_layers, enc_dropout).to(device)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-05Cqsljawwf"
      },
      "source": [
        "model = Seq2Seq(encoder, decoder, output_size).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "pad_idx = en_vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig9IAAjCbLNG"
      },
      "source": [
        "# Train\n",
        "for epoch in range(num_epochs):\n",
        "  running_loss = 0.0\n",
        "  for batch_idx, (en, hi) in enumerate(train_loader):\n",
        "    input = en.to(device)    # shape: (source_len, batch_size)\n",
        "    target = hi.to(device)    # shape: (target_len, batch_size)\n",
        "    \n",
        "    output = model(input, target)\n",
        "    # output shape: (target_len, batch_size, hindi_vocab_size)\n",
        "\n",
        "    output = output[1:].reshape(-1, output.shape[-1])   # start from 1st index because at 0th index we have start token\n",
        "    target = target[1:].reshape(-1)\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.detach().cpu().item()\n",
        "\n",
        "  print(f'Epoch: [{epoch+1} / {num_epochs}]\\tLoss: {running_loss/len(train_loader):.6f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWThhXbyfUrd"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awnxUrddbvRC"
      },
      "source": [
        "def translate_sentence(model, sentence, en_vocab, hi_vocab, device, max_length=50):\n",
        "\n",
        "  # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
        "  if type(sentence) == str:\n",
        "    tokens = [tok.text.lower() for tok in spacy_eng.tokenizer(sentence)]\n",
        "  else:\n",
        "    tokens = [token.lower() for token in sentence]\n",
        "\n",
        "\n",
        "  # Add <SOS> and <EOS> in beginning and end respectively\n",
        "  tokens.insert(0, '<sos>')\n",
        "  tokens.append('<eos>')\n",
        "\n",
        "  # Go through each english token and convert to an index\n",
        "  text_to_indices = [en_vocab.stoi[token] if token in en_vocab.stoi else en_vocab.stoi['<unk>'] for token in tokens]\n",
        "\n",
        "  # Convert to Tensor\n",
        "  sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)   # (source_len x batch_size) => (tokens_length, 1)\n",
        "\n",
        "  # Build encoder hidden, cell state\n",
        "  with torch.no_grad():\n",
        "      encoder_states, hidden, cell = model.encoder(sentence_tensor)\n",
        "\n",
        "  outputs = [hi_vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "  for _ in range(max_length):\n",
        "      previous_word = torch.LongTensor([outputs[-1]]).to(device) # shape: (1)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output, hidden, cell = model.decoder(previous_word, encoder_states, hidden, cell) # output  shape: (batch_size, target_vocab_size) => (1, hindi_vocab_size)\n",
        "          best_guess = output.argmax(1).item()\n",
        "\n",
        "      outputs.append(best_guess)\n",
        "\n",
        "      # Model predicts it's the end of the sentence\n",
        "      if output.argmax(1).item() == hi_vocab.stoi[\"<eos>\"]:\n",
        "          break\n",
        "\n",
        "  translated_sentence = [hi_vocab.itos[idx] for idx in outputs]\n",
        "\n",
        "  # remove start token\n",
        "  return translated_sentence[1:]"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1PZPDrB99yI",
        "outputId": "ccf6e56e-3919-47d6-c75f-8ec77ccdeb7d"
      },
      "source": [
        "sentence = 'Can you imagine that?'\n",
        "translate_sentence(model, sentence, en_vocab, hi_vocab, device, max_length=50)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['क्या', 'आप', 'ऐसा', 'कर', 'सकते', 'हैं?', '<eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyE01W1WAJ64"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}