{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/quora-insincere-questions-classification/test.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/train.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings.zip\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quora-insincere-questions-classification']\n"
     ]
    }
   ],
   "source": [
    "print (os.listdir('../input'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import operator\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '../input/quora-insincere-questions-classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1306122, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "train_df = pd.read_csv(data + 'train.csv')\n",
    "print (train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data length:  1306122\n"
     ]
    }
   ],
   "source": [
    "train_df_len = train_df.shape[0]\n",
    "print ('Train data length: ',train_df_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 0 vs Target 1 = 1225312 vs 80810 ,93.81% vs 6.19%\n"
     ]
    }
   ],
   "source": [
    "# statistics of target 1 vs target 0\n",
    "t0, t1 = len(train_df[train_df.target == 0]), len(train_df[train_df.target == 1])\n",
    "t0_pct, t1_pct = t0/train_df_len * 100, t1/train_df_len * 100\n",
    "print (f'Target 0 vs Target 1 = {t0} vs {t1} ,{t0_pct:.2f}% vs {t1_pct:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data length:  375806\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(data + 'test.csv')\n",
    "test_df_len = test_df.shape[0]\n",
    "print ('Test data length: ',test_df_len)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample sub length:  375806\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  prediction\n",
       "0  0000163e3ea7c7a74cd7           0\n",
       "1  00002bd4fb5d505b9161           0\n",
       "2  00007756b4a147d2b0b3           0\n",
       "3  000086e4b7e1c7146103           0\n",
       "4  0000c4c3fbe8785a3090           0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv(data + 'sample_submission.csv')\n",
    "print ('sample sub length: ', sample_df.shape[0])\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "#### From the reference, Paragram will be used as pre-trained embeddings.\n",
    "#### Preprocessing steps - \n",
    "1. lower\n",
    "2. clean contractions\n",
    "3. replace special characters\n",
    "4. tokenize\n",
    "5. remove stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contraction corrections\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_contractions(text, contraction_mapping):\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([contraction_mapping[word] if word in contraction_mapping else word for word in text.split(\" \")])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I cannot go to work today. I would rather stay home.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "text = \"I can`t go to work today. I'd rather stay home.\"\n",
    "text = clean_contractions(text, contraction_mapping)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/-\\'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\"\"“”’∞θ÷α•à−β∅³π‘₹´°£€\\\\×™√²—–&'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special characters\n",
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_mapping = {\n",
    "    \"‘\": \"'\",    \"₹\": \"e\",      \"´\": \"'\", \"°\": \"\",         \"€\": \"e\",\n",
    "    \"™\": \"tm\",   \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\",        \"—\": \"-\",\n",
    "    \"–\": \"-\",    \"’\": \"'\",      \"_\": \"-\", \"`\": \"'\",        '“': '\"',\n",
    "    '”': '\"',    '“': '\"',      \"£\": \"e\", '∞': 'infinity', 'θ': 'theta',\n",
    "    '÷': '/',    'α': 'alpha',  '•': '.', 'à': 'a',        '−': '-',\n",
    "    'β': 'beta', '∅': '',       '³': '3', 'π': 'pi'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_special_chars(text, punct, punct_mapping):\n",
    "    for p in punct_mapping:\n",
    "        text = text.replace(p, punct_mapping[p])\n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  # Other special characters that I have to deal with in last\n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have  $ 20 .  So ,  I can buy an awesome watch !  ! '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "text = \"I have $20. So, I can buy an awesome watch!!\"\n",
    "text = clean_special_chars(text,punct,punct_mapping)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, contraction_mapping, punct, punct_mapping):\n",
    "    texts = df.question_text\n",
    "    processed_texts = texts.apply(lambda x:x.lower())\n",
    "    processed_texts = processed_texts.apply(lambda x: clean_contractions(x, contraction_mapping))\n",
    "    processed_texts = processed_texts.apply(lambda x: clean_special_chars(x, punct, punct_mapping))\n",
    "    processed_texts = processed_texts.apply(lambda x: re.split('\\W+', x))\n",
    "    processed_texts = processed_texts.apply(lambda x: [token for token in x if token not in stopwords])\n",
    "    df['processed_text'] = processed_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Choose data from trainset\n",
    "In this training, some portion of the data will be used. The number of negative data is very small compared to positive.\n",
    "Since the test run with big portion of positive data made the result worse, the positive data is cut down to some portion. How many to read is a big question though.\n",
    "* test data: 56370\n",
    "* target 0/1 ratio: 93.81/6.19%, 1225312/80810 (very skewed)\n",
    "\n",
    "The total number of data is set to become 10x of test data after train/validation split by 0.9 to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rows_t0 = 639190    # positive data\n",
    "sample_rows_t1 = 80810     # negative data\n",
    "df_t0 = train_df[train_df.target == 0].sample(sample_rows_t0)\n",
    "df_t1 = train_df[train_df.target == 1].sample(sample_rows_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_t0 length : 639190\n",
      "df_t1 length : 80810\n"
     ]
    }
   ],
   "source": [
    "print (f'df_t0 length : {df_t0.shape[0]}')\n",
    "print (f'df_t1 length : {df_t1.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1142055</th>\n",
       "      <td>dfca985dea316518b411</td>\n",
       "      <td>Am I the only one worried that Trump is anglin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[one, worried, trump, angling, war, iran, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255413</th>\n",
       "      <td>f60612b948e4e45ff3d2</td>\n",
       "      <td>Can you pass a drug test using baking soda?</td>\n",
       "      <td>0</td>\n",
       "      <td>[pass, drug, test, using, baking, soda, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183014</th>\n",
       "      <td>e7d4973ab9818c412f64</td>\n",
       "      <td>How do I forgive my best friend after she stol...</td>\n",
       "      <td>0</td>\n",
       "      <td>[forgive, best, friend, stole, wanted, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856364</th>\n",
       "      <td>a7c80b7002e11c8cf9ce</td>\n",
       "      <td>What has been the darkest time of your life?</td>\n",
       "      <td>0</td>\n",
       "      <td>[darkest, time, life, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467572</th>\n",
       "      <td>5b8edbddd935105b903d</td>\n",
       "      <td>What do actual musical fans think of La La Land?</td>\n",
       "      <td>0</td>\n",
       "      <td>[actual, musical, fans, think, la, la, land, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "1142055  dfca985dea316518b411   \n",
       "1255413  f60612b948e4e45ff3d2   \n",
       "1183014  e7d4973ab9818c412f64   \n",
       "856364   a7c80b7002e11c8cf9ce   \n",
       "467572   5b8edbddd935105b903d   \n",
       "\n",
       "                                             question_text  target  \\\n",
       "1142055  Am I the only one worried that Trump is anglin...       0   \n",
       "1255413        Can you pass a drug test using baking soda?       0   \n",
       "1183014  How do I forgive my best friend after she stol...       0   \n",
       "856364        What has been the darkest time of your life?       0   \n",
       "467572    What do actual musical fans think of La La Land?       0   \n",
       "\n",
       "                                         processed_text  \n",
       "1142055     [one, worried, trump, angling, war, iran, ]  \n",
       "1255413       [pass, drug, test, using, baking, soda, ]  \n",
       "1183014        [forgive, best, friend, stole, wanted, ]  \n",
       "856364                          [darkest, time, life, ]  \n",
       "467572   [actual, musical, fans, think, la, la, land, ]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df_t0, contraction_mapping, punct, punct_mapping)\n",
    "df_t0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>971199</th>\n",
       "      <td>be469d3a81d598c91dbc</td>\n",
       "      <td>Why are Turkish women so short?</td>\n",
       "      <td>1</td>\n",
       "      <td>[turkish, women, short, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357069</th>\n",
       "      <td>45fd310ecfac662ddaa1</td>\n",
       "      <td>What India has done for 26/11 victims? Pakista...</td>\n",
       "      <td>1</td>\n",
       "      <td>[india, done, 26, 11, victims, pakistan, done,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656042</th>\n",
       "      <td>80806a26a6f8e8515147</td>\n",
       "      <td>Do the people who support trump have any moral...</td>\n",
       "      <td>1</td>\n",
       "      <td>[people, support, trump, morals, human, decenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983327</th>\n",
       "      <td>c0a6e24c2446c3b2115d</td>\n",
       "      <td>New question. Doug I love you? I want both of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[new, question, doug, love, want, souls, us, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974588</th>\n",
       "      <td>beee38c6aa5457d44512</td>\n",
       "      <td>Was it the right time and or appropriate for T...</td>\n",
       "      <td>1</td>\n",
       "      <td>[right, time, appropriate, trump, give, comica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "971199  be469d3a81d598c91dbc   \n",
       "357069  45fd310ecfac662ddaa1   \n",
       "656042  80806a26a6f8e8515147   \n",
       "983327  c0a6e24c2446c3b2115d   \n",
       "974588  beee38c6aa5457d44512   \n",
       "\n",
       "                                            question_text  target  \\\n",
       "971199                    Why are Turkish women so short?       1   \n",
       "357069  What India has done for 26/11 victims? Pakista...       1   \n",
       "656042  Do the people who support trump have any moral...       1   \n",
       "983327  New question. Doug I love you? I want both of ...       1   \n",
       "974588  Was it the right time and or appropriate for T...       1   \n",
       "\n",
       "                                           processed_text  \n",
       "971199                          [turkish, women, short, ]  \n",
       "357069  [india, done, 26, 11, victims, pakistan, done,...  \n",
       "656042  [people, support, trump, morals, human, decenc...  \n",
       "983327  [new, question, doug, love, want, souls, us, r...  \n",
       "974588  [right, time, appropriate, trump, give, comica...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(df_t1, contraction_mapping, punct, punct_mapping)\n",
    "df_t1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "      <td>[many, women, become, rude, arrogant, get, lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "      <td>[apply, rv, college, engineering, bms, college...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "      <td>[really, like, nurse, practitioner, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "      <td>[entrepreneurs, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "      <td>[education, really, making, good, people, nowa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...   \n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...   \n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...   \n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?   \n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?   \n",
       "\n",
       "                                      processed_text  \n",
       "0  [many, women, become, rude, arrogant, get, lit...  \n",
       "1  [apply, rv, college, engineering, bms, college...  \n",
       "2              [really, like, nurse, practitioner, ]  \n",
       "3                                  [entrepreneurs, ]  \n",
       "4  [education, really, making, good, people, nowa...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(test_df, contraction_mapping, punct, punct_mapping)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Find Vocabulary\n",
    "Memory restriction is tight. Loading whole pretrained embeddings easily leads to memory exhaustion. To save memory, below just grabs vocabulary found in train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts, vocab):\n",
    "    for word in texts:\n",
    "        vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177387\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "df_t1.processed_text.apply(lambda x:build_vocab(x,vocab))\n",
    "df_t0.processed_text.apply(lambda x:build_vocab(x,vocab))\n",
    "test_df.processed_text.apply(lambda x:build_vocab(x,vocab))\n",
    "print (len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Loading Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "GoogleNews-vectors-negative300/                2018-10-31 20:04:14            0\n",
      "glove.840B.300d/                               2018-10-31 19:53:42            0\n",
      "paragram_300_sl999/                            2015-08-25 06:11:12            0\n",
      "wiki-news-300d-1M/                             2018-10-31 19:58:52            0\n",
      "glove.840B.300d/glove.840B.300d.txt            2015-10-24 10:35:30   5646236541\n",
      "GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin 2018-10-31 16:38:00   3644258522\n",
      "wiki-news-300d-1M/wiki-news-300d-1M.vec        2018-03-14 14:01:54   2259088777\n",
      "paragram_300_sl999/README.txt                  2015-08-25 06:11:12          731\n",
      "paragram_300_sl999/paragram_300_sl999.txt      2015-08-25 06:04:16   4555969303\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import codecs\n",
    "file = ZipFile('../input/quora-insincere-questions-classification/embeddings.zip','r')\n",
    "print (file.printdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing paragram \n",
    "paragram = file.open(file.namelist()[8])     # since we want to use paragram as pretrained embeddings, hence index 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1703756it [05:18, 5341.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# load embeddings\n",
    "word2vec = {}\n",
    "i = 0\n",
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "for line in tqdm(codecs.iterdecode(paragram,'latin')):\n",
    "    word, coefs = get_coefs(*line.split(\" \"))\n",
    "    if word in vocab:\n",
    "        word2vec[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length:  177387\n",
      "Word2Vec length:  134644\n"
     ]
    }
   ],
   "source": [
    "print ('Vocab length: ',len(vocab))\n",
    "print ('Word2Vec length: ',len(word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Question Word statistics\n",
    "The number of question in words varies. To deal with both long and short questions, we find the appropriate number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For positive questions: Min words:1 vs Max words:91\n",
      "For negative questions: Min words:1 vs Max words:181\n",
      "For test questions: Min words:0 vs Max words:239\n"
     ]
    }
   ],
   "source": [
    "lens_t0 = list(map(len, df_t0.processed_text))\n",
    "lens_t1 = list(map(len, df_t1.processed_text))\n",
    "lens_test = list(map(len, test_df.processed_text))\n",
    "\n",
    "print (f'For positive questions: Min words:{min(lens_t0)} vs Max words:{max(lens_t0)}')\n",
    "print (f'For negative questions: Min words:{min(lens_t1)} vs Max words:{max(lens_t1)}')\n",
    "print (f'For test questions: Min words:{min(lens_test)} vs Max words:{max(lens_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_stats(tag,counts, key, topk, total):\n",
    "    most_freqs = sorted(counts, key=key, reverse=True)[:topk]\n",
    "    freqs = [counts[freq] for freq in most_freqs]\n",
    "    \n",
    "    print (f'{tag}: best {topk} frequent word count: {most_freqs}')\n",
    "    print (f'freqs: {freqs}')\n",
    "    print (f'Covers: {sum(freqs)/total*100:.2f}%')\n",
    "    \n",
    "    return max(most_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: best 20 frequent word count: [5, 6, 7, 4, 8, 9, 10, 3, 11, 12, 13, 14, 15, 16, 17, 2, 18, 19, 20, 21]\n",
      "freqs: [106343, 103308, 82568, 80189, 61369, 44534, 32288, 28837, 23874, 17454, 13342, 10140, 7737, 5708, 4140, 3570, 3121, 2488, 1941, 1643]\n",
      "Covers: 99.28%\n",
      "neg: best 20 frequent word count: [6, 7, 5, 8, 9, 10, 4, 11, 12, 13, 14, 15, 16, 17, 3, 18, 19, 20, 21, 22]\n",
      "freqs: [8138, 7634, 7412, 7019, 6342, 5619, 5325, 5051, 4376, 3822, 3349, 2662, 2154, 1885, 1747, 1628, 1325, 1138, 1011, 855]\n",
      "Covers: 97.13%\n",
      "test: best 20 frequent word count: [5, 6, 7, 4, 8, 9, 10, 3, 11, 12, 13, 14, 15, 16, 17, 18, 2, 19, 20, 21]\n",
      "freqs: [61140, 59354, 47525, 45416, 35711, 26837, 19582, 16128, 14678, 11060, 8537, 6533, 4978, 3826, 2783, 2172, 1869, 1712, 1365, 1196]\n",
      "Covers: 99.09%\n",
      "21 22 21\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts_t0 = Counter(lens_t0) # counts words freq. Ex. How many 13 words questions are there?\n",
    "counts_t1 = Counter(lens_t1)\n",
    "counts_test = Counter(lens_test)\n",
    "\n",
    "topk = 20  # pick top 20 freq of words\n",
    "max_t0 = freq_stats('pos',counts_t0, counts_t0.get, topk, sample_rows_t0)\n",
    "max_t1 = freq_stats('neg',counts_t1, counts_t1.get, topk, sample_rows_t1)\n",
    "max_test = freq_stats('test',counts_test, counts_test.get, topk, test_df_len)\n",
    "\n",
    "print (max_t0, max_t1, max_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = max(max_t0, max_t1, max_test)\n",
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec['india'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Build Word Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weights_matrix(word2vec):\n",
    "    word2idx = {}\n",
    "    weights_matrix = np.zeros((len(word2vec), 300))\n",
    "    for i, (k,v) in enumerate(word2vec.items()):\n",
    "        word2idx[k] = i\n",
    "        weights_matrix[i] = v\n",
    "    return word2idx, weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, weights_matrix = build_weights_matrix(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134644, 300)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_question(word2idx, text, seq_length):\n",
    "    encoded = []\n",
    "    for word in text[:seq_length]:\n",
    "        try:\n",
    "            encoded.append(word2idx[word])\n",
    "        except KeyError:\n",
    "            # missing words in the table\n",
    "            continue\n",
    "    \n",
    "    return np.array(encoded, dtype='int_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(np_arr, seq_length):\n",
    "    curr_length = np_arr.shape[0]\n",
    "    if curr_length < seq_length:\n",
    "        padding = np.zeros((seq_length - curr_length, ), dtype = 'int_')\n",
    "        return np.concatenate((padding,np_arr))\n",
    "    else:\n",
    "        return np_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(texts, label, word2idx, seq_length):\n",
    "    texts_len = len(texts)\n",
    "    y = np.array([label]*texts_len, dtype='float')\n",
    "    X = []\n",
    "    for i, text in enumerate(texts):\n",
    "        text_array = encode_question(word2idx, text, seq_length)\n",
    "        text_array = add_padding(text_array, seq_length)\n",
    "        X.append(text_array)\n",
    "    return np.array(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data to train and validation\n",
    "test_size = 0.1\n",
    "train_texts_t0, val_texts_t0 = train_test_split(df_t0.processed_text, test_size = test_size)\n",
    "train_texts_t1, val_texts_t1 = train_test_split(df_t1.processed_text, test_size = test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: train_X (648000, 22), train_y (648000,)\n"
     ]
    }
   ],
   "source": [
    "train_X_t0, train_y_t0 = create_dataset(train_texts_t0, 0, word2idx, seq_length)\n",
    "train_X_t1, train_y_t1 = create_dataset(train_texts_t1, 1, word2idx, seq_length)\n",
    "\n",
    "train_X = np.concatenate((train_X_t0, train_X_t1))\n",
    "train_y = np.concatenate((train_y_t0, train_y_t1))\n",
    "\n",
    "print (f'Shapes: train_X {train_X.shape}, train_y {train_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: val_X (72000, 22), val_y (72000,)\n"
     ]
    }
   ],
   "source": [
    "val_X_t0, val_y_t0 = create_dataset(val_texts_t0, 0, word2idx, seq_length)\n",
    "val_X_t1, val_y_t1 = create_dataset(val_texts_t1, 1, word2idx, seq_length)\n",
    "\n",
    "val_X = np.concatenate((val_X_t0, val_X_t1))\n",
    "val_y = np.concatenate((val_y_t0, val_y_t1))\n",
    "\n",
    "print (f'Shapes: val_X {val_X.shape}, val_y {val_y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Pytorch - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device config\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensor dataset\n",
    "train_set = TensorDataset(torch.from_numpy(train_X), torch.from_numpy(train_y))\n",
    "val_set = TensorDataset(torch.from_numpy(val_X), torch.from_numpy(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "batch_size = 200\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Building Network Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, weights, output_size, hidden_size, n_layers, bidirectional=False, dropout=0.5,layer_dropout=0.3):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        if bidirectional:\n",
    "            self.direction = 2\n",
    "        else:\n",
    "            self.direction = 1\n",
    "        \n",
    "        num_embeddings, embedding_dim = weights.shape\n",
    "        \n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(weights))\n",
    "        self.embedding.requires_grad = False\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, n_layers, batch_first=True, dropout=dropout,bidirectional = bidirectional)\n",
    "        \n",
    "        # GRU layer\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, n_layers, batch_first=True, dropout=dropout,bidirectional = bidirectional)\n",
    "            \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(layer_dropout)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear((hidden_size*self.direction), output_size)\n",
    "        \n",
    "        # Sigmoid activation layer\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        lstm_hidden = hidden\n",
    "        \n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        lstm_out, lstm_hidden = self.lstm(embeds, lstm_hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        sig_out = self.sig(out)\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]   # get last batch of labels\n",
    "        \n",
    "        return  sig_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size, bidirectional=False):\n",
    "        weight = next(self.parameters()).data\n",
    "        # for LSTM (initial_hidden_state, initial_cell_state)\n",
    "        lstm_hidden = (\n",
    "            weight.new(self.n_layers*self.direction, batch_size, self.hidden_size).zero_().to(device),\n",
    "            weight.new(self.n_layers*self.direction, batch_size, self.hidden_size).zero_().to(device)\n",
    "        )\n",
    "        # for GRU, initial_hidden_state\n",
    "        #gru_hidden = weight.new(self.n_layers*self.direction, batch_size, self.n_hidden).zero_().to(DEVICE)\n",
    "        return lstm_hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(134644, 300)\n",
      "  (lstm): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (gru): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Network\n",
    "# Hyperparams\n",
    "output_size = 1\n",
    "hidden_size = 256\n",
    "n_layers = 2\n",
    "\n",
    "\n",
    "net = RNN(weights_matrix, output_size, hidden_size, n_layers, bidirectional=False).to(device)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training params\n",
    "lr = 0.00001\n",
    "epochs = 10\n",
    "clip = 5  # gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer functions\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, optimizer, train_loader, clip, epoch, epochs, gru=False):\n",
    "    counter = 0\n",
    "    print_every = 500\n",
    "    train_length = len(train_loader)\n",
    "    \n",
    "    # init hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    train_losses = []\n",
    "    net.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs, h = net(inputs, h)\n",
    "        \n",
    "        # calculate loss and perform backprop\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        # clip_grad_norm helps prevent exploding gradient\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            train_losses.append(loss.item())\n",
    "            print (f'Epoch: {epoch+1}/{epochs} \\t Step: {counter} \\t Train Loss: {np.mean(train_losses):.6f} \\t Time: {datetime.datetime.now()}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3240"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation loss\n",
    "def validate(net, criterion, optimizer, val_loader, epoch, epochs, gru=False):\n",
    "    # init hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    val_losses = []\n",
    "    acc = 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # forward pass\n",
    "            outputs, h = net(inputs, h)\n",
    "\n",
    "            # calculate loss and perform backprop\n",
    "            val_loss = criterion(outputs.squeeze(), labels.float())\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "            acc += torch.eq(labels.float(), torch.round(outputs.squeeze())).sum().item()\n",
    "            \n",
    "        print (f'Epoch: {epoch+1}/{epochs} \\t Val Loss: {np.mean(val_losses):.6f} \\t Acc: {(acc/(len(val_loader)*batch_size))*100:.2f}% \\t Time: {datetime.datetime.now()}')    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(net, criterion, optimizer, epochs, train_loader, val_loader, clip, gru=False):\n",
    "    for epoch in range(epochs):\n",
    "        print ('Running epoch {}...\\n'.format(epoch+1))\n",
    "        train(net, criterion, optimizer, train_loader ,clip, epoch, epochs, gru)\n",
    "        validate(net, criterion, optimizer, val_loader, epoch, epochs, gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch 1...\n",
      "\n",
      "Epoch: 1/10 \t Step: 500 \t Train Loss: 0.330770 \t Time: 2020-07-28 06:58:17.992288\n",
      "Epoch: 1/10 \t Step: 1000 \t Train Loss: 0.291725 \t Time: 2020-07-28 06:58:26.617073\n",
      "Epoch: 1/10 \t Step: 1500 \t Train Loss: 0.275940 \t Time: 2020-07-28 06:58:35.357402\n",
      "Epoch: 1/10 \t Step: 2000 \t Train Loss: 0.255114 \t Time: 2020-07-28 06:58:44.017442\n",
      "Epoch: 1/10 \t Step: 2500 \t Train Loss: 0.257262 \t Time: 2020-07-28 06:58:52.654842\n",
      "Epoch: 1/10 \t Step: 3000 \t Train Loss: 0.251641 \t Time: 2020-07-28 06:59:01.272786\n",
      "Epoch: 1/10 \t Val Loss: 0.202240 \t Acc: 91.59% \t Time: 2020-07-28 06:59:06.959745\n",
      "Running epoch 2...\n",
      "\n",
      "Epoch: 2/10 \t Step: 500 \t Train Loss: 0.212575 \t Time: 2020-07-28 06:59:15.607529\n",
      "Epoch: 2/10 \t Step: 1000 \t Train Loss: 0.215191 \t Time: 2020-07-28 06:59:24.197795\n",
      "Epoch: 2/10 \t Step: 1500 \t Train Loss: 0.189352 \t Time: 2020-07-28 06:59:32.863898\n",
      "Epoch: 2/10 \t Step: 2000 \t Train Loss: 0.190402 \t Time: 2020-07-28 06:59:41.574490\n",
      "Epoch: 2/10 \t Step: 2500 \t Train Loss: 0.188776 \t Time: 2020-07-28 06:59:50.623642\n",
      "Epoch: 2/10 \t Step: 3000 \t Train Loss: 0.187445 \t Time: 2020-07-28 06:59:59.262620\n",
      "Epoch: 2/10 \t Val Loss: 0.187891 \t Acc: 92.20% \t Time: 2020-07-28 07:00:04.914526\n",
      "Running epoch 3...\n",
      "\n",
      "Epoch: 3/10 \t Step: 500 \t Train Loss: 0.140442 \t Time: 2020-07-28 07:00:13.540484\n",
      "Epoch: 3/10 \t Step: 1000 \t Train Loss: 0.167509 \t Time: 2020-07-28 07:00:22.118697\n",
      "Epoch: 3/10 \t Step: 1500 \t Train Loss: 0.195147 \t Time: 2020-07-28 07:00:30.857895\n",
      "Epoch: 3/10 \t Step: 2000 \t Train Loss: 0.192924 \t Time: 2020-07-28 07:00:39.482247\n",
      "Epoch: 3/10 \t Step: 2500 \t Train Loss: 0.191142 \t Time: 2020-07-28 07:00:48.084894\n",
      "Epoch: 3/10 \t Step: 3000 \t Train Loss: 0.186962 \t Time: 2020-07-28 07:00:56.686491\n",
      "Epoch: 3/10 \t Val Loss: 0.180438 \t Acc: 92.48% \t Time: 2020-07-28 07:01:02.348564\n",
      "Running epoch 4...\n",
      "\n",
      "Epoch: 4/10 \t Step: 500 \t Train Loss: 0.156784 \t Time: 2020-07-28 07:01:11.037686\n",
      "Epoch: 4/10 \t Step: 1000 \t Train Loss: 0.156629 \t Time: 2020-07-28 07:01:20.248518\n",
      "Epoch: 4/10 \t Step: 1500 \t Train Loss: 0.178505 \t Time: 2020-07-28 07:01:28.911571\n",
      "Epoch: 4/10 \t Step: 2000 \t Train Loss: 0.181490 \t Time: 2020-07-28 07:01:37.704641\n",
      "Epoch: 4/10 \t Step: 2500 \t Train Loss: 0.185648 \t Time: 2020-07-28 07:01:46.362115\n",
      "Epoch: 4/10 \t Step: 3000 \t Train Loss: 0.192637 \t Time: 2020-07-28 07:01:54.999603\n",
      "Epoch: 4/10 \t Val Loss: 0.176631 \t Acc: 92.67% \t Time: 2020-07-28 07:02:00.701579\n",
      "Running epoch 5...\n",
      "\n",
      "Epoch: 5/10 \t Step: 500 \t Train Loss: 0.200224 \t Time: 2020-07-28 07:02:09.397512\n",
      "Epoch: 5/10 \t Step: 1000 \t Train Loss: 0.181887 \t Time: 2020-07-28 07:02:18.093043\n",
      "Epoch: 5/10 \t Step: 1500 \t Train Loss: 0.176888 \t Time: 2020-07-28 07:02:26.774092\n",
      "Epoch: 5/10 \t Step: 2000 \t Train Loss: 0.172773 \t Time: 2020-07-28 07:02:35.591688\n",
      "Epoch: 5/10 \t Step: 2500 \t Train Loss: 0.181848 \t Time: 2020-07-28 07:02:44.297405\n",
      "Epoch: 5/10 \t Step: 3000 \t Train Loss: 0.189003 \t Time: 2020-07-28 07:02:53.395735\n",
      "Epoch: 5/10 \t Val Loss: 0.172511 \t Acc: 92.82% \t Time: 2020-07-28 07:02:59.126282\n",
      "Running epoch 6...\n",
      "\n",
      "Epoch: 6/10 \t Step: 500 \t Train Loss: 0.212984 \t Time: 2020-07-28 07:03:07.789323\n",
      "Epoch: 6/10 \t Step: 1000 \t Train Loss: 0.194654 \t Time: 2020-07-28 07:03:16.411070\n",
      "Epoch: 6/10 \t Step: 1500 \t Train Loss: 0.185204 \t Time: 2020-07-28 07:03:25.007041\n",
      "Epoch: 6/10 \t Step: 2000 \t Train Loss: 0.172385 \t Time: 2020-07-28 07:03:33.806092\n",
      "Epoch: 6/10 \t Step: 2500 \t Train Loss: 0.177653 \t Time: 2020-07-28 07:03:42.466038\n",
      "Epoch: 6/10 \t Step: 3000 \t Train Loss: 0.179536 \t Time: 2020-07-28 07:03:51.077154\n",
      "Epoch: 6/10 \t Val Loss: 0.170306 \t Acc: 92.93% \t Time: 2020-07-28 07:03:56.762481\n",
      "Running epoch 7...\n",
      "\n",
      "Epoch: 7/10 \t Step: 500 \t Train Loss: 0.188295 \t Time: 2020-07-28 07:04:05.389877\n",
      "Epoch: 7/10 \t Step: 1000 \t Train Loss: 0.172384 \t Time: 2020-07-28 07:04:14.371846\n",
      "Epoch: 7/10 \t Step: 1500 \t Train Loss: 0.169597 \t Time: 2020-07-28 07:04:22.931794\n",
      "Epoch: 7/10 \t Step: 2000 \t Train Loss: 0.162464 \t Time: 2020-07-28 07:04:31.560321\n",
      "Epoch: 7/10 \t Step: 2500 \t Train Loss: 0.161231 \t Time: 2020-07-28 07:04:40.178559\n",
      "Epoch: 7/10 \t Step: 3000 \t Train Loss: 0.158843 \t Time: 2020-07-28 07:04:48.763912\n",
      "Epoch: 7/10 \t Val Loss: 0.169054 \t Acc: 93.01% \t Time: 2020-07-28 07:04:54.541454\n",
      "Running epoch 8...\n",
      "\n",
      "Epoch: 8/10 \t Step: 500 \t Train Loss: 0.133184 \t Time: 2020-07-28 07:05:03.186694\n",
      "Epoch: 8/10 \t Step: 1000 \t Train Loss: 0.137453 \t Time: 2020-07-28 07:05:11.793743\n",
      "Epoch: 8/10 \t Step: 1500 \t Train Loss: 0.143928 \t Time: 2020-07-28 07:05:20.384248\n",
      "Epoch: 8/10 \t Step: 2000 \t Train Loss: 0.148287 \t Time: 2020-07-28 07:05:28.975923\n",
      "Epoch: 8/10 \t Step: 2500 \t Train Loss: 0.147454 \t Time: 2020-07-28 07:05:37.696774\n",
      "Epoch: 8/10 \t Step: 3000 \t Train Loss: 0.148294 \t Time: 2020-07-28 07:05:46.745191\n",
      "Epoch: 8/10 \t Val Loss: 0.166406 \t Acc: 93.08% \t Time: 2020-07-28 07:05:52.471113\n",
      "Running epoch 9...\n",
      "\n",
      "Epoch: 9/10 \t Step: 500 \t Train Loss: 0.195565 \t Time: 2020-07-28 07:06:01.136794\n",
      "Epoch: 9/10 \t Step: 1000 \t Train Loss: 0.183959 \t Time: 2020-07-28 07:06:09.737076\n",
      "Epoch: 9/10 \t Step: 1500 \t Train Loss: 0.186239 \t Time: 2020-07-28 07:06:18.346786\n",
      "Epoch: 9/10 \t Step: 2000 \t Train Loss: 0.173703 \t Time: 2020-07-28 07:06:26.966096\n",
      "Epoch: 9/10 \t Step: 2500 \t Train Loss: 0.173256 \t Time: 2020-07-28 07:06:35.754759\n",
      "Epoch: 9/10 \t Step: 3000 \t Train Loss: 0.167331 \t Time: 2020-07-28 07:06:44.435111\n",
      "Epoch: 9/10 \t Val Loss: 0.164697 \t Acc: 93.16% \t Time: 2020-07-28 07:06:50.107953\n",
      "Running epoch 10...\n",
      "\n",
      "Epoch: 10/10 \t Step: 500 \t Train Loss: 0.224314 \t Time: 2020-07-28 07:06:58.753412\n",
      "Epoch: 10/10 \t Step: 1000 \t Train Loss: 0.192407 \t Time: 2020-07-28 07:07:07.313790\n",
      "Epoch: 10/10 \t Step: 1500 \t Train Loss: 0.176179 \t Time: 2020-07-28 07:07:16.330403\n",
      "Epoch: 10/10 \t Step: 2000 \t Train Loss: 0.179464 \t Time: 2020-07-28 07:07:24.907547\n",
      "Epoch: 10/10 \t Step: 2500 \t Train Loss: 0.168722 \t Time: 2020-07-28 07:07:33.569670\n",
      "Epoch: 10/10 \t Step: 3000 \t Train Loss: 0.164111 \t Time: 2020-07-28 07:07:42.197872\n",
      "Epoch: 10/10 \t Val Loss: 0.163596 \t Acc: 93.23% \t Time: 2020-07-28 07:07:47.869561\n"
     ]
    }
   ],
   "source": [
    "run_train(net, criterion, optimizer, epochs, train_loader, val_loader, clip,gru=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuoraTestDataset(Dataset):\n",
    "    def __init__(self, df, word2idx, seq_length):\n",
    "        self.word2idx = word2idx\n",
    "        self.seq_length = seq_length\n",
    "        self.data = df\n",
    "        self.data_len = len(df)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.data_len:\n",
    "            idx %= self.data_len\n",
    "            \n",
    "        #preprocessed\n",
    "        tokens = self.data.iloc[idx].processed_text\n",
    "        \n",
    "        # encode to make array of indices\n",
    "        encoded = encode_question(word2idx, tokens, self.seq_length)\n",
    "        text_array = add_padding(encoded, self.seq_length)\n",
    "        return self.data.iloc[idx].qid, torch.from_numpy(text_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "test_set = QuoraTestDataset(test_df, word2idx, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375806"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_loader, batch_size=test_batch_size):\n",
    "    test_l_h = net.init_hidden(batch_size)\n",
    "    ret_qid = []\n",
    "    ret_pred = []\n",
    "    test_len = len(test_loader)\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for qids, inputs in test_loader:\n",
    "            counter += 1\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            # for LSTM\n",
    "            test_l_h = tuple([each.data for each in test_l_h])\n",
    "\n",
    "            outputs, test_l_h = net(inputs, test_l_h)\n",
    "            \n",
    "            ret_qid.append(qids)\n",
    "            ret_pred.append(torch.round(outputs.squeeze()).cpu().numpy().astype(int))\n",
    "            \n",
    "            if counter % 300 == 0:\n",
    "                print('{}/{} done'.format(counter, test_len))\n",
    "\n",
    "    return ret_qid, ret_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/9166 done\n",
      "600/9166 done\n",
      "900/9166 done\n",
      "1200/9166 done\n",
      "1500/9166 done\n",
      "1800/9166 done\n",
      "2100/9166 done\n",
      "2400/9166 done\n",
      "2700/9166 done\n",
      "3000/9166 done\n",
      "3300/9166 done\n",
      "3600/9166 done\n",
      "3900/9166 done\n",
      "4200/9166 done\n",
      "4500/9166 done\n",
      "4800/9166 done\n",
      "5100/9166 done\n",
      "5400/9166 done\n",
      "5700/9166 done\n",
      "6000/9166 done\n",
      "6300/9166 done\n",
      "6600/9166 done\n",
      "6900/9166 done\n",
      "7200/9166 done\n",
      "7500/9166 done\n",
      "7800/9166 done\n",
      "8100/9166 done\n",
      "8400/9166 done\n",
      "8700/9166 done\n",
      "9000/9166 done\n"
     ]
    }
   ],
   "source": [
    "ret_qid, ret_pred = test(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806\n",
      "375806\n"
     ]
    }
   ],
   "source": [
    "ret_qid = np.concatenate(ret_qid)\n",
    "ret_pred = np.concatenate(ret_pred)\n",
    "print (len(ret_qid))\n",
    "print (len(ret_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame({'qid': ret_qid, 'prediction': ret_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  prediction\n",
       "0  0000163e3ea7c7a74cd7           1\n",
       "1  00002bd4fb5d505b9161           0\n",
       "2  00007756b4a147d2b0b3           0\n",
       "3  000086e4b7e1c7146103           0\n",
       "4  0000c4c3fbe8785a3090           0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
