{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_01_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPViH0Q4o2jXZHKnz4IHFM9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4112248c7284bf28fda1a65d656156b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c67bda0658c2494a879801062419856c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1da1465e12b24a8a851eceb579acf73a",
              "IPY_MODEL_046007e768414f9baf277be80f2f0c1b"
            ]
          }
        },
        "c67bda0658c2494a879801062419856c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1da1465e12b24a8a851eceb579acf73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e274a62ba45d49869e158642da74c652",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1b3a1a613cf4627801ed5c9bf6ebb59"
          }
        },
        "046007e768414f9baf277be80f2f0c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc6e6929c3484f87b2c0fa98426c9551",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:20&lt;00:00, 1743087.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d85b321c4045451e879b8a686d963db1"
          }
        },
        "e274a62ba45d49869e158642da74c652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1b3a1a613cf4627801ed5c9bf6ebb59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc6e6929c3484f87b2c0fa98426c9551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d85b321c4045451e879b8a686d963db1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14b3d05d4c6b4bf68757714a3a491eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fcc3419260c94a7eaec54d2d278831b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3ff93d95b9b4dfc9d3a3e34850d2dae",
              "IPY_MODEL_124a5135886e4f76bc448a9010761868"
            ]
          }
        },
        "fcc3419260c94a7eaec54d2d278831b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3ff93d95b9b4dfc9d3a3e34850d2dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9a4a822aa6424fe2b3a5398a84a31c86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08e3fb31d37742dfb3a80051b4036339"
          }
        },
        "124a5135886e4f76bc448a9010761868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6bfb8f174e964062be1e372424588568",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:16&lt;00:00, 78423.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6db923d02fe540648237784385a3738a"
          }
        },
        "9a4a822aa6424fe2b3a5398a84a31c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08e3fb31d37742dfb3a80051b4036339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bfb8f174e964062be1e372424588568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6db923d02fe540648237784385a3738a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0576c84a101a47688ca144a0f6708072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_05a229f5a15642268355c095230f87a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_868aa2920374475eb4df54a61dfd7b06",
              "IPY_MODEL_f12865316a14492ca242043ffd7fb46a"
            ]
          }
        },
        "05a229f5a15642268355c095230f87a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "868aa2920374475eb4df54a61dfd7b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3a3f60270b544600a31fa3bdfaf842a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f6db800d9d9412ab778bffc1f6170fb"
          }
        },
        "f12865316a14492ca242043ffd7fb46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a7dc6c735b64967a67b49b972227030",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:15&lt;00:00, 264201.55it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a90606744cc242bba0f5a6e2560b8ac2"
          }
        },
        "3a3f60270b544600a31fa3bdfaf842a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f6db800d9d9412ab778bffc1f6170fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a7dc6c735b64967a67b49b972227030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a90606744cc242bba0f5a6e2560b8ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5f4df3c9a4748d29f9f825fa812a309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_49133dee35444e7a8e4d08f9aab0706e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3786005cc21b426da081b283e901e106",
              "IPY_MODEL_a3dd09cdfe58448abb59653aed1814fa"
            ]
          }
        },
        "49133dee35444e7a8e4d08f9aab0706e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3786005cc21b426da081b283e901e106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7caff1df14344fec9555ebe62fe3b8da",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_264a73c812bc40ad864c6d35e7a05371"
          }
        },
        "a3dd09cdfe58448abb59653aed1814fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f435fc6ec90542b19397ba3e6f7843a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4542 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f088c592abc4a699c201e0fc754883d"
          }
        },
        "7caff1df14344fec9555ebe62fe3b8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "264a73c812bc40ad864c6d35e7a05371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f435fc6ec90542b19397ba3e6f7843a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f088c592abc4a699c201e0fc754883d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palash04/Artificial-Intelligence/blob/master/Neural_Networks/Intro_to_Pytorch/_01_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0RObpDL5F1k",
        "colab_type": "text"
      },
      "source": [
        "![Screenshot 2020-06-29 at 17 15 11](https://user-images.githubusercontent.com/26361028/86001132-1876fd00-ba2c-11ea-9cf6-d069b0eeb914.png)\n",
        "![Screenshot 2020-06-29 at 17 15 39](https://user-images.githubusercontent.com/26361028/86001182-29277300-ba2c-11ea-9516-4401fb360888.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBwcqFPv5FWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing pytorch\n",
        "import torch"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5d17gF0JN_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Activation (sigmoid) function\n",
        "def activation(x):\n",
        "  \"\"\" Sigmoid Activaion Function\n",
        "      Arguments\n",
        "      ---------\n",
        "      x : torch.Tensor\n",
        "  \"\"\"\n",
        "  return 1 / (1 + torch.exp(-x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a61iNhG2JooY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "804757ea-db10-4791-ce3c-bc75ff7b69c4"
      },
      "source": [
        "# Example\n",
        "\n",
        "x = torch.Tensor([1,2,3,4])\n",
        "print (activation(x))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.7311, 0.8808, 0.9526, 0.9820])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UGAWvMLJter",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7) # set the random seed so that things are predictable\n",
        "\n",
        "# Features are 5 random normal variables\n",
        "features = torch.randn((1,5)) # 2 dimensional tensor 1 row and 5 columns, contains values randomly distributed according to the normal distribution with mean of zero and standard deviation of one\n",
        "\n",
        "# Weights for our data, random weights again\n",
        "weights = torch.randn_like(features) # same shape as features, again containing values from normal distribution\n",
        "\n",
        "# and a bias term\n",
        "bias = torch.randn((1,1)) # 1 row, and 1 column, i.e just one value\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE3KhDEuNggW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6378687e-201f-4d6f-e974-8d23cdedd28b"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ8EZ6VKNshc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a57b2750-d84b-42a4-cee9-ed28e1d50661"
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyQsEKxaNuAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d5fe03a2-7fdc-46bd-fba0-cecee33f753b"
      },
      "source": [
        "x = torch.sum(features*weights) + bias\n",
        "y = activation(x)\n",
        "print (y)\n",
        "\n",
        "# another way\n",
        "y = activation((features*weights).sum() + bias)\n",
        "print (y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1595]])\n",
            "tensor([[0.1595]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww7tlyAIVB1n",
        "colab_type": "text"
      },
      "source": [
        "You can do the multiplication and sum in the same operation using a matrix multiplication. In general, you'll want to use matrix multiplications since they are more efficient and accelerated using modern libraries and high-performance computing on GPUs.\n",
        "\n",
        "Here, we want to do a matrix multiplication of the features and the weights. For this we can use torch.mm() or torch.matmul() which is somewhat more complicated and supports broadcasting. If we try to do it with features and weights as they are, we'll get an error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh1ZzDNqOVBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "92320cb7-66ad-4427-cce6-1a275a718518"
      },
      "source": [
        "torch.mm(features,weights)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-eee0877cf81f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 5], m2: [1 x 5] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JArUnJ_2VM4j",
        "colab_type": "text"
      },
      "source": [
        " - weights.reshape(a, b) will return a new tensor with the same data as weights with size (a, b) sometimes, and sometimes a clone, as in it copies the data to another part of memory.\n",
        " - weights.resize_(a, b) returns the same tensor with a different shape. However, if the new shape results in fewer elements than the original tensor, some elements will be removed from the tensor (but not from memory). If the new shape results in more elements than the original tensor, new elements will be uninitialized in memory. Here I should note that the underscore at the end of the method denotes that this method is performed in-place. Here is a great forum thread to read more about in-place operations in PyTorch.\n",
        " - weights.view(a, b) will return a new tensor with the same data as weights with size (a, b)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkbstzCUVFVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95127dc5-692d-4add-941b-76b359b3a95a"
      },
      "source": [
        "# So, now we can reshape weights to have five rows and 1 column like\n",
        "weights = weights.view(5,1)\n",
        "weights.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX5YLJOtWMwh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5c0a439-385e-4934-b740-aa3400407f6f"
      },
      "source": [
        "y = activation(torch.mm(features,weights) + bias)\n",
        "print (y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1595]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed-mQdg4ZRxo",
        "colab_type": "text"
      },
      "source": [
        "![Screenshot 2020-06-29 at 19 34 20](https://user-images.githubusercontent.com/26361028/86015711-8a0c7680-ba3f-11ea-80b0-fb91758c46d7.png)\n",
        "![Screenshot 2020-06-29 at 19 34 44](https://user-images.githubusercontent.com/26361028/86015758-97c1fc00-ba3f-11ea-935c-3dc45eb7ca14.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN9y6eClWu1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implementing above neural network, for some random data\n",
        "\n",
        "### Generate some data\n",
        "torch.manual_seed(7) # set the random seed so that things are predictable\n",
        "\n",
        "# Features are 3 random normal variables\n",
        "features = torch.randn((1,3))\n",
        "\n",
        "# Define the size of each layer in our network\n",
        "n_input = features.shape[1]\n",
        "n_hidden = 2    # Number of hidden units\n",
        "n_output = 1    # Number of output units\n",
        "\n",
        "# Weights for inputs to hidden layer\n",
        "W1 = torch.randn((n_input,n_hidden))\n",
        "\n",
        "# Weights for hidden layer to output layer\n",
        "W2 = torch.randn((n_hidden,n_output))\n",
        "\n",
        "# Bias terms for hidden and output layer\n",
        "B1 = torch.randn((1, n_hidden))\n",
        "B2 = torch.randn((1,n_output))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeiRKWvWbr6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88f6c4b6-f00f-4a22-b2f7-1b439d0fdaaf"
      },
      "source": [
        "# Calculating the output for multi-layer network using weights W1 and W2, and the biases B1 and B2\n",
        "\n",
        "h = activation(torch.mm(features,W1) + B1)\n",
        "y = activation(torch.mm(h,W2) + B2)\n",
        "print (y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3171]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGcrIJzKf4AC",
        "colab_type": "text"
      },
      "source": [
        "Numpy to torch and back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u50Y2t7tb7OA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQgmcAdfdPu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5ca74397-748e-4425-cf5e-2d3a1b11a7d0"
      },
      "source": [
        "a = np.random.rand(4,3)\n",
        "a"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4949733 , 0.2898629 , 0.55330195],\n",
              "       [0.76009278, 0.0901079 , 0.91771219],\n",
              "       [0.95775943, 0.01649582, 0.02168991],\n",
              "       [0.80281124, 0.83804703, 0.1478994 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6X00u6lgBPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7f35c0da-b4af-4488-f9e2-096244269654"
      },
      "source": [
        "b = torch.from_numpy(a)\n",
        "b"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4950, 0.2899, 0.5533],\n",
              "        [0.7601, 0.0901, 0.9177],\n",
              "        [0.9578, 0.0165, 0.0217],\n",
              "        [0.8028, 0.8380, 0.1479]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX9teqF1gEZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d6024a92-c62e-4577-ab52-8289a53521ff"
      },
      "source": [
        "b.numpy()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4949733 , 0.2898629 , 0.55330195],\n",
              "       [0.76009278, 0.0901079 , 0.91771219],\n",
              "       [0.95775943, 0.01649582, 0.02168991],\n",
              "       [0.80281124, 0.83804703, 0.1478994 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzYS-UyQgHdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "17709af8-99bb-4995-cf23-008654853167"
      },
      "source": [
        "# The memory is shared between the Numpy array and Torch tensor, so if we change the values in-place of one object, the other will change as well.\n",
        "b.mul_(2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9899, 0.5797, 1.1066],\n",
              "        [1.5202, 0.1802, 1.8354],\n",
              "        [1.9155, 0.0330, 0.0434],\n",
              "        [1.6056, 1.6761, 0.2958]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVfXBAUegg-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bec0a722-4ec8-42cd-d15e-9e236c0288d0"
      },
      "source": [
        "a"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9899466 , 0.57972581, 1.1066039 ],\n",
              "       [1.52018556, 0.18021579, 1.83542438],\n",
              "       [1.91551885, 0.03299164, 0.04337982],\n",
              "       [1.60562248, 1.67609406, 0.29579879]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avgJOlC99VBo",
        "colab_type": "text"
      },
      "source": [
        "Deep learning networks tend to be massive with dozens or hundreds of layers, that's where the term \"deep\" comes from. You can build one of these deep networks using only weight matrices as we did in the previous notebook, but in general it's very cumbersome and difficult to implement. PyTorch has a nice module **nn** that provides a nice way to efficiently build large neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHSNT4We-xxO",
        "colab_type": "text"
      },
      "source": [
        "## Coding our first pytorch neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev7KrOgTglU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing necessary pacakages\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import helper\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S10lI92q-E9W",
        "colab_type": "text"
      },
      "source": [
        "Probelm : Identifying text in an image. </br>\n",
        "Dataset used : MNIST dataset, which consists of greyscale handwritten digits. </br>\n",
        "Each image is 28x28 pixels. \n",
        "\n",
        "![Screenshot 2020-06-30 at 07 36 24](https://user-images.githubusercontent.com/26361028/86074907-69c2d300-baa4-11ea-9bdf-6f72fb28e789.png)\n",
        "\n",
        "Goal is to build a neural network that can take one of these images and predict the digit in the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqS0BzKD9-o9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352,
          "referenced_widgets": [
            "f4112248c7284bf28fda1a65d656156b",
            "c67bda0658c2494a879801062419856c",
            "1da1465e12b24a8a851eceb579acf73a",
            "046007e768414f9baf277be80f2f0c1b",
            "e274a62ba45d49869e158642da74c652",
            "d1b3a1a613cf4627801ed5c9bf6ebb59",
            "dc6e6929c3484f87b2c0fa98426c9551",
            "d85b321c4045451e879b8a686d963db1",
            "14b3d05d4c6b4bf68757714a3a491eba",
            "fcc3419260c94a7eaec54d2d278831b5",
            "f3ff93d95b9b4dfc9d3a3e34850d2dae",
            "124a5135886e4f76bc448a9010761868",
            "9a4a822aa6424fe2b3a5398a84a31c86",
            "08e3fb31d37742dfb3a80051b4036339",
            "6bfb8f174e964062be1e372424588568",
            "6db923d02fe540648237784385a3738a",
            "0576c84a101a47688ca144a0f6708072",
            "05a229f5a15642268355c095230f87a8",
            "868aa2920374475eb4df54a61dfd7b06",
            "f12865316a14492ca242043ffd7fb46a",
            "3a3f60270b544600a31fa3bdfaf842a6",
            "6f6db800d9d9412ab778bffc1f6170fb",
            "7a7dc6c735b64967a67b49b972227030",
            "a90606744cc242bba0f5a6e2560b8ac2",
            "b5f4df3c9a4748d29f9f825fa812a309",
            "49133dee35444e7a8e4d08f9aab0706e",
            "3786005cc21b426da081b283e901e106",
            "a3dd09cdfe58448abb59653aed1814fa",
            "7caff1df14344fec9555ebe62fe3b8da",
            "264a73c812bc40ad864c6d35e7a05371",
            "f435fc6ec90542b19397ba3e6f7843a5",
            "7f088c592abc4a699c201e0fc754883d"
          ]
        },
        "outputId": "1c391305-5809-4daf-a998-033a1c7e5428"
      },
      "source": [
        "# Downloading the dataset.\n",
        "# This is provided by torchvision package\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "# transforms.ToTensor() converts inupt image to Python Tensor\n",
        "# transforms.Normalize scales input data \n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),\n",
        "                                ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data',download=True,train=True,transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4112248c7284bf28fda1a65d656156b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14b3d05d4c6b4bf68757714a3a491eba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0576c84a101a47688ca144a0f6708072",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5f4df3c9a4748d29f9f825fa812a309",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNJDkdgrB-PD",
        "colab_type": "text"
      },
      "source": [
        "So, below we have tensor with size (64,1,28,28) i.e 64 images per batch, 1 color channel, and 28x28 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxyD1yvaBMP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "052b7b36-95ea-49ce-c7c2-809a473ad822"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images,labels = dataiter.next()\n",
        "print (type(images))\n",
        "print (images.shape)\n",
        "print (labels.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN3v3PFkBzGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c7197321-570a-4b02-8b17-4b770267b9ee"
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fea57b24d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 251,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRfn6Gj6CQTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3df7caf-6bbc-4cb8-f673-1dda57d6ecc0"
      },
      "source": [
        "images[0].shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxboJRrEDoWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76a458ac-92ce-4ceb-b41f-c704435eb3f1"
      },
      "source": [
        "images.shape[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPcAyw8cK77G",
        "colab_type": "text"
      },
      "source": [
        "# TODO:\n",
        "Flatten the batch of images. Then build a multi-layer network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. For now, use a sigmoid activation for the hidden layer. Leave the output layer without an activation,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH7xTh58KmPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80f4ea12-16f7-44a9-b75c-56817b21a77c"
      },
      "source": [
        "# Solution:\n",
        "\n",
        "def activation(x):\n",
        "  return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "# Flatten the input images\n",
        "inputs = images.view(images.shape[0],-1)      # (64,784)\n",
        "\n",
        "# Create parameters\n",
        "n_input = inputs.shape[1]     # Number of input features\n",
        "n_hidden = 256                # Number of hidden units\n",
        "n_output = 10                 # Number of output units (0 - 9)\n",
        "\n",
        "w1 = torch.randn((n_input,n_hidden))\n",
        "b1 = torch.randn(n_hidden)\n",
        "\n",
        "w2 = torch.randn((n_hidden,n_output))\n",
        "b2 = torch.randn(n_output)\n",
        "\n",
        "h = activation(torch.mm(inputs,w1) + b1)        # [inputs]_mat_of_size(64x784) x [w1]_mat_of_size(784x256) => [h]_mat_of_size(64x256)\n",
        "output = torch.mm(h,w2) + b2                    # [h]_mat_of_size(64x256) x [w2]_mat_of_size(256,10) = [output]_mat_of_size(64x10)\n",
        "\n",
        "print (output)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 4.1850e+00,  1.7385e+01, -2.0025e+01, -3.1723e+00, -3.5890e+00,\n",
            "         -5.5427e-01,  6.3814e+00,  1.2403e+01,  4.3539e-01,  5.4370e+00],\n",
            "        [-4.7575e+00,  1.5829e+01, -2.2019e+01,  5.1966e+00, -5.0433e-01,\n",
            "          8.2517e+00,  1.0362e+01,  4.4520e+00,  1.6230e+01,  6.6735e+00],\n",
            "        [-5.8159e+00,  2.0752e+01, -1.4510e+01, -4.0851e+00,  1.2044e+01,\n",
            "         -5.2770e+00,  1.5019e+01,  6.0332e+00,  2.6487e+00,  4.7284e+00],\n",
            "        [-6.5566e-02,  9.0499e+00, -6.1621e+00, -8.0228e+00,  8.4912e-01,\n",
            "         -1.2533e+01,  5.8463e+00,  1.1087e+01,  8.1131e+00, -1.1102e+00],\n",
            "        [-1.0341e+01,  7.8912e+00, -1.3880e+01,  3.2861e+00,  5.5803e+00,\n",
            "          5.1073e+00,  1.1375e+01,  7.1374e+00,  1.2983e+01, -4.1446e+00],\n",
            "        [-8.7998e+00,  1.2696e+01, -9.1019e+00, -3.2297e+00,  1.3302e+01,\n",
            "         -5.5572e+00,  1.9638e+01,  1.2058e+01,  2.7587e+00, -9.6813e-01],\n",
            "        [-4.3998e+00,  9.7839e+00, -9.3046e+00, -5.2474e-01,  1.3046e+01,\n",
            "          9.3212e+00,  1.4141e+01,  5.5907e+00,  1.0477e+01,  6.9960e+00],\n",
            "        [-2.5904e+00,  4.9976e+00, -1.1594e+01, -6.7529e+00, -1.0658e+01,\n",
            "          7.7110e+00,  1.1820e+01,  2.6636e+00,  1.0189e+01, -1.2421e+00],\n",
            "        [ 5.2115e-01, -1.3644e+00, -1.6513e+01, -4.6554e+00,  3.7285e+00,\n",
            "         -3.1080e+00,  7.7881e+00,  1.0042e+01, -6.8008e-01,  3.9067e+00],\n",
            "        [-7.6980e+00,  1.7183e+01, -7.7356e+00, -3.1033e+00,  9.3301e+00,\n",
            "          1.7091e+00,  1.7921e+01,  7.0748e+00,  1.3149e+01, -2.9447e+00],\n",
            "        [-6.3854e+00,  1.1959e+01, -1.3212e+01, -8.3055e+00, -5.5979e+00,\n",
            "         -1.0100e+00,  1.1872e+01,  1.4507e+01,  8.8909e+00, -9.9130e-01],\n",
            "        [-7.2685e+00,  9.3966e+00, -1.6992e+01, -8.7132e+00,  1.6523e+00,\n",
            "         -4.5413e+00,  1.1993e+01,  1.0928e+01,  1.4099e-01, -2.0974e+00],\n",
            "        [-6.0836e+00,  1.1314e+00, -7.8998e+00, -8.2629e+00, -2.3832e+00,\n",
            "         -5.8015e+00,  2.0638e+01,  1.1984e+01,  6.4640e+00, -1.0880e-01],\n",
            "        [ 8.8649e+00,  1.1780e+01, -5.3047e+00, -1.5820e+00, -7.1967e-01,\n",
            "         -1.0783e+01,  6.4219e+00,  1.2323e+01,  1.8625e+00,  1.1160e+01],\n",
            "        [-5.0527e+00,  9.7073e-01, -1.2549e+01,  7.4699e+00,  2.4881e+00,\n",
            "          8.5988e+00,  1.3410e+01,  2.8074e+00,  1.3882e+01,  2.5406e+00],\n",
            "        [ 3.1370e+00,  9.8613e+00, -1.5008e+01, -8.4445e+00,  3.1676e+00,\n",
            "          3.9761e-01,  1.7956e+01,  1.0018e+01,  9.8141e+00,  8.2353e+00],\n",
            "        [-4.1325e-01,  9.4053e+00, -7.8674e+00, -9.6269e+00,  4.6310e+00,\n",
            "         -3.9226e+00,  1.9257e+01,  1.5801e+01,  1.2540e+01, -1.9370e+00],\n",
            "        [-8.0577e+00,  8.7921e-01, -2.2821e+01,  1.0957e+01, -5.1954e-03,\n",
            "          2.0093e+00,  7.3236e+00,  1.2771e+00,  7.0792e+00,  9.8861e+00],\n",
            "        [-1.7177e+00,  4.8022e+00, -1.4918e+01, -9.0315e+00,  1.7778e+00,\n",
            "         -8.8775e+00,  1.5127e+01,  1.3011e+01,  8.0305e+00,  1.3752e+00],\n",
            "        [-1.1042e+01,  1.8486e+01, -7.8181e+00, -2.0258e+00,  6.6382e+00,\n",
            "         -1.1085e+01,  8.0895e+00,  7.1986e+00,  4.9272e+00,  4.1767e+00],\n",
            "        [-1.1431e+01,  9.0846e+00, -9.6848e+00, -2.4778e+00, -2.1890e+00,\n",
            "         -6.5941e-01,  1.5210e+01,  1.4524e+01,  1.2787e+01,  2.6752e-01],\n",
            "        [-1.0980e+01,  1.8590e+01, -3.9387e+00, -3.6066e+00,  7.4491e+00,\n",
            "         -1.3622e+01,  9.0497e+00,  6.7897e+00,  8.8084e+00,  4.0295e+00],\n",
            "        [-5.5636e+00,  9.0201e+00, -1.1805e+01,  5.3366e+00,  1.1283e+01,\n",
            "         -6.3773e+00,  6.8987e+00,  8.7577e+00,  1.4956e+01, -3.2343e+00],\n",
            "        [ 1.3601e+00,  7.0005e+00, -1.6155e+01, -2.1695e+00,  4.5036e+00,\n",
            "         -3.4691e+00,  6.1916e+00,  6.2630e+00,  2.5849e+00,  6.4051e+00],\n",
            "        [-2.5974e+00,  5.3203e+00, -1.5966e+01, -1.1527e+01,  6.2414e+00,\n",
            "         -2.8921e+00,  2.3688e+01,  9.8732e+00,  4.2984e+00,  1.3113e+00],\n",
            "        [-8.7829e+00,  6.0873e+00, -1.3347e+01, -8.4448e+00,  1.4486e+01,\n",
            "         -5.3137e+00,  1.8460e+01,  1.2370e+01,  3.7597e+00,  5.0722e-01],\n",
            "        [-2.1901e+00,  1.3368e+01, -1.0093e+01, -1.2596e+01,  5.8887e-01,\n",
            "         -1.2001e+01,  1.1280e+01,  1.8297e+01,  1.1891e+01, -2.4339e+00],\n",
            "        [-4.1558e+00,  5.3178e+00, -1.7129e+01, -1.4081e+01,  1.5484e-01,\n",
            "         -4.2667e+00,  1.8459e+01,  9.0142e+00,  1.0509e+01, -2.2456e+00],\n",
            "        [-9.2438e+00,  1.0064e+01, -1.1944e+01, -4.8412e+00, -1.1263e+00,\n",
            "         -6.1675e+00,  1.4904e+01,  1.2564e+01,  9.0218e+00,  3.1502e+00],\n",
            "        [-2.2386e-01,  6.7728e+00, -1.3367e+01, -5.5902e+00, -2.1062e+00,\n",
            "         -4.0307e+00,  1.5782e+01,  1.0553e+01,  7.0632e+00,  6.9369e+00],\n",
            "        [-2.2139e-01,  1.0696e+01, -5.9660e+00, -8.0274e+00, -5.6501e+00,\n",
            "         -1.4529e+01,  1.1841e+01,  1.6149e+01,  1.1986e+01, -2.2052e+00],\n",
            "        [-4.1362e+00,  1.1397e+01, -1.5301e+01, -2.3836e+00,  1.1667e+00,\n",
            "          2.5122e+00,  1.4458e+01,  1.3733e+01,  5.5537e+00,  8.0834e+00],\n",
            "        [-5.4519e-01,  9.6976e+00,  2.9708e+00, -6.7921e+00, -6.4790e+00,\n",
            "          1.0058e+00,  1.3513e+01,  5.8830e+00,  6.0672e+00, -1.1714e+01],\n",
            "        [-1.1170e+01,  1.5640e+01, -2.2294e+01, -1.2260e+00,  1.5441e+01,\n",
            "          7.9898e-01,  1.2776e+01,  6.8489e+00,  1.0487e+00, -3.5832e+00],\n",
            "        [-4.5033e+00,  9.3958e+00, -1.3184e+01, -6.2791e+00,  5.8166e+00,\n",
            "         -4.4917e-01,  1.0410e+01,  6.7540e+00,  1.8731e+00,  6.7213e+00],\n",
            "        [ 1.9238e+00,  8.3823e+00, -1.3004e+01,  1.2227e+00, -3.0391e+00,\n",
            "         -1.3344e+01,  2.6431e+00,  7.4998e+00,  1.4807e+01,  8.6500e+00],\n",
            "        [-3.0271e+00,  9.6333e+00, -8.3151e+00,  9.1011e-01, -5.4341e+00,\n",
            "          2.8711e+00,  1.0209e+01,  1.1705e+01,  1.0081e+01,  2.2721e+00],\n",
            "        [-3.2283e+00,  1.0432e+01, -5.7130e+00, -1.1007e+01,  3.6888e+00,\n",
            "         -1.4765e+01,  1.7926e+01,  1.1113e+01,  7.5183e+00,  2.5639e+00],\n",
            "        [-2.2616e+00,  7.2675e+00, -2.1534e+00, -3.3060e+00, -4.6795e-01,\n",
            "         -8.9165e+00,  1.7148e+01,  1.3761e+01,  2.9513e+00, -1.5279e+00],\n",
            "        [ 3.7860e-01,  1.3357e+01, -1.7841e+01,  2.9327e+00,  2.0945e+00,\n",
            "          6.2253e+00,  1.0285e+01,  6.7317e+00,  1.6635e+01,  1.4078e+00],\n",
            "        [-4.3434e+00,  1.3977e+01, -1.2403e+01, -9.1765e+00,  5.2227e-01,\n",
            "         -1.0590e+01,  9.5861e+00,  1.4870e+01,  1.0442e+01, -3.1680e+00],\n",
            "        [-8.7876e+00,  8.9068e+00, -1.9795e+00, -2.5498e+00, -6.8097e+00,\n",
            "          2.9650e+00,  1.2275e+01,  8.1385e+00,  1.3914e+01,  8.1529e-01],\n",
            "        [-8.9099e+00,  9.2171e+00, -1.9731e+01, -7.5366e+00,  1.2967e+01,\n",
            "          8.8302e-01,  1.8400e+01,  1.9516e+01,  3.3681e+00,  1.4466e+00],\n",
            "        [-1.0256e+01,  1.1738e+01, -6.6419e-01,  1.3500e+00,  4.7162e+00,\n",
            "          2.0411e+00,  1.5941e+01,  6.2851e+00,  7.1429e+00,  1.7877e+00],\n",
            "        [-1.0246e+01,  1.4187e+01, -1.0951e+01, -1.8873e+00,  3.1641e+00,\n",
            "         -8.7496e+00,  1.0036e+01,  7.5093e+00,  7.8438e+00,  1.1774e+00],\n",
            "        [-4.2189e+00,  8.4167e+00, -1.3223e+01, -1.1786e+00, -4.4208e+00,\n",
            "         -6.7730e-01,  7.6857e+00,  1.1434e+01, -4.7568e-01, -2.8455e+00],\n",
            "        [-1.3728e+01,  1.2870e+01, -1.4951e+00,  3.2610e-01,  3.0599e+00,\n",
            "         -2.9031e+00,  8.3916e+00,  1.0850e+01,  8.9481e+00,  1.1472e+00],\n",
            "        [-1.6851e+01,  8.6362e+00, -1.3482e+01, -9.1172e+00, -4.6271e+00,\n",
            "          1.1791e+00,  1.7244e+01,  1.8464e+01,  6.2052e+00, -2.3030e+00],\n",
            "        [-8.8184e+00,  1.0868e+01, -1.9423e+00,  3.0957e+00,  5.4258e-01,\n",
            "         -1.1564e+01,  1.0943e+01,  1.0025e+01,  5.5268e+00, -2.3497e-01],\n",
            "        [-8.5603e+00,  1.0645e+01, -1.2709e+01, -3.1323e+00,  9.6809e+00,\n",
            "          1.2916e+00,  1.8620e+01,  1.5268e+01,  5.2457e+00,  4.4071e+00],\n",
            "        [-4.0467e-01,  8.5597e+00, -3.1527e+00, -6.9082e+00, -1.8916e+00,\n",
            "         -1.3860e+01,  1.1952e+01,  1.1545e+01,  9.3310e+00, -6.3034e+00],\n",
            "        [-1.6065e+00,  7.7063e+00, -1.1179e+01, -5.4710e+00, -5.7738e+00,\n",
            "          1.3536e+00,  1.2524e+01,  6.9959e+00,  9.0170e-01,  6.0696e+00],\n",
            "        [-1.2590e+01,  2.0707e+01, -1.5957e+01,  2.4601e+00,  4.9483e+00,\n",
            "         -1.0541e+00,  1.1242e+01,  1.4026e+01,  1.8189e+01,  4.4057e-01],\n",
            "        [ 1.4923e+00,  5.5211e+00, -1.1972e+01, -5.2868e+00,  9.6789e+00,\n",
            "          1.2675e+01,  2.7543e+00, -5.0296e-01,  1.2957e+01,  6.8223e+00],\n",
            "        [ 3.4888e+00,  1.4902e+01, -1.1281e+01, -3.3543e+00, -8.3681e-01,\n",
            "         -1.2305e+00,  6.5554e+00,  9.9245e+00,  1.0555e+00,  3.8452e+00],\n",
            "        [-1.6149e+00,  1.1821e+01, -3.5202e+00, -7.0847e+00, -2.4528e-01,\n",
            "         -1.0203e+01,  7.5965e+00,  1.1858e+01,  8.4004e+00, -3.8651e+00],\n",
            "        [-7.8837e+00,  1.2660e+01, -2.3660e+01, -5.1586e+00,  2.3644e+00,\n",
            "          1.0045e+01,  1.0572e+01,  3.2022e+00,  6.6557e+00,  1.2990e+00],\n",
            "        [-5.4311e+00,  6.4793e+00, -2.6151e+00, -9.6552e+00, -2.7518e+00,\n",
            "         -6.8275e+00,  9.5950e+00,  1.7229e+01,  7.0692e+00,  4.8758e+00],\n",
            "        [-1.9916e+00,  9.1562e+00, -4.6642e+00, -2.0166e+00,  3.0617e+00,\n",
            "         -1.0867e+01,  2.6212e+01,  1.4120e+01,  5.6053e+00,  5.4672e+00],\n",
            "        [ 1.4745e+00,  6.2417e-01, -8.7238e+00, -5.0791e+00, -1.3555e+00,\n",
            "         -5.1967e+00,  4.4643e+00,  1.2591e+01,  6.0209e+00,  2.3650e+00],\n",
            "        [-1.6216e+00,  7.6380e+00, -1.5021e+01, -1.3525e+00,  8.2283e+00,\n",
            "          1.1689e+00,  1.7312e+01,  1.2478e+01,  5.3560e+00,  4.2523e+00],\n",
            "        [-4.8547e+00,  4.8990e+00, -1.3926e+01, -7.7183e+00, -2.2911e+00,\n",
            "         -3.5915e+00,  1.4871e+01,  1.2643e+01,  8.8995e-01, -5.9035e-01],\n",
            "        [-2.8574e+00,  3.6078e+00, -4.2756e+00, -2.7234e+00, -2.7683e+00,\n",
            "         -1.1229e+01,  1.3954e+01,  1.6369e+01,  6.4825e+00, -5.8984e+00],\n",
            "        [-5.1581e+00,  1.0237e+01, -1.1158e+01, -3.7968e+00,  4.6862e+00,\n",
            "         -2.9867e+00,  1.4047e+01,  1.0164e+01,  1.3768e+01,  3.0494e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmtiGY2CLex4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "842c9be1-7631-442c-fcc6-2e295c3d6637"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m51sSAdzbh-P",
        "colab_type": "text"
      },
      "source": [
        "Now we have 10 outputs for our network. We want to pass in an image to our network and get out a probability distribution over the classes that tells us the likely class(es) the image belongs to.\n",
        "\n",
        "![Screenshot 2020-06-30 at 09 43 52](https://user-images.githubusercontent.com/26361028/86082769-36893f80-bab6-11ea-8ca5-503d0a473a4d.png)\n",
        "\n",
        "Here we see that the probability for each class is roughly the same. This is representing an untrained network, it hasn't seen any data yet so it just returns a uniform distribution with equal probabilities for each class.\n",
        "\n",
        "To calculate this probability distribution, we often use the softmax function. Mathematically this looks like - \n",
        "\n",
        "![Screenshot 2020-06-30 at 09 44 42](https://user-images.githubusercontent.com/26361028/86082826-54ef3b00-bab6-11ea-8e47-8e5b70b9c09f.png)\n",
        "\n",
        "What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilites sum up to one.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJtjD-yTLf2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In out example, output matrix size = (64,10)\n",
        "# So, for one example in each row, we want to sum all 10 columns\n",
        "def softmax(x):\n",
        "  return torch.exp(x) / torch.sum(torch.exp(x),dim=1).view(-1,1)      # we want the sum across the columns, so dim = 1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5ul1kCajPXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e9181284-8709-4cf1-a1c0-91058af240e2"
      },
      "source": [
        "probabilities = softmax(output)\n",
        "print (probabilities.shape) # should be 64x10\n",
        "print (probabilities.sum(dim=1))      # sum should be 1\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91YkRFsWuqRo",
        "colab_type": "text"
      },
      "source": [
        "# Building networks with Pytorch\n",
        "\n",
        "###### Building the same above network with Pytorch's nn \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiB2xkkktmIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu_M_RGpwLGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Inputs to hidden layer linear transformation\n",
        "    self.hidden = nn.Linear(784, 256)   # since we know input features will 784 long and 256 hidden units\n",
        "\n",
        "    # Output layer - 10 units - one for each digit\n",
        "    self.output = nn.Linear(256,10) \n",
        "\n",
        "    # Define sigmoid activation and softmax output\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.hidden(x)\n",
        "    x = self.sigmoid(x)\n",
        "    x = self.output(x)\n",
        "    x = self.softmax(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGYbyMIB3FZM",
        "colab_type": "text"
      },
      "source": [
        "![Screenshot 2020-06-30 at 11 43 38](https://user-images.githubusercontent.com/26361028/86090018-f2eb0180-bac6-11ea-8b8c-f536bef243d4.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyhA_MxL25ej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "96fe4795-abee-43f8-f88b-6090a8770ca5"
      },
      "source": [
        "# Create the newtwork\n",
        "model = Network()\n",
        "model"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6-9pTSd3jix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can also define the above network more concisely and clearly using torch.nn.functional module\n",
        "# We normally import this as F\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden = nn.Linear(784,256)\n",
        "    self.output = nn.Linear(256,10)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = F.sigmoid(self.hidden(x))\n",
        "    x = F.softmax(self.output(x))\n",
        "\n",
        "    return x"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPU3LsBu5hm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f53d7be2-c0a3-4cb5-ee88-ebe7112bc183"
      },
      "source": [
        "model = Network()\n",
        "model"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeudmO6u6W5Q",
        "colab_type": "text"
      },
      "source": [
        "![Screenshot 2020-06-30 at 11 58 00](https://user-images.githubusercontent.com/26361028/86091116-f41d2e00-bac8-11ea-9afc-dcc9d45fe9a1.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_mbu6zl6hUS",
        "colab_type": "text"
      },
      "source": [
        "Objective : Build a multi-layer neural network that utilizes the ReLU activation function in it's hidden layers.\n",
        "\n",
        "Build this - </br>\n",
        "![Screenshot 2020-06-30 at 12 00 21](https://user-images.githubusercontent.com/26361028/86091300-48281280-bac9-11ea-8c74-67cfb45fda7a.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpYAewK26H0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden1 = nn.Linear(784,128)\n",
        "    self.hidden2 = nn.Linear(128,64)\n",
        "    self.output = nn.Linear(64,10)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.hidden1(x))\n",
        "    x = F.relu(self.hidden2(x))\n",
        "    x = F.softmax(self.output(x),dim=1)\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWjRbtnw9fZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9d1a7396-f240-4031-8bf1-f090cb53b0c8"
      },
      "source": [
        "model = Network()\n",
        "model"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2VSYP4sBNR8",
        "colab_type": "text"
      },
      "source": [
        "### Initializing the weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmLEXHch9yyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "4729b756-3919-47b1-f983-1aa62bab488e"
      },
      "source": [
        "# Acessing the weights and bias attached to the layer\n",
        "print (model.hidden1.weight)\n",
        "print (model.hidden1.bias)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0027, -0.0015,  0.0289,  ...,  0.0127,  0.0287,  0.0160],\n",
            "        [ 0.0148, -0.0356,  0.0197,  ...,  0.0144, -0.0031,  0.0178],\n",
            "        [-0.0047, -0.0077, -0.0325,  ...,  0.0319,  0.0353,  0.0111],\n",
            "        ...,\n",
            "        [ 0.0268, -0.0230,  0.0033,  ...,  0.0229,  0.0125,  0.0056],\n",
            "        [ 0.0048, -0.0178, -0.0268,  ...,  0.0226, -0.0118, -0.0277],\n",
            "        [-0.0298,  0.0009,  0.0248,  ..., -0.0197, -0.0324, -0.0007]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0055, -0.0025, -0.0040,  0.0211, -0.0023,  0.0197, -0.0098,  0.0086,\n",
            "         0.0153,  0.0127, -0.0080, -0.0018,  0.0310,  0.0209, -0.0279,  0.0038,\n",
            "         0.0211, -0.0280, -0.0354, -0.0346,  0.0077,  0.0270,  0.0150, -0.0330,\n",
            "         0.0125,  0.0229, -0.0355, -0.0016,  0.0294,  0.0053,  0.0350,  0.0210,\n",
            "         0.0011,  0.0176,  0.0002, -0.0127, -0.0130, -0.0164, -0.0134, -0.0212,\n",
            "        -0.0277,  0.0214,  0.0184,  0.0059, -0.0313, -0.0188,  0.0225,  0.0299,\n",
            "         0.0299,  0.0047, -0.0238, -0.0196,  0.0241,  0.0200, -0.0347, -0.0111,\n",
            "         0.0093, -0.0025, -0.0106,  0.0144,  0.0206, -0.0061,  0.0274, -0.0055,\n",
            "        -0.0128, -0.0354,  0.0009,  0.0235,  0.0074, -0.0114, -0.0300, -0.0162,\n",
            "         0.0109,  0.0064,  0.0137,  0.0116,  0.0147,  0.0229,  0.0002, -0.0051,\n",
            "         0.0008, -0.0148, -0.0055, -0.0066,  0.0146, -0.0197,  0.0296, -0.0122,\n",
            "        -0.0259, -0.0357, -0.0261,  0.0071, -0.0005, -0.0032, -0.0273,  0.0274,\n",
            "         0.0201,  0.0258, -0.0009, -0.0258, -0.0201, -0.0246, -0.0325, -0.0046,\n",
            "         0.0031, -0.0323, -0.0232, -0.0155,  0.0153,  0.0127, -0.0217,  0.0051,\n",
            "         0.0143, -0.0073,  0.0288, -0.0254, -0.0116, -0.0073,  0.0269,  0.0228,\n",
            "        -0.0298, -0.0285,  0.0147,  0.0162, -0.0060, -0.0224, -0.0093,  0.0154],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdMaxekiA9Xt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3e2e9b25-7416-41b9-9b06-9112a4901f0a"
      },
      "source": [
        "# Set biases to all zeros\n",
        "model.hidden1.bias.data.fill_(0)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3rg9VfyEYnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b76d0608-4922-4849-a8d7-26ae77b0f80e"
      },
      "source": [
        "# sample from random normal with standard dev = 0.01\n",
        "model.hidden1.bias.data.normal_(std=0.01)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0042, -0.0140,  0.0065,  0.0104, -0.0085, -0.0073, -0.0076, -0.0065,\n",
              "        -0.0010,  0.0184, -0.0009,  0.0052,  0.0038,  0.0072,  0.0213,  0.0241,\n",
              "        -0.0132, -0.0061,  0.0091,  0.0063,  0.0019,  0.0087,  0.0155,  0.0103,\n",
              "        -0.0086,  0.0164, -0.0085,  0.0208, -0.0049,  0.0193,  0.0099,  0.0143,\n",
              "         0.0030,  0.0088, -0.0026, -0.0032,  0.0004,  0.0140,  0.0151,  0.0068,\n",
              "        -0.0021, -0.0022, -0.0064, -0.0006,  0.0143,  0.0072,  0.0057,  0.0126,\n",
              "        -0.0076,  0.0173, -0.0010, -0.0039,  0.0031,  0.0062, -0.0063,  0.0105,\n",
              "         0.0099, -0.0075, -0.0015, -0.0107, -0.0046, -0.0040, -0.0128, -0.0072,\n",
              "         0.0112,  0.0089,  0.0072,  0.0093, -0.0086, -0.0056, -0.0054,  0.0022,\n",
              "         0.0096, -0.0114,  0.0018,  0.0086,  0.0034,  0.0062,  0.0070,  0.0053,\n",
              "        -0.0048,  0.0169, -0.0053, -0.0076, -0.0061, -0.0030,  0.0220, -0.0085,\n",
              "        -0.0063,  0.0058, -0.0118, -0.0162, -0.0028,  0.0042, -0.0152,  0.0125,\n",
              "        -0.0025, -0.0037, -0.0067, -0.0023,  0.0113,  0.0086,  0.0057, -0.0134,\n",
              "         0.0171,  0.0111,  0.0065, -0.0054,  0.0065,  0.0103,  0.0117,  0.0060,\n",
              "        -0.0160, -0.0155,  0.0062,  0.0141, -0.0089, -0.0207, -0.0073,  0.0069,\n",
              "        -0.0032,  0.0147, -0.0048,  0.0104, -0.0172,  0.0016,  0.0219, -0.0099])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul2Obc7B1xia",
        "colab_type": "text"
      },
      "source": [
        "## Using nn.Sequential\n",
        "\n",
        "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, nn.Sequential. Using this to build the equivalent network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xH0QsKJ1y5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a07da889-a2f5-4502-8c2c-6e2f3c1ffe10"
      },
      "source": [
        "# Hyperparameters for our network\n",
        "\n",
        "input_size = 784\n",
        "hidden_sizes = [128,64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward neural network\n",
        "model = nn.Sequential(nn.Linear(input_size,hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0],hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1],output_size),\n",
        "                      nn.Softmax(dim=1))\n",
        "\n",
        "print (model)\n",
        "\n",
        "# Forward pass through the network and display the output\n",
        "images,labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0],1,784)\n",
        "ps = model.forward(images[0,:])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): Softmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXMOSM9-1zP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ba2b2e2-12b6-4fe0-df2e-53768cb25268"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "301ZbQx24wJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7151d72a-108d-447c-92a1-3ba17881c00a"
      },
      "source": [
        "print (model[0])\n",
        "print (model[0].weight)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=784, out_features=128, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0274, -0.0194, -0.0051,  ...,  0.0215,  0.0178,  0.0150],\n",
            "        [ 0.0351, -0.0314, -0.0009,  ..., -0.0196,  0.0122, -0.0218],\n",
            "        [-0.0119, -0.0339,  0.0007,  ..., -0.0318,  0.0254, -0.0203],\n",
            "        ...,\n",
            "        [ 0.0225,  0.0047, -0.0256,  ..., -0.0111,  0.0008, -0.0111],\n",
            "        [ 0.0237,  0.0289, -0.0045,  ..., -0.0280, -0.0062, -0.0156],\n",
            "        [-0.0232,  0.0349, -0.0028,  ..., -0.0111,  0.0023,  0.0116]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw-D-9auRwDG",
        "colab_type": "text"
      },
      "source": [
        "![Screenshot 2020-06-30 at 12 35 09](https://user-images.githubusercontent.com/26361028/86094433-24b39680-bace-11ea-8b62-9e1f7bcd0697.png)\n",
        "\n",
        "## Backpropagation\n",
        "\n",
        "![Screenshot 2020-06-30 at 18 19 51](https://user-images.githubusercontent.com/26361028/86127929-4b89c100-bafe-11ea-94ee-0de42544d604.png)\n",
        "\n",
        "![Screenshot 2020-06-30 at 18 22 02](https://user-images.githubusercontent.com/26361028/86128134-9a375b00-bafe-11ea-9eb6-1f2fda7736f9.png)\n",
        "\n",
        "\n",
        "![Screenshot 2020-06-30 at 18 25 04](https://user-images.githubusercontent.com/26361028/86128475-07e38700-baff-11ea-93a0-9f7a1e994efc.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8t2IoNk6r5a",
        "colab_type": "text"
      },
      "source": [
        "### Losses in Pytorch\n",
        "Let's start by seeing how we calculate the loss with PyTorch. Through the nn module, PyTorch provides losses such as the cross-entropy loss (nn.CrossEntropyLoss). You'll usually see the loss assigned to criterion. As noted in the last part, with a classification problem such as MNIST, we're using the softmax function to predict class probabilities. With a softmax output, you want to use cross-entropy as the loss. To actually calculate the loss, you first define the criterion then pass in the output of your network and the correct labels.\n",
        "\n",
        "- This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
        "- The input is expected to contain scores for each class.\n",
        "\n",
        "This means we need to pass in the raw output of our network into the loss, not the output of the softmax function. This raw output is usually called the logits or scores. We use the logits because softmax gives you probabilities which will often be very close to zero or one but floating-point numbers can't accurately represent values near zero or one.\n",
        "It's usually best to avoid doing calculations with probabilities, typically we use log-probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGGTpG3jFNpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets,transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),\n",
        "                                ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/',download=True,train=True,transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 64, shuffle = True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7FbXEZN86N2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bca4904a-69d4-42ed-91c1-81b0afee939f"
      },
      "source": [
        "# Build a feedforward neural network\n",
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10))\n",
        "\n",
        "# Define the Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0],-1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with logits and labels\n",
        "loss = criterion(logits,labels)\n",
        "\n",
        "print (loss)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2718, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVgXRpA29qSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29552b93-60c5-4680-9675-aca61ef62fd0"
      },
      "source": [
        "# Building a feed-forwaard neural network\n",
        "# with log-softmax output and using negative log likelihood loss\n",
        "\n",
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "# Define the Loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Get our data\n",
        "images,labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0],-1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logps = model(images)\n",
        "# Calculate the loss with logits and labels\n",
        "loss = criterion(logps,labels)\n",
        "\n",
        "print (loss)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3010, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8xZ_GYbG4Nb",
        "colab_type": "text"
      },
      "source": [
        "![Screenshot 2020-06-30 at 22 11 11](https://user-images.githubusercontent.com/26361028/86152990-9d424380-bb1e-11ea-8771-b729260ab017.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwS8g7KA9tPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "179adde1-7db1-43b6-9d48-03f54bfe62ad"
      },
      "source": [
        "x = torch.randn(2,2,requires_grad = True)\n",
        "print (x)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4253, 0.5767],\n",
            "        [0.0469, 1.3786]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DV-YtGdGEcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "42d6a26d-4965-4920-92b6-cc4b9b732a4f"
      },
      "source": [
        "y = x**2\n",
        "print (y)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1809, 0.3326],\n",
            "        [0.0022, 1.9007]], grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQCcqeosHgEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "637b20ac-941b-41f8-d289-9c07cc3748ed"
      },
      "source": [
        "# grad_fn shows the function that generated this variable\n",
        "print (y.grad_fn)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PowBackward0 object at 0x7fea57564cc0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fClLdAjOHrGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4feaa8cf-1040-431f-f5f8-d2b750515c5c"
      },
      "source": [
        "# The autograd module keeps track of these operations and knows how to calculate the gradient for each one.\n",
        "# In this way, it's able to calculate gradient for chain of operations, with respect to any one tensor.\n",
        "\n",
        "# Let's reduce the tensor y to scalar value, the mean\n",
        "z = y.mean()\n",
        "print (z)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6041, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxArftYjIMab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca259ce1-41bd-47f8-b09e-e4fc53119279"
      },
      "source": [
        "# Checking the gradients of x and y, they should be empty curently as we didn't backpropagate\n",
        "print (x.grad)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNonkW3cIuVA",
        "colab_type": "text"
      },
      "source": [
        "![Screenshot 2020-06-30 at 22 18 59](https://user-images.githubusercontent.com/26361028/86153718-b39ccf00-bb1f-11ea-99fa-fea80e123836.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1HJDjyQIZtW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0d3f0b58-2524-4119-dc66-d026a0255531"
      },
      "source": [
        "z.backward()\n",
        "print (x.grad)\n",
        "print (x/2)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2127, 0.2883],\n",
            "        [0.0234, 0.6893]])\n",
            "tensor([[0.2127, 0.2883],\n",
            "        [0.0234, 0.6893]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCfW37xTIz0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0b3383c-317c-44df-9c41-ac5f68d95a1c"
      },
      "source": [
        "# Build a feed-forward neural network\n",
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images,labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0],-1)\n",
        "\n",
        "logps = model(images)\n",
        "loss = criterion(logps,labels)\n",
        "loss"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2803, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrmRYqgMNkXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5487c67e-a33f-417e-f9a1-1b309afdc063"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul-3_dtuOzc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b4bd8582-a002-4656-a080-c4c661a65674"
      },
      "source": [
        "print ('Before Backpropagation: \\n', model[0].weight.grad)    #  model[0].weight is the weights between input and hiddenlayer 1\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print ('After Backpropagation: \\n', model[0].weight.grad)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Backpropagation: \n",
            " None\n",
            "After Backpropagation: \n",
            " tensor([[ 3.3637e-03,  3.3637e-03,  3.3637e-03,  ...,  3.3637e-03,\n",
            "          3.3637e-03,  3.3637e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 3.3560e-03,  3.3560e-03,  3.3560e-03,  ...,  3.3560e-03,\n",
            "          3.3560e-03,  3.3560e-03],\n",
            "        ...,\n",
            "        [-6.9562e-05, -6.9562e-05, -6.9562e-05,  ..., -6.9562e-05,\n",
            "         -6.9562e-05, -6.9562e-05],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-4.3422e-03, -4.3422e-03, -4.3422e-03,  ..., -4.3422e-03,\n",
            "         -4.3422e-03, -4.3422e-03]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGcH79OmGDGy",
        "colab_type": "text"
      },
      "source": [
        "Now, we use an optimizer to update the weights with the gradients. \n",
        "We get these from pytorch's optim package. \n",
        "- Ex. We can use stochastic gradient descent with optim.SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GoRjm89FVNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers requires parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRZJjESoHbQW",
        "colab_type": "text"
      },
      "source": [
        "Now we know how to use all the individual parts so it's time to see how they work together. Let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
        "\n",
        "- Make a forward pass through the network\n",
        "- Use the network output to calculate the loss\n",
        "- Perform a backward pass through the network with loss.backward() to calculate the gradients\n",
        "- Take a step with the optimizer to update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JV7mfHgOdn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwHOvUqfG6FI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "fdd3d792-5dc3-48d8-8a82-5737c484a6f2"
      },
      "source": [
        "print ('Initial Weights - ', model[0].weight)\n",
        "\n",
        "images,labels = next(iter(trainloader))\n",
        "images.resize_(64,784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, the  backward pass, then update weights\n",
        "output = model.forward(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print ('Gradient - ', model[0].weight.grad)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Weights -  Parameter containing:\n",
            "tensor([[-0.0018, -0.0072,  0.0231,  ..., -0.0330,  0.0143, -0.0090],\n",
            "        [ 0.0212, -0.0127, -0.0028,  ...,  0.0223,  0.0219, -0.0242],\n",
            "        [-0.0042, -0.0115,  0.0200,  ..., -0.0210, -0.0013, -0.0299],\n",
            "        ...,\n",
            "        [-0.0330,  0.0226,  0.0220,  ...,  0.0052,  0.0209,  0.0094],\n",
            "        [ 0.0081,  0.0042, -0.0178,  ...,  0.0226, -0.0042, -0.0199],\n",
            "        [ 0.0075, -0.0058,  0.0035,  ...,  0.0200, -0.0264,  0.0267]],\n",
            "       requires_grad=True)\n",
            "Gradient -  tensor([[ 0.0042,  0.0042,  0.0042,  ...,  0.0042,  0.0042,  0.0042],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0038,  0.0038,  0.0038,  ...,  0.0038,  0.0038,  0.0038],\n",
            "        ...,\n",
            "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0107, -0.0107, -0.0107,  ..., -0.0107, -0.0107, -0.0107]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMPsgr_bNUhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cfee35e9-e166-4787-f893-6022205965f9"
      },
      "source": [
        "# Take an update step and fill the new weights\n",
        "optimizer.step()\n",
        "print ('Updated weights - ', model[0].weight)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[-0.0029, -0.0348,  0.0005,  ..., -0.0319,  0.0222,  0.0323],\n",
            "        [ 0.0127,  0.0054,  0.0023,  ..., -0.0218, -0.0183,  0.0238],\n",
            "        [-0.0083,  0.0124, -0.0054,  ..., -0.0308, -0.0213, -0.0283],\n",
            "        ...,\n",
            "        [-0.0261, -0.0233,  0.0121,  ...,  0.0126,  0.0233, -0.0254],\n",
            "        [-0.0048,  0.0352,  0.0160,  ..., -0.0302, -0.0243,  0.0272],\n",
            "        [ 0.0110,  0.0336,  0.0236,  ..., -0.0027,  0.0353,  0.0321]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XMK_V_dPjdh",
        "colab_type": "text"
      },
      "source": [
        "#### Training for real"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XooHFbvNfsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torchvision import datasets,transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),\n",
        "                                ])\n",
        "\n",
        "# Download and load the training data\n",
        "trset = datasets.MNIST('~/.pytorch/MNIST_data/',download=True,train=True,transform=transform)\n",
        "trloader = torch.utils.data.DataLoader(trainset,batch_size = 64, shuffle = True)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuDRxyFxP3UB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "02b07807-bd6b-4a9b-cfcb-fd9b6e2848b2"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784,128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128,64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64,10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images,labels in trloader:\n",
        "    # Flatten MNIST images into 784 long vector\n",
        "    images = images.view(images.shape[0],-1)\n",
        "\n",
        "    # Training pass\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(images)\n",
        "    loss = criterion(output,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()    # to update the weights\n",
        "    running_loss += loss.item()\n",
        "  \n",
        "  print(f\"Training loss: {running_loss/len(trloader)}\") \n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.051402537998106\n",
            "Training loss: 0.38951910079033897\n",
            "Training loss: 0.32854559195480115\n",
            "Training loss: 0.29369335960763604\n",
            "Training loss: 0.2681131253221523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVV8JTjcRP-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}