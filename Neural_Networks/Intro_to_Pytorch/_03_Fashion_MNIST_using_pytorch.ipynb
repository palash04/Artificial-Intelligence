{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_03_Fashion_MNIST_using_pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMixo2f4FSBAd7HIHShxujN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palash04/Artificial-Intelligence/blob/master/Neural_Networks/Intro_to_Pytorch/_03_Fashion_MNIST_using_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orHWK8Ke-2ET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing all the packages\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets,transforms"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BM7o9SLAE3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,))])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GYxRr6VAfgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading dataset\n",
        "# Shuffle them and transform each one of them\n",
        "\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data',download=True,train=True,transform=transform)\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data',download=True,train=False,transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpFIEfylDdMV",
        "colab_type": "text"
      },
      "source": [
        "![Screenshot 2020-07-01 at 16 35 31](https://user-images.githubusercontent.com/26361028/86237159-e2b34f00-bbb8-11ea-9e60-6c92a7b2491a.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoTeJ-d2DnJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ca0fb0d7-f0ed-47f6-9074-bea53972b4ce"
      },
      "source": [
        "# Making a mapping for label and description\n",
        "def what_is_this(x):\n",
        "  what = {0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'}\n",
        "  return what[x]\n",
        "\n",
        "what_is_this(3)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Dress'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uFuOyayBPI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "6a4e4c24-e4dd-41fc-aa8e-99182155bf52"
      },
      "source": [
        "# Let's plot one output\n",
        "images,labels = next(iter(trainloader))\n",
        "print (images.shape)\n",
        "\n",
        "i = 25\n",
        "plt.imshow(images[i].numpy().squeeze(), cmap='gray_r')\n",
        "#print (\"Them labeled item is : \", what_is_this(labels[i]))\n",
        "x = list(labels.numpy())[i]\n",
        "print (\"Labeled object is : \", what_is_this(x))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "Labeled object is :  Shirt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WS1ZhvpCSbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bdbe281b-669a-474f-f45e-9746b029749b"
      },
      "source": [
        "# Building the network\n",
        "\n",
        "input_size = 784\n",
        "hidden_sizes = [256,128,64]\n",
        "output_size = 10\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size,hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0],hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1],hidden_sizes[2]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[2],output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "print (model)\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (7): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_N91oIXXDPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "3500bcff-1ffd-4b0d-863f-6ec98e81e069"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images,labels in trainloader:\n",
        "    images = images.view(images.shape[0],-1)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(images)\n",
        "    loss = criterion(output,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  print ('Epoch {} - Training Loss: {}'.format(e,running_loss/len(trainloader)))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Training Loss: 1.3566355807885433\n",
            "Epoch 1 - Training Loss: 0.6120463666885392\n",
            "Epoch 2 - Training Loss: 0.5294754433987746\n",
            "Epoch 3 - Training Loss: 0.4834233410577022\n",
            "Epoch 4 - Training Loss: 0.4521421437610441\n",
            "Epoch 5 - Training Loss: 0.4268081608706954\n",
            "Epoch 6 - Training Loss: 0.40717102601520544\n",
            "Epoch 7 - Training Loss: 0.39153063438658015\n",
            "Epoch 8 - Training Loss: 0.3773364330818658\n",
            "Epoch 9 - Training Loss: 0.365087588395137\n",
            "Epoch 10 - Training Loss: 0.3556111622879754\n",
            "Epoch 11 - Training Loss: 0.3456148462000686\n",
            "Epoch 12 - Training Loss: 0.33653204980244766\n",
            "Epoch 13 - Training Loss: 0.32713798495498037\n",
            "Epoch 14 - Training Loss: 0.3208584764809497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tlJhW5XeA1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31aede00-f078-4de8-95a7-43549562ce68"
      },
      "source": [
        "# Testing the model\n",
        "correct_count, all_count = 0,0\n",
        "for images,labels in testloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1,784)\n",
        "    with torch.no_grad():\n",
        "      logps = model(img)\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if true_label == pred_label:\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print ('Number of images tested: ', all_count)\n",
        "print ('Model accuracy: ', (correct_count/all_count))\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images tested:  10000\n",
            "Model accuracy:  0.8665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc3aUnm2flmA",
        "colab_type": "text"
      },
      "source": [
        "86%..Not that bad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVi5wv4EfiJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's build once again, this time we will change the learning rate a bit \n",
        "\n",
        "model2 = nn.Sequential(nn.Linear(784,256),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(256,128),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(128,64),\n",
        "                       nn.ReLU(),\n",
        "                       nn.Linear(64,10),\n",
        "                       nn.LogSoftmax(dim=1))\n",
        "\n",
        "optimizer = optim.SGD(model2.parameters(), lr = 0.03)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTEzLtc4ghE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b07013d6-d2ab-4335-8f98-8d48b0fa4b56"
      },
      "source": [
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images,labels in trainloader:\n",
        "    images = images.view(images.shape[0],-1)\n",
        "    logps = model2(images)\n",
        "    loss = criterion(logps,labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  \n",
        "  print ('Epoch {} - Training Loss {}: '.format(e,running_loss/len(trainloader)))\n",
        "  "
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Training Loss 0.8564614081370042: \n",
            "Epoch 1 - Training Loss 0.47932088356028235: \n",
            "Epoch 2 - Training Loss 0.41926447956610335: \n",
            "Epoch 3 - Training Loss 0.3840973034088037: \n",
            "Epoch 4 - Training Loss 0.3590042540418314: \n",
            "Epoch 5 - Training Loss 0.33761743248017356: \n",
            "Epoch 6 - Training Loss 0.32161201929836386: \n",
            "Epoch 7 - Training Loss 0.30881492014346856: \n",
            "Epoch 8 - Training Loss 0.2967112873520043: \n",
            "Epoch 9 - Training Loss 0.2854115111248961: \n",
            "Epoch 10 - Training Loss 0.2758173187261324: \n",
            "Epoch 11 - Training Loss 0.2670316408866885: \n",
            "Epoch 12 - Training Loss 0.2589345124484634: \n",
            "Epoch 13 - Training Loss 0.2491871321411021: \n",
            "Epoch 14 - Training Loss 0.24338489096524366: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQJdZuMghBz_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c43a067e-010f-418d-a6e7-c7028ebad0d6"
      },
      "source": [
        "# Testing the new model\n",
        "\n",
        "correct_count, all_count = 0,0\n",
        "\n",
        "for images,labels in testloader:\n",
        "  for i in range(len(labels)):\n",
        "    img =  images[i].view(1,784)\n",
        "    with torch.no_grad():\n",
        "      logps = model2(img)\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if true_label == pred_label:\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print ('Number of images tested: ', all_count)\n",
        "print ('Model Accuracy: ', (correct_count/all_count))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images tested:  10000\n",
            "Model Accuracy:  0.8813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJo8qIr5ibQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}