{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_AutoCorrection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "um4SU91feIGg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPxxAZZ1dbSx"
      },
      "source": [
        "file_name = '/content/shakespeare.txt'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoTc3p-7eSLk"
      },
      "source": [
        "## Part 1: Data preprocessing\n",
        "\n",
        "- Read in a corpus\n",
        "- Change everything to lowercase\n",
        "- Return a list of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97qk_LTEePSx"
      },
      "source": [
        "def process_data(file_name):\n",
        "  with open(file_name) as f:\n",
        "    text = f.read()\n",
        "\n",
        "  text = text.lower()\n",
        "  words = re.findall(r'\\w+', text)\n",
        "  return words"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz9-HIw8esgq",
        "outputId": "870efe75-ba13-441c-e3b6-beb2a0a20e57"
      },
      "source": [
        "words = process_data(file_name)\n",
        "vocab = set(words)\n",
        "print(f'The first ten words in the text are: \\n', words[:10])\n",
        "print(f'There are {len(vocab)} unique words in vocabulary.')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The first ten words in the text are: \n",
            " ['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
            "There are 6116 unique words in vocabulary.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEKj1JSX7S6x"
      },
      "source": [
        "### Building a dictionary of word frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vQC_bz7gOwJ"
      },
      "source": [
        "def get_count(words):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    words: a list of words representing the corpus\n",
        "  Output:\n",
        "    word_count_dict: a dictionary where key is the word and value is the frequency\n",
        "  \"\"\"\n",
        "  word_count_dict = Counter(words)\n",
        "  return word_count_dict"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8acaajtl74do",
        "outputId": "6d972b9d-7be2-4e0f-ede5-bdcb2cde816a"
      },
      "source": [
        "word_count_dict = get_count(words)\n",
        "print(f'There are {len(word_count_dict)} key-value pairs')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 6116 key-value pairs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePDrhY4Q8rpc"
      },
      "source": [
        "### Building a dictionary of probabilities of words.\n",
        "\n",
        "That is compute the probability that each word will appear if randomly selected from the corpus of words.\n",
        "\n",
        "$P(w) = \\frac {freq(w)}{M}$\n",
        "where M = total number of words in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqKR5lcj79_I"
      },
      "source": [
        "def get_probs(word_count_dict):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    word_count_dict: The wordcount dictionary where key is word and value is its frequency\n",
        "  Output:\n",
        "    probs: A dictionary where key are the words and values are the probabilitiy that a word will occur\n",
        "  \"\"\"\n",
        "  probs = {}\n",
        "  M = len(words)\n",
        "  for word, freq in word_count_dict.items():\n",
        "    probs[word] = freq / M\n",
        "  \n",
        "  return probs"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKpOtPst-CgX",
        "outputId": "b50354e4-c30e-4705-a9f8-da868a30b956"
      },
      "source": [
        "probs = get_probs(word_count_dict)\n",
        "print(f'Length of probs is {len(probs)}')\n",
        "print(f'P(\"the\") is {probs[\"the\"]:.4f}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of probs is 6116\n",
            "P(\"the\") is 0.0284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2r_BWw_3lnk"
      },
      "source": [
        "## Part2: String manipulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wPcCUi3-Ofy",
        "outputId": "6cb81010-83c9-4ff2-c4c2-65ccb09741f7"
      },
      "source": [
        "# function to delete a character in a string\n",
        "def delete_letter(word, verbose=False):\n",
        "  # returns a list of all possible words after deleting a letter \n",
        "  split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "  delete_l = [L+R[1:] for L, R in split_l if R]\n",
        "  return delete_l\n",
        "\n",
        "delete_word_l = delete_letter('cans')\n",
        "print(delete_word_l)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ans', 'cns', 'cas', 'can']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EZwcwGq3fvK",
        "outputId": "c838a776-655f-41bd-c346-93051868def7"
      },
      "source": [
        "# function to switch two adjacent letters. Returns all such possible words\n",
        "def switch_letter(word):\n",
        "  switch_l = []\n",
        "  temp = word\n",
        "  \n",
        "  for i in range(len(word)-1):\n",
        "      a = temp[i]\n",
        "      b = temp[i+1]\n",
        "      w = temp[:i] + b + a + temp[i+2:]\n",
        "      switch_l.append(w)\n",
        "\n",
        "  return switch_l\n",
        "\n",
        "switch_word_l = switch_letter(word=\"abc\")\n",
        "print(switch_word_l) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bac', 'acb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04WqTrMi5hjR",
        "outputId": "bf1697ec-2d4f-4694-deb9-c518b004932d"
      },
      "source": [
        "# funtion to replace a letter \n",
        "def replace_letter(word, verbose=False):\n",
        "  '''\n",
        "  Input:\n",
        "      word: the input string/word \n",
        "  Output:\n",
        "      replaces: a list of all possible strings where we replaced one letter from the original word. \n",
        "  ''' \n",
        "  \n",
        "  letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "  split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
        "  \n",
        "  replace_l = [L + c + R[1:] for L, R in split_l for c in letters if R and R[0] != c]\n",
        "  \n",
        "  replace_set = set(replace_l)\n",
        "\n",
        "  replace_l = sorted(list(replace_set))\n",
        "  \n",
        "  return replace_l\n",
        "\n",
        "replace_l = replace_letter(word='can')\n",
        "print(replace_l)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4eCLWkz8NFB",
        "outputId": "731e1daf-308b-47fc-d789-828e6912d6f4"
      },
      "source": [
        "# function to insert a letter\n",
        "def insert_letter(word, verbose=False):\n",
        "  '''\n",
        "  Input:\n",
        "      word: the input string/word \n",
        "  Output:\n",
        "      inserts: a set of all possible strings with one new letter inserted at every offset\n",
        "  ''' \n",
        "  letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "  insert_l = []\n",
        "  split_l = []\n",
        "  \n",
        "  split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "  \n",
        "  insert_l = [L + c + R for L,R in split_l for c in letters]\n",
        "  \n",
        "  return insert_l\n",
        "\n",
        "insert_l = insert_letter('at', True)\n",
        "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of strings output by insert_letter('at') is 78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ex4t3gQBGTA"
      },
      "source": [
        "## Part3: Combining the edits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZZBZ0VaCLxI"
      },
      "source": [
        "### Edit one letter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmyKCQIW_6ce",
        "outputId": "1a34660f-816b-4cba-d183-c94bf33d9aa2"
      },
      "source": [
        "# function to get all possible edits that are one edit away from a word\n",
        "def edit_one_letter(word, allow_switches = True):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "      word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
        "  Output:\n",
        "      edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
        "  \"\"\"\n",
        "  \n",
        "  edit_one_set = set()\n",
        "  \n",
        "  l1 = delete_letter(word)\n",
        "  l2 = switch_letter(word)\n",
        "  l3 = replace_letter(word)\n",
        "  l4 = insert_letter(word)\n",
        "  \n",
        "  for ele in l1:\n",
        "      edit_one_set.add(ele)\n",
        "  for ele in l2:\n",
        "      edit_one_set.add(ele)\n",
        "  for ele in l3:\n",
        "      edit_one_set.add(ele)\n",
        "  for ele in l4:\n",
        "      edit_one_set.add(ele)\n",
        "  \n",
        "  return edit_one_set\n",
        "\n",
        "tmp_word = \"at\"\n",
        "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
        "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
        "\n",
        "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n",
        "print(f\"The type of the returned object should be a set {type(tmp_edit_one_set)}\")\n",
        "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input word at \n",
            "edit_one_l \n",
            "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
            "\n",
            "The type of the returned object should be a set <class 'set'>\n",
            "Number of outputs from edit_one_letter('at') is 129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk-hKu8WApPO",
        "outputId": "dae3de24-6b9f-47d2-da90-36189167588c"
      },
      "source": [
        "def edit_two_letters(word, allow_switches = True):\n",
        "  '''\n",
        "  Input:\n",
        "      word: the input string/word \n",
        "  Output:\n",
        "      edit_two_set: a set of strings with all possible two edits\n",
        "  '''\n",
        "  \n",
        "  edit_two_set = set()\n",
        "    \n",
        "  e1 = list(edit_one_letter(word))\n",
        "  \n",
        "  for w in e1:\n",
        "      w_l = list(edit_one_letter(w))\n",
        "      for ww in w_l:\n",
        "          edit_two_set.add(ww)\n",
        "  \n",
        "  return edit_two_set\n",
        "\n",
        "tmp_edit_two_set = edit_two_letters(\"abc\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
        "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
        "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
        "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
        "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('abc'))}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of strings with edit distance of two: 14352\n",
            "First 10 strings ['a', 'aa', 'aaa', 'aaabc', 'aaac', 'aab', 'aaba', 'aabac', 'aabb', 'aabbc']\n",
            "Last 10 strings ['zwc', 'zxabc', 'zxbc', 'zxc', 'zyabc', 'zybc', 'zyc', 'zzabc', 'zzbc', 'zzc']\n",
            "The data type of the returned object should be a set <class 'set'>\n",
            "Number of strings that are 2 edit distances from 'at' is 14352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCRlWgJbyVbs"
      },
      "source": [
        "## Part4: Suggest spelling suggestions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK25Pm7RB-8b"
      },
      "source": [
        "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
        "  '''\n",
        "  Input: \n",
        "      word: a user entered string to check for suggestions\n",
        "      probs: a dictionary that maps each word to its probability in the corpus\n",
        "      vocab: a set containing all the vocabulary\n",
        "      n: number of possible word corrections you want returned in the dictionary\n",
        "  Output: \n",
        "      n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
        "  '''\n",
        "\n",
        "  suggestions = []\n",
        "  n_best = []\n",
        "  \n",
        "  if word in vocab:\n",
        "      n_best.append((word, probs[word]))\n",
        "      return n_best\n",
        "  \n",
        "  e1 = edit_one_letter(word)\n",
        "  for w in e1:\n",
        "      if w in vocab:\n",
        "          suggestions.append(w)\n",
        "  \n",
        "  if len(e1) == 0:\n",
        "      e2 = edit_two_letters(word)\n",
        "      for w in e1:\n",
        "          if w in vocab:\n",
        "              suggestions.append(w)\n",
        "\n",
        "  \n",
        "  for w in suggestions:\n",
        "      n_best.append((w, probs[w]))\n",
        "  \n",
        "  n_best.sort(key = lambda x : x[1], reverse=True)\n",
        "\n",
        "  if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
        "\n",
        "  return n_best"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6dLMk9tykJi",
        "outputId": "356a24c4-755d-4ef1-b8b4-b98b09e1edc8"
      },
      "source": [
        "my_word = 'hors' \n",
        "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
        "\n",
        "print(f\"data type of corrections {type(tmp_corrections)}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entered word =  hors \n",
            "suggestions =  ['horns', 'horn', 'hers', 'hours', 'horse']\n",
            "word 0: hours, probability 0.000317\n",
            "word 1: horse, probability 0.000224\n",
            "word 2: hers, probability 0.000168\n",
            "word 3: horns, probability 0.000037\n",
            "word 4: horn, probability 0.000019\n",
            "data type of corrections <class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZUHg8jAzik-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}