{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_Seq2Seq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1uDWVSi-rTY"
      },
      "source": [
        "!pip install d2l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMqVs5XZ_nKo"
      },
      "source": [
        "import collections\n",
        "import math\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from d2l import torch as d2l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI3YgTYBAoDs"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3bJXTVZ_q-y"
      },
      "source": [
        "class Seq2SeqEncoder(nn.Module):\n",
        "  \"\"\"The RNN encoder for sequence to sequence learning\"\"\"\n",
        "  def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
        "    super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
        "    # Embedding layer\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "    self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)\n",
        "\n",
        "  def forward(self, X, *args):\n",
        "    # Input X shape: (batch_size, num_steps)\n",
        "    X = self.embedding(X) # Shape of X after embedding: (batch_size, num_steps, embed_size)\n",
        "\n",
        "    # In RNN models the first axis corresponds to time steps\n",
        "    X = X.permute(1,0,2)    # shape: (num_steps, batch_size, embed_size)\n",
        "\n",
        "    # When state is not mentioned, it defaults to zeros\n",
        "    output, state = self.rnn(X)\n",
        "\n",
        "    # output shape: (num_steps, batch_size, num_hiddens)\n",
        "    # state shape: (num_layers, batch_size, num_hiddens)\n",
        "    return output, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsp2hYtAF8Z6",
        "outputId": "e9bb26ac-c78e-4a84-e773-871a9ff98d5c"
      },
      "source": [
        "# Testig above implementation\n",
        "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
        "encoder.eval()\n",
        "batch_size = 4\n",
        "num_steps = 7\n",
        "X = torch.zeros((batch_size,num_steps), dtype=torch.long)\n",
        "output, state = encoder(X)\n",
        "print(output.shape)\n",
        "print(state.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 4, 16])\n",
            "torch.Size([2, 4, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ymPWFbnHT5z"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHkWa64WGn9j"
      },
      "source": [
        "class Seq2SeqDecoder(nn.Module):\n",
        "  def __init__(self, vocab_size, num_hiddens, embed_size, num_layers, dropout=0, **kwargs):\n",
        "    super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "    self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
        "    self.dense = nn.Linear(num_hiddens, vocab_size)\n",
        "\n",
        "  def init_state(self, enc_outputs, *args):\n",
        "    return enc_outputs[1]\n",
        "\n",
        "  def forward(self, X, state):\n",
        "    # Input shape of X: (batch_size,num_steps)\n",
        "    X = self.embedding(X) # (batch_size, num_steps, embed_size)\n",
        "    X = X.permute(1,0,2)  # (num_steps, batch_size, embed_size)\n",
        "\n",
        "    # Broadcast context\n",
        "    context = state[-1].repeat(X.shape[0], 1, 1)  # (num_steps, batch_size, num_hiddens)\n",
        "    X_and_context = torch.cat((X,context), 2)   # (num_steps, batch_size, embed_size + num_hiddens)\n",
        "\n",
        "    output, state = self.rnn(X_and_context, state) \n",
        "    output = self.dense(output).permute(1,0,2)\n",
        "\n",
        "    # output shape: (batch_size, num_steps, vocab_size)\n",
        "    # state shape: (num_layers, batch_size, num_hiddens)\n",
        "\n",
        "    return output, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIr6LwWMIRns",
        "outputId": "d47cc663-ae5b-47ec-d082-db8aeb1f8022"
      },
      "source": [
        "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
        "                         num_layers=2)\n",
        "decoder.eval()\n",
        "state = decoder.init_state(encoder(X))\n",
        "output, state = decoder(X, state)\n",
        "output.shape, state.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CFlRM1IPfCF"
      },
      "source": [
        "Encoder Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US2w1J5WPgeB"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  \"\"\"The base class for the encoder-decoder architecture.\"\"\"\n",
        "  def __init__(self, encoder, decoder, **kwargs):\n",
        "    super(EncoderDecoder, self).__init__(**kwargs)\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, enc_X, dec_X, *args):\n",
        "    enc_outputs = self.encoder(enc_X, *args)\n",
        "    dec_state = self.decoder.init_state(enc_outputs, *args)\n",
        "    return self.decoder(dec_X, dec_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yfib_VvpLAYt",
        "outputId": "75e1475f-79d8-46d5-ed3c-8d66ed4eb749"
      },
      "source": [
        "def sequence_mask(X, valid_len, value=0):\n",
        "  \"\"\"Mask irrelevant entries in sequences.\"\"\"\n",
        "  maxlen = X.size(1)\n",
        "  mask = torch.arange((maxlen), dtype=torch.float32,\n",
        "                      device=X.device)[None, :] < valid_len[:, None]\n",
        "  X[~mask] = value\n",
        "  return X\n",
        "\n",
        "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "sequence_mask(X, torch.tensor([1, 2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0],\n",
              "        [4, 5, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRqz88qdMK2n",
        "outputId": "6447a07c-e38a-4e13-d697-9c0140dc428a"
      },
      "source": [
        "X = torch.ones(2, 3, 4)\n",
        "sequence_mask(X, torch.tensor([1, 2]), value=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.,  1.,  1.,  1.],\n",
              "         [-1., -1., -1., -1.],\n",
              "         [-1., -1., -1., -1.]],\n",
              "\n",
              "        [[ 1.,  1.,  1.,  1.],\n",
              "         [ 1.,  1.,  1.,  1.],\n",
              "         [-1., -1., -1., -1.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo3qi4XCMNdy"
      },
      "source": [
        "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
        "  \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
        "\n",
        "  # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
        "  # `label` shape: (`batch_size`, `num_steps`)\n",
        "  # `valid_len` shape: (`batch_size`,)\n",
        "  def forward(self, pred, label, valid_len):\n",
        "    weights = torch.ones_like(label)\n",
        "    weights = sequence_mask(weights, valid_len)\n",
        "    self.reduction = 'none'\n",
        "    unweighted_loss = super(MaskedSoftmaxCELoss,\n",
        "                            self).forward(pred.permute(0, 2, 1), label)\n",
        "    weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
        "    return weighted_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhapLWb4NLq0",
        "outputId": "136ec01e-b74b-40bf-cc48-0ea093313884"
      },
      "source": [
        "loss = MaskedSoftmaxCELoss()\n",
        "loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long),\n",
        "     torch.tensor([4, 2, 0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.3026, 1.1513, 0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSUVi1Z8NecX"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VQzym04NNgo"
      },
      "source": [
        "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
        "  def xavier_init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "      nn.init.xavier_uniform_(m.weight)\n",
        "    if type(m) == nn.GRU:\n",
        "      for param in m._flat_weights_names:\n",
        "        if \"weight\" in param:\n",
        "          nn.init.xavier_uniform_(m._parameters[param])\n",
        "  \n",
        "  net.apply(xavier_init_weights)\n",
        "  net.to(device)\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "  loss = MaskedSoftmaxCELoss()\n",
        "  net.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    metric = d2l.Accumulator(2)\n",
        "    for batch in data_iter:\n",
        "      optimizer.zero_grad()\n",
        "      X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
        "      # Shape of X: (batch_size, num_steps)\n",
        "      # Shape of Y: (batch_size, num_steps)\n",
        "      bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0], device=device).reshape(-1, 1)\n",
        "      dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
        "      Y_hat, _ = net(X, dec_input, X_valid_len)\n",
        "      l = loss(Y_hat, Y, Y_valid_len)\n",
        "      l.sum().backward()  # Make the loss scalar for `backward`\n",
        "      d2l.grad_clipping(net, 1)\n",
        "      num_tokens = Y_valid_len.sum()\n",
        "      optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGy2g0EzPYoC"
      },
      "source": [
        "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
        "batch_size, num_steps = 64, 10\n",
        "lr, num_epochs, device = 0.005, 300, d2l.try_gpu()\n",
        "\n",
        "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
        "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,\n",
        "                         dropout)\n",
        "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,\n",
        "                         dropout)\n",
        "net = EncoderDecoder(encoder, decoder)\n",
        "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyzVeYwfPr7S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}